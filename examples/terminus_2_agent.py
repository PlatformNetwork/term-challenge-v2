#!/usr/bin/env python3
"""
Terminus-2 Agent adapted for Term SDK 2.0.

This is a port of the terminal-bench Terminus-2 agent without external dependencies.
Uses JSON format for LLM responses with batch command execution.

Key features:
- Batch command execution (multiple commands per LLM call)
- JSON response format with analysis, plan, and commands
- Double confirmation for task completion
- Output truncation to manage context length
- Auto-correction for common JSON parsing errors

Usage:
    export LLM_API_KEY="your-api-key"
    export LLM_MODEL="anthropic/claude-3.5-sonnet"  # optional
    python terminus_2_agent.py
"""

import json
import os
import re
import time
from dataclasses import dataclass
from typing import List, Optional, Tuple

from term_sdk import Agent, AgentContext, LLM, LLMError, CostLimitExceeded, run


# =============================================================================
# PROMPT TEMPLATES
# =============================================================================

SYSTEM_PROMPT = """You are an AI assistant tasked with solving command-line tasks in a Linux environment. You will be given a task description and the output from previously executed commands. Your goal is to solve the task by providing batches of shell commands.

Format your response as JSON with the following structure:

{
  "analysis": "Analyze the current state based on the terminal output provided. What do you see? What has been accomplished? What still needs to be done?",
  "plan": "Describe your plan for the next steps. What commands will you run and why? Be specific about what you expect each command to accomplish.",
  "commands": [
    {
      "keystrokes": "ls -la",
      "duration": 0.1
    },
    {
      "keystrokes": "cd project",
      "duration": 0.1
    }
  ],
  "task_complete": false
}

Required fields:
- "analysis": Your analysis of the current situation
- "plan": Your plan for the next steps
- "commands": Array of command objects to execute

Optional fields:
- "task_complete": Boolean indicating if the task is complete (defaults to false if not present)

Command object structure:
- "keystrokes": String containing the exact command to execute (required)
- "duration": Number of seconds to wait for the command to complete (defaults to 1.0 if not present)

The "duration" attribute specifies the timeout for the command. On immediate tasks (cd, ls, echo, cat) set 0.1 seconds. On slow commands (make, python, wget) set appropriate duration. Maximum is 60 seconds.

Important notes:
- Each command is executed as a separate shell invocation
- Commands array can be empty if you want to wait without taking action
- Be concise in analysis and plan to save tokens
- The JSON must be valid - use proper escaping for quotes and special characters"""

INITIAL_PROMPT_TEMPLATE = """Task Description:
{instruction}

Current terminal state:
{terminal_state}"""

TIMEOUT_TEMPLATE = """Previous command:
{command}

The command timed out after {timeout_sec} seconds.

It is possible that the command is not yet finished executing. You can check status with additional commands, or the operation may require more time.

Current terminal state:
{terminal_state}"""

COMPLETION_CONFIRMATION = """Current terminal state:
{terminal_output}

Are you sure you want to mark the task as complete? This will trigger your solution to be graded and you won't be able to make any further corrections. If so, include "task_complete": true in your JSON response again."""


# =============================================================================
# JSON PARSER
# =============================================================================

@dataclass
class ParsedCommand:
    """A parsed command from the LLM response."""
    keystrokes: str
    duration: float


@dataclass
class ParseResult:
    """Result of parsing an LLM response."""
    commands: List[ParsedCommand]
    is_task_complete: bool
    error: str
    warning: str


class JSONParser:
    """Parser for terminus JSON response format."""
    
    REQUIRED_FIELDS = ["analysis", "plan", "commands"]
    
    def parse_response(self, response: str) -> ParseResult:
        """Parse a JSON response and extract commands."""
        # Try normal parsing first
        result = self._try_parse(response)
        
        if result.error:
            # Try auto-fixes
            for fix_name, fix_func in self._get_auto_fixes():
                corrected, was_fixed = fix_func(response, result.error)
                if was_fixed:
                    corrected_result = self._try_parse(corrected)
                    if not corrected_result.error:
                        warning = f"AUTO-CORRECTED: {fix_name}"
                        if corrected_result.warning:
                            corrected_result.warning = f"- {warning}\n{corrected_result.warning}"
                        else:
                            corrected_result.warning = f"- {warning}"
                        return corrected_result
        
        return result
    
    def _try_parse(self, response: str) -> ParseResult:
        """Try to parse a JSON response."""
        warnings = []
        
        # Extract JSON content
        json_content, extra_warnings = self._extract_json(response)
        warnings.extend(extra_warnings)
        
        if not json_content:
            return ParseResult([], False, "No valid JSON found in response", 
                             self._format_warnings(warnings))
        
        # Parse JSON
        try:
            data = json.loads(json_content)
        except json.JSONDecodeError as e:
            error_msg = f"Invalid JSON: {e}"
            if len(json_content) < 200:
                error_msg += f" | Content: {repr(json_content)}"
            return ParseResult([], False, error_msg, self._format_warnings(warnings))
        
        # Validate structure
        if not isinstance(data, dict):
            return ParseResult([], False, "Response must be a JSON object", 
                             self._format_warnings(warnings))
        
        # Check required fields
        missing = [f for f in self.REQUIRED_FIELDS if f not in data]
        if missing:
            return ParseResult([], False, f"Missing required fields: {', '.join(missing)}", 
                             self._format_warnings(warnings))
        
        # Check commands is a list
        commands_data = data.get("commands", [])
        if not isinstance(commands_data, list):
            return ParseResult([], False, "Field 'commands' must be an array", 
                             self._format_warnings(warnings))
        
        # Check task_complete
        is_complete = data.get("task_complete", False)
        if isinstance(is_complete, str):
            is_complete = is_complete.lower() in ("true", "1", "yes")
        
        # Parse commands
        commands, parse_error = self._parse_commands(commands_data, warnings)
        if parse_error:
            if is_complete:
                warnings.append(parse_error)
                return ParseResult([], True, "", self._format_warnings(warnings))
            return ParseResult([], False, parse_error, self._format_warnings(warnings))
        
        return ParseResult(commands, is_complete, "", self._format_warnings(warnings))
    
    def _extract_json(self, response: str) -> Tuple[str, List[str]]:
        """Extract JSON object from response."""
        warnings = []
        
        json_start = -1
        json_end = -1
        brace_count = 0
        in_string = False
        escape_next = False
        
        for i, char in enumerate(response):
            if escape_next:
                escape_next = False
                continue
            if char == "\\":
                escape_next = True
                continue
            if char == '"' and not escape_next:
                in_string = not in_string
                continue
            if not in_string:
                if char == "{":
                    if brace_count == 0:
                        json_start = i
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                    if brace_count == 0 and json_start != -1:
                        json_end = i + 1
                        break
        
        if json_start == -1 or json_end == -1:
            return "", ["No valid JSON object found"]
        
        before = response[:json_start].strip()
        after = response[json_end:].strip()
        
        if before:
            warnings.append("Extra text before JSON")
        if after:
            warnings.append("Extra text after JSON")
        
        return response[json_start:json_end], warnings
    
    def _parse_commands(self, commands_data: List, warnings: List[str]) -> Tuple[List[ParsedCommand], str]:
        """Parse commands array into ParsedCommand objects."""
        commands = []
        
        for i, cmd_data in enumerate(commands_data):
            if not isinstance(cmd_data, dict):
                return [], f"Command {i+1} must be an object"
            
            if "keystrokes" not in cmd_data:
                return [], f"Command {i+1} missing 'keystrokes' field"
            
            keystrokes = cmd_data["keystrokes"]
            if not isinstance(keystrokes, str):
                return [], f"Command {i+1} 'keystrokes' must be a string"
            
            # Parse duration with default
            duration = cmd_data.get("duration", 1.0)
            if not isinstance(duration, (int, float)):
                warnings.append(f"Command {i+1}: Invalid duration, using default 1.0")
                duration = 1.0
            
            # Cap duration at 60 seconds
            duration = min(float(duration), 60.0)
            
            commands.append(ParsedCommand(keystrokes=keystrokes, duration=duration))
        
        return commands, ""
    
    def _get_auto_fixes(self):
        """Return auto-fix functions."""
        return [
            ("Fixed incomplete JSON", self._fix_incomplete_json),
            ("Extracted JSON from mixed content", self._fix_mixed_content),
        ]
    
    def _fix_incomplete_json(self, response: str, error: str) -> Tuple[str, bool]:
        """Fix incomplete JSON by adding missing closing braces."""
        if any(x in error for x in ["Invalid JSON", "Expecting", "Unterminated", "No valid JSON"]):
            brace_count = response.count("{") - response.count("}")
            if brace_count > 0:
                return response + "}" * brace_count, True
        return response, False
    
    def _fix_mixed_content(self, response: str, error: str) -> Tuple[str, bool]:
        """Extract JSON from mixed content."""
        pattern = r"\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}"
        matches = re.findall(pattern, response, re.DOTALL)
        
        for match in matches:
            try:
                json.loads(match)
                return match, True
            except json.JSONDecodeError:
                continue
        
        return response, False
    
    def _format_warnings(self, warnings: List[str]) -> str:
        """Format warnings list into string."""
        if not warnings:
            return ""
        return "- " + "\n- ".join(warnings)


# =============================================================================
# TERMINUS-2 AGENT
# =============================================================================

class Terminus2Agent(Agent):
    """
    Terminus-2 agent using batch command execution.
    
    This agent sends batches of commands to the terminal based on LLM analysis.
    It uses a JSON format for structured communication with the LLM.
    """
    
    def setup(self):
        """Initialize LLM and parser."""
        model = os.environ.get("LLM_MODEL", "anthropic/claude-3.5-sonnet")
        temperature = float(os.environ.get("LLM_TEMPERATURE", "0.7"))
        
        self.llm = LLM(
            provider="openrouter",
            default_model=model,
            temperature=temperature,
        )
        self.parser = JSONParser()
        self.history: List[dict] = []
        self.pending_completion = False
        
        # Max output size in bytes to prevent context overflow
        self.max_output_bytes = int(os.environ.get("MAX_OUTPUT_BYTES", "10000"))
        
        print(f"[agent] Terminus-2 using model: {model}", flush=True)
    
    def run(self, ctx: AgentContext):
        """Execute the task using batch command execution."""
        ctx.log(f"Task: {ctx.instruction[:100]}...")
        
        # Get initial terminal state
        initial_result = ctx.shell("pwd && ls -la")
        terminal_state = self._limit_output(initial_result.output)
        
        # Build initial prompt
        prompt = INITIAL_PROMPT_TEMPLATE.format(
            instruction=ctx.instruction,
            terminal_state=terminal_state,
        )
        
        # Initialize message history with system prompt
        self.history = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ]
        
        # Main agent loop (agent manages its own step limit)
        max_iterations = 200
        iteration = 0
        while iteration < max_iterations:
            # Get LLM response
            try:
                response = self.llm.chat(
                    self.history[-20:],  # Keep last 20 messages to manage context
                    max_tokens=4096,
                )
            except CostLimitExceeded as e:
                ctx.log(f"Cost limit reached: {e}")
                break
            except LLMError as e:
                ctx.log(f"LLM error: {e.code} - {e.message}")
                # Retry once on transient errors
                if e.code in ("rate_limit", "service_unavailable", "server_error"):
                    time.sleep(5)
                    continue
                break
            
            # Add assistant response to history
            self.history.append({"role": "assistant", "content": response.text})
            
            # Parse the response
            result = self.parser.parse_response(response.text)
            
            # Handle parse errors
            if result.error:
                ctx.log(f"Parse error: {result.error}")
                error_msg = (
                    f"Your response had parsing errors:\n{result.error}\n\n"
                    "Please provide a valid JSON response."
                )
                if result.warning:
                    error_msg += f"\n\nWarnings:\n{result.warning}"
                self.history.append({"role": "user", "content": error_msg})
                continue
            
            # Log warnings if any
            if result.warning:
                ctx.log(f"Parse warnings: {result.warning}")
            
            # Handle task completion with double confirmation
            if result.is_task_complete:
                if self.pending_completion:
                    ctx.log("Task completion confirmed")
                    break
                else:
                    self.pending_completion = True
                    terminal_output = self._get_terminal_state(ctx)
                    confirm_msg = COMPLETION_CONFIRMATION.format(
                        terminal_output=terminal_output
                    )
                    self.history.append({"role": "user", "content": confirm_msg})
                    continue
            else:
                self.pending_completion = False
            
            # Execute commands
            if not result.commands:
                ctx.log("No commands to execute")
                # Ask for next action
                self.history.append({
                    "role": "user",
                    "content": "No commands provided. What should we do next?"
                })
                continue
            
            terminal_output, timed_out, timeout_cmd = self._execute_commands(
                ctx, result.commands
            )
            
            # Build next prompt
            if timed_out:
                next_prompt = TIMEOUT_TEMPLATE.format(
                    command=timeout_cmd,
                    timeout_sec=60,
                    terminal_state=terminal_output,
                )
            else:
                next_prompt = terminal_output
                if result.warning:
                    next_prompt = f"Warnings from previous response:\n{result.warning}\n\n{next_prompt}"
            
            self.history.append({"role": "user", "content": next_prompt})
        
        ctx.done()
    
    def _execute_commands(
        self, 
        ctx: AgentContext, 
        commands: List[ParsedCommand]
    ) -> Tuple[str, bool, str]:
        """
        Execute a batch of commands.
        
        Returns:
            (terminal_output, timed_out, timeout_command)
        """
        outputs = []
        
        for cmd in commands:
            iteration += 1
            
            ctx.log(f"$ {cmd.keystrokes[:80]}")
            
            # Execute command with timeout
            timeout = max(1, int(cmd.duration))
            result = ctx.shell(cmd.keystrokes, timeout=timeout)
            
            if result.timed_out:
                outputs.append(f"$ {cmd.keystrokes}\n[TIMEOUT after {timeout}s]")
                if result.output:
                    outputs.append(result.output)
                return self._limit_output("\n".join(outputs)), True, cmd.keystrokes
            
            # Collect output
            output_text = f"$ {cmd.keystrokes}\n"
            if result.output:
                output_text += result.output
            if result.exit_code != 0:
                output_text += f"\n[exit code: {result.exit_code}]"
            outputs.append(output_text)
        
        return self._limit_output("\n\n".join(outputs)), False, ""
    
    def _get_terminal_state(self, ctx: AgentContext) -> str:
        """Get current terminal state (pwd + ls)."""
        result = ctx.shell("pwd && ls -la")
        return self._limit_output(result.output)
    
    def _limit_output(self, output: str, max_bytes: Optional[int] = None) -> str:
        """
        Limit output to max bytes, keeping first and last portions.
        """
        max_bytes = max_bytes or self.max_output_bytes
        
        if len(output.encode("utf-8")) <= max_bytes:
            return output
        
        portion_size = max_bytes // 2
        output_bytes = output.encode("utf-8")
        
        first = output_bytes[:portion_size].decode("utf-8", errors="ignore")
        last = output_bytes[-portion_size:].decode("utf-8", errors="ignore")
        
        omitted = len(output_bytes) - len(first.encode()) - len(last.encode())
        
        return (
            f"{first}\n"
            f"[... output limited to {max_bytes} bytes; {omitted} bytes omitted ...]\n"
            f"{last}"
        )
    
    def cleanup(self):
        """Print stats and cleanup."""
        stats = self.llm.get_stats()
        print(f"[agent] Total tokens: {stats['total_tokens']}", flush=True)
        print(f"[agent] Total cost: ${stats['total_cost']:.4f}", flush=True)
        print(f"[agent] Requests: {stats['request_count']}", flush=True)
        self.llm.close()


if __name__ == "__main__":
    run(Terminus2Agent())
