//! LLM-powered agent example.
//!
//! Set OPENROUTER_API_KEY environment variable before running.

use term_sdk::{Agent, Request, Response, LLM, run};

const SYSTEM_PROMPT: &str = r#"You are a terminal agent. Complete tasks using shell commands.

Rules:
1. Execute one command at a time
2. Check command output before proceeding
3. Use exit codes to detect errors (0 = success)
4. Set task_complete=true only when verified complete

Respond with JSON:
{"command": "shell command here", "task_complete": false}

When done:
{"command": null, "task_complete": true}"#;

struct LLMAgent {
    llm: LLM,
    history: Vec<String>,
}

impl LLMAgent {
    fn new() -> Self {
        Self {
            llm: LLM::new("anthropic/claude-3-haiku"),
            history: Vec::new(),
        }
    }
}

impl Agent for LLMAgent {
    fn solve(&mut self, req: &Request) -> Response {
        // Build context
        let context = format!(
            "Task: {}\n\nStep: {}\nWorking Directory: {}\nLast Command: {:?}\nExit Code: {:?}\nOutput:\n{}",
            req.instruction,
            req.step,
            req.cwd,
            req.last_command,
            req.exit_code,
            req.output.as_deref().unwrap_or("(no output)")
        );

        // Keep history manageable
        self.history.push(format!("Step {}:\n{}", req.step, context));
        if self.history.len() > 5 {
            self.history = self.history[self.history.len()-5..].to_vec();
        }

        // Call LLM
        let prompt = format!(
            "{}\n\nYour response (JSON):",
            self.history.join("\n---\n")
        );

        match self.llm.ask_with_system(SYSTEM_PROMPT, &prompt) {
            Ok(result) => Response::from_llm(&result.text),
            Err(e) => {
                eprintln!("LLM error: {}", e);
                Response::done()
            }
        }
    }

    fn cleanup(&mut self) {
        eprintln!("Total cost: ${:.4}", self.llm.total_cost);
    }
}

fn main() {
    run(&mut LLMAgent::new());
}
