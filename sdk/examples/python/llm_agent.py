#!/usr/bin/env python3
"""
LLM-powered agent example.

Set OPENROUTER_API_KEY environment variable before running.
"""
from term_sdk import Agent, Request, Response, LLM, run


SYSTEM_PROMPT = """You are a terminal agent. Complete tasks using shell commands.

Rules:
1. Execute one command at a time
2. Check command output before proceeding
3. Use exit codes to detect errors (0 = success)
4. Set task_complete=true only when verified complete

Respond with JSON:
{"command": "shell command here", "task_complete": false}

When done:
{"command": null, "task_complete": true}"""


class LLMAgent(Agent):
    """Agent powered by an LLM."""
    
    def setup(self):
        self.llm = LLM(default_model="anthropic/claude-3-haiku")
        self.history: list[str] = []
    
    def solve(self, req: Request) -> Response:
        # Build context
        context = f"""Task: {req.instruction}

Step: {req.step}
Working Directory: {req.cwd}
Last Command: {req.last_command}
Exit Code: {req.exit_code}
Output:
{req.output or "(no output)"}
"""
        
        # Keep history manageable
        self.history.append(f"Step {req.step}:\n{context}")
        if len(self.history) > 5:
            self.history = self.history[-5:]
        
        # Call LLM
        prompt = "\n---\n".join(self.history) + "\n\nYour response (JSON):"
        
        try:
            result = self.llm.ask(prompt, system=SYSTEM_PROMPT)
            return Response.from_llm(result.text)
        except Exception as e:
            print(f"LLM error: {e}", file=__import__('sys').stderr)
            return Response.done()
    
    def cleanup(self):
        print(f"Total cost: ${self.llm.total_cost:.4f}", file=__import__('sys').stderr)


if __name__ == "__main__":
    run(LLMAgent())
