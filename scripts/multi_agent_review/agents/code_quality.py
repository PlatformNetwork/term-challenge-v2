"""Code Quality Reviewer Agent - Checks readability and structure."""

import re
from typing import Dict, List

from .base import CodeAnalysis, ReviewAgent, ReviewMessage, ReviewVerdict


class CodeQualityReviewer(ReviewAgent):
    """Agent specialized in code quality, readability, and structure."""

    # Common single-letter variables that are acceptable
    ACCEPTABLE_SINGLE_VARS = {"i", "j", "k", "x", "y", "n", "m", "f", "e", "_"}

    def __init__(self, llm_client=None):
        """Initialize the Code Quality Reviewer agent."""
        super().__init__(
            name="CodeQualityReviewer",
            role="Code Quality & Readability Specialist",
            llm_client=llm_client,
        )

    def analyze_code(self, code: str, filename: str = "agent.py") -> CodeAnalysis:
        """
        Analyze code quality and readability.

        Args:
            code: The source code to analyze.
            filename: Name of the file being analyzed.

        Returns:
            CodeAnalysis with quality findings.
        """
        issues: List[str] = []
        warnings: List[str] = []
        positives: List[str] = []

        lines = code.split("\n")

        # === READABILITY CHECKS ===

        # Check for docstrings
        has_module_docstring = code.strip().startswith('"""') or code.strip().startswith(
            "'''"
        )
        if has_module_docstring:
            positives.append("Has module-level docstring")
        else:
            warnings.append("Missing module-level docstring")

        # Check for function/class docstrings
        func_pattern = r"def\s+(\w+)\s*\([^)]*\)\s*:"
        class_pattern = r"class\s+(\w+)"

        functions = re.findall(func_pattern, code)
        classes = re.findall(class_pattern, code)

        # Count documented functions
        docstring_after_def = len(re.findall(r'def\s+\w+[^:]+:\s*\n\s*["\']', code))
        if functions:
            doc_ratio = docstring_after_def / len(functions)
            if doc_ratio >= 0.8:
                positives.append(
                    f"Well-documented: {doc_ratio:.0%} of functions have docstrings"
                )
            elif doc_ratio < 0.3:
                warnings.append(
                    f"Poor documentation: only {doc_ratio:.0%} of functions documented"
                )

        # Check variable naming
        single_vars = set(re.findall(r"\b([a-z])\s*=", code)) - self.ACCEPTABLE_SINGLE_VARS
        if len(single_vars) > 5:
            warnings.append(f"Many unclear single-letter variables: {single_vars}")

        # Check for meaningful function names
        bad_func_names = [
            f for f in functions if len(f) < 3 or (f.startswith("f") and f[1:].isdigit())
        ]
        if bad_func_names:
            warnings.append(f"Unclear function names: {bad_func_names}")

        # === STRUCTURE CHECKS ===

        # Check line length
        long_lines = [(i + 1, len(l)) for i, l in enumerate(lines) if len(l) > 120]
        if long_lines:
            warnings.append(f"{len(long_lines)} lines exceed 120 characters")

        # Check nesting depth (rough estimate)
        max_indent = 0
        if lines:
            for line in lines:
                if line.strip():
                    indent = (len(line) - len(line.lstrip())) // 4
                    max_indent = max(max_indent, indent)
        if max_indent > 6:
            warnings.append(
                f"Deep nesting detected (max {max_indent} levels) - consider refactoring"
            )

        # Check function length
        func_lines = self._calculate_function_lengths(lines)
        long_funcs = [f for f, length in func_lines.items() if length > 50]
        if long_funcs:
            warnings.append(f"Long functions (>50 lines): {long_funcs}")

        # === POSITIVE SIGNALS ===

        # Type hints
        type_hints = len(re.findall(r"def\s+\w+\([^)]*:\s*\w+", code))
        type_hints += len(re.findall(r"->\s*\w+", code))
        if type_hints > 5:
            positives.append(f"Good use of type hints ({type_hints} found)")

        # Constants (UPPER_CASE)
        constants = re.findall(r"^[A-Z_]{2,}\s*=", code, re.MULTILINE)
        if constants:
            positives.append(f"Uses named constants ({len(constants)} found)")

        # Error handling
        try_blocks = len(re.findall(r"\btry\s*:", code))
        if try_blocks > 0:
            positives.append(f"Has error handling ({try_blocks} try blocks)")

        # Code organization
        if classes:
            positives.append(f"Uses classes ({len(classes)} found)")

        # Check for main guard
        if "if __name__" in code:
            positives.append("Has __main__ guard")

        # === DETERMINE VERDICT ===

        # Calculate quality score
        quality_score = len(positives) * 2 - len(warnings) - len(issues) * 3

        if issues:
            verdict = ReviewVerdict.REJECT
            confidence = 0.85
        elif quality_score >= 5:
            verdict = ReviewVerdict.APPROVE
            confidence = min(0.9, 0.6 + quality_score * 0.05)
        elif quality_score >= 0:
            verdict = ReviewVerdict.NEEDS_DISCUSSION
            confidence = 0.6
        else:
            verdict = ReviewVerdict.REJECT
            confidence = 0.7

        return CodeAnalysis(
            issues=issues,
            warnings=warnings,
            positives=positives,
            verdict=verdict,
            confidence=confidence,
        )

    def _calculate_function_lengths(self, lines: List[str]) -> Dict[str, int]:
        """
        Calculate the length of each function in lines.

        Args:
            lines: List of code lines.

        Returns:
            Dictionary mapping function names to their line counts.
        """
        func_lines: Dict[str, int] = {}
        current_func = None
        func_start = 0

        for i, line in enumerate(lines):
            func_match = re.match(r"\s*def\s+(\w+)", line)
            if func_match:
                if current_func:
                    func_lines[current_func] = i - func_start
                current_func = func_match.group(1)
                func_start = i

        if current_func:
            func_lines[current_func] = len(lines) - func_start

        return func_lines

    def respond_to_discussion(
        self,
        code: str,
        conversation: List[ReviewMessage],
        my_analysis: CodeAnalysis,
    ) -> ReviewMessage:
        """
        Respond to discussion.

        Args:
            code: The source code being reviewed.
            conversation: List of messages in the discussion so far.
            my_analysis: This agent's initial analysis.

        Returns:
            A ReviewMessage with the agent's response.
        """
        other_messages = [m for m in conversation if m.agent_name != self.name]

        if not other_messages:
            content = self._format_initial_response(my_analysis)
            return self._create_message(content, my_analysis.verdict)

        last_msg = other_messages[-1]

        if self.llm_client:
            return self._llm_respond(code, conversation, my_analysis, last_msg)

        return self._rule_based_respond(my_analysis, last_msg)

    def _format_initial_response(self, analysis: CodeAnalysis) -> str:
        """
        Format initial analysis.

        Args:
            analysis: The code analysis results.

        Returns:
            Formatted message string.
        """
        parts = ["## Code Quality Analysis\n"]

        if analysis.issues:
            parts.append("**ðŸš¨ Critical Issues:**")
            for issue in analysis.issues:
                parts.append(f"- {issue}")
            parts.append("")

        if analysis.warnings:
            parts.append("**âš ï¸ Quality Concerns:**")
            for warning in analysis.warnings[:5]:  # Limit to top 5
                parts.append(f"- {warning}")
            if len(analysis.warnings) > 5:
                parts.append(f"- ... and {len(analysis.warnings) - 5} more")
            parts.append("")

        if analysis.positives:
            parts.append("**âœ… Quality Highlights:**")
            for positive in analysis.positives:
                parts.append(f"- {positive}")
            parts.append("")

        verdict_emoji = {
            ReviewVerdict.APPROVE: "âœ…",
            ReviewVerdict.REJECT: "âŒ",
            ReviewVerdict.NEEDS_DISCUSSION: "ðŸ¤”",
        }

        parts.append(
            f"**Verdict:** {verdict_emoji[analysis.verdict]} {analysis.verdict.value}"
        )
        parts.append(f"**Confidence:** {analysis.confidence:.0%}")

        return "\n".join(parts)

    def _rule_based_respond(
        self, analysis: CodeAnalysis, last_msg: ReviewMessage
    ) -> ReviewMessage:
        """
        Generate rule-based response.

        Args:
            analysis: This agent's analysis.
            last_msg: The last message from another agent.

        Returns:
            A ReviewMessage with the response.
        """
        # If security found critical issues, defer
        if (
            last_msg.agent_name == "SecurityAuditor"
            and last_msg.verdict == ReviewVerdict.REJECT
        ):
            content = (
                f"@{last_msg.agent_name} raises valid security concerns. "
                f"Code quality analysis is secondary when security is compromised. "
                f"I support rejection pending security fixes."
            )
            return self._create_message(content, ReviewVerdict.REJECT, last_msg.agent_name)

        # Share quality perspective
        quality_summary = f"{len(analysis.positives)} strengths, {len(analysis.warnings)} concerns"
        readability_status = (
            "readable and maintainable"
            if analysis.verdict == ReviewVerdict.APPROVE
            else "could use improvements"
        )
        content = (
            f"Regarding @{last_msg.agent_name}'s points - from a code quality perspective: "
            f"{quality_summary}. The code is {readability_status}."
        )

        return self._create_message(content, analysis.verdict, last_msg.agent_name)

    def _llm_respond(
        self,
        code: str,
        conversation: List[ReviewMessage],
        analysis: CodeAnalysis,
        last_msg: ReviewMessage,
    ) -> ReviewMessage:
        """
        Generate LLM-powered response.

        Args:
            code: The source code being reviewed.
            conversation: List of messages in the discussion.
            analysis: This agent's analysis.
            last_msg: The last message from another agent.

        Returns:
            A ReviewMessage with the LLM-generated response.
        """
        conv_text = "\n\n".join(
            [
                f"**{m.agent_name}** ({m.verdict.value if m.verdict else 'N/A'}):\n{m.content}"
                for m in conversation[-5:]
            ]
        )

        prompt = f"""You are the Code Quality Reviewer in a code review discussion.
Your analysis found:
- Warnings: {analysis.warnings}
- Positives: {analysis.positives}

Recent conversation:
{conv_text}

Last message was from {last_msg.agent_name}. Respond:
1. Address their specific points
2. Share relevant quality insights
3. Be constructive - focus on actionable feedback
4. End with your verdict: APPROVE, REJECT, or NEEDS_DISCUSSION

Keep response under 200 words."""

        try:
            response = self.llm_client.chat(
                [
                    {"role": "system", "content": self.get_system_prompt()},
                    {"role": "user", "content": prompt},
                ]
            )

            verdict = analysis.verdict
            response_text = response if isinstance(response, str) else str(response)
            if "APPROVE" in response_text.upper():
                verdict = ReviewVerdict.APPROVE
            elif "REJECT" in response_text.upper():
                verdict = ReviewVerdict.REJECT

            return self._create_message(response_text, verdict, last_msg.agent_name)
        except Exception:
            return self._rule_based_respond(analysis, last_msg)

    def get_system_prompt(self) -> str:
        """Get the system prompt for this agent's LLM."""
        return """You are a Code Quality Reviewer AI specialized in:
- Code readability and maintainability
- Clean code principles
- Python best practices and PEP8
- Code structure and organization

You review Python agents for clarity and quality.
Be constructive - provide actionable feedback.
Balance being thorough with being practical."""
