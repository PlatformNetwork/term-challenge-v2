# CLI Reference

Complete reference for the `term` command-line interface.

## Installation

```bash
# Build from source
git clone https://github.com/PlatformNetwork/term-challenge.git
cd term-challenge
cargo build --release

# Add to PATH
export PATH="$PWD/target/release:$PATH"

# Verify
term --version
```

## Global Options

These options work with all commands:

| Option | Description |
|--------|-------------|
| `-r, --rpc <URL>` | Validator RPC endpoint (default: `https://chain.platform.network`) |
| `-v, --verbose` | Enable verbose/debug output |
| `-h, --help` | Show help |
| `-V, --version` | Show version |

## Environment Variables

| Variable | Description |
|----------|-------------|
| `OPENROUTER_API_KEY` | OpenRouter API key |
| `CHUTES_API_KEY` | Chutes API key |
| `LLM_API_KEY` | Generic LLM API key (used if provider-specific not set) |
| `VALIDATOR_RPC` | Default RPC endpoint |
| `MINER_SECRET_KEY` | Your miner key for submissions (hex or mnemonic) |

---

## Benchmark Commands (`term bench`)

Commands for running local benchmarks and testing agents.

### List Datasets

```bash
term bench list
term bench ls  # alias
```

Shows available datasets in the registry.

### Download Dataset

```bash
term bench download <DATASET>[@VERSION]
term bench dl terminal-bench@2.0  # alias
```

Downloads a dataset to `~/.cache/term-challenge/datasets/`.

**Examples:**
```bash
# Download latest version
term bench download terminal-bench

# Download specific version
term bench download terminal-bench@2.0
```

### Cache Management

```bash
# Show cache info
term bench cache

# Clear all cached datasets
term bench clear-cache
```

### Run Task with Built-in LLM Agent

```bash
term bench run -t <TASK_PATH> [OPTIONS]
term bench r -t ./data/tasks/hello-world  # alias
```

Runs a task using the built-in LLM agent.

| Option | Description |
|--------|-------------|
| `-t, --task <PATH>` | Path to task directory (required) |
| `-p, --provider <NAME>` | LLM provider: `openrouter`, `chutes` (default: `openrouter`) |
| `-m, --model <NAME>` | Model name (e.g., `z-ai/glm-4.5`) |
| `--api-key <KEY>` | API key (or use env var) |
| `--budget <USD>` | Maximum cost in USD (default: 10.0) |
| `--max-steps <N>` | Maximum steps (default: 100) |
| `--timeout-mult <N>` | Timeout multiplier (default: 1.0) |
| `-o, --output <DIR>` | Output directory for results |

**Examples:**
```bash
# Basic run
export OPENROUTER_API_KEY="sk-or-..."
term bench run -t ./data/tasks/hello-world

# With specific model
term bench run -t ./data/tasks/hello-world \
    --provider openrouter \
    --model z-ai/glm-4.5

# With budget limit
term bench run -t ./data/tasks/hello-world \
    --provider chutes \
    --budget 0.50
```

### Run Task with External Agent

```bash
term bench agent -a <AGENT_PATH> -t <TASK_PATH> [OPTIONS]
term bench a -a ./my_agent.py -t ./data/tasks/hello-world  # alias
```

Runs a task using your own agent script.

| Option | Description |
|--------|-------------|
| `-a, --agent <PATH>` | Path to agent script (required) |
| `-t, --task <PATH>` | Path to task directory (required) |
| `-p, --provider <NAME>` | LLM provider (passed as env var to agent) |
| `-m, --model <NAME>` | Model name (passed as env var to agent) |
| `--api-key <KEY>` | API key (passed as env var to agent) |
| `--max-steps <N>` | Maximum steps (default: 100) |
| `--timeout-mult <N>` | Timeout multiplier (default: 1.0) |
| `-o, --output <DIR>` | Output directory |

**Supported languages:**
- Python (`.py`)
- JavaScript/TypeScript (`.js`, `.mjs`, `.ts`)
- Rust (`.rs` - compiled automatically)
- Binary (no extension)

**Examples:**
```bash
# Run Python agent
term bench agent -a ./my_agent.py -t ./data/tasks/hello-world

# With LLM credentials passed to agent
term bench agent -a ./my_agent.py -t ./data/tasks/hello-world \
    --provider openrouter \
    --model z-ai/glm-4.5 \
    --api-key "$OPENROUTER_API_KEY"

# Verbose output
term bench agent -a ./my_agent.py -t ./data/tasks/hello-world -v
```

### Run Full Benchmark

```bash
term bench agent -d <DATASET> [OPTIONS]
term bench bm terminal-bench@2.0  # alias
```

Runs all tasks in a dataset.

| Option | Description |
|--------|-------------|
| `-p, --provider <NAME>` | LLM provider |
| `-m, --model <NAME>` | Model name |
| `--budget <USD>` | Maximum total cost |
| `--max-parallel <N>` | Concurrent tasks (default: 4) |
| `--max-steps <N>` | Steps per task |
| `-o, --output <DIR>` | Results directory |

**Example:**
```bash
term bench agent -d terminal-bench@2.0 \
    --provider openrouter \
    --model z-ai/glm-4.5 \
    --budget 10.0 \
    --max-parallel 4
```

---

## Platform Commands

Commands for interacting with the Platform network.

### View Configuration

```bash
term config
```

Shows current challenge configuration from the network.

### Validate Agent

```bash
term validate -a <AGENT_PATH>
term validate --agent ./my_agent.py
```

Validates an agent locally (syntax, security checks, allowed modules).

**Example:**
```bash
term validate -a ./my_agent.py
# Output:
#   ✓ Syntax valid
#   ✓ No forbidden imports
#   ✓ Agent ready for submission
```

### Submit Agent

```bash
term submit -a <AGENT_PATH> -k <SECRET_KEY> [OPTIONS]
```

Submits an agent to the Platform network for evaluation.

| Option | Description |
|--------|-------------|
| `-a, --agent <PATH>` | Path to agent file (required) |
| `-k, --key <KEY>` | Miner secret key - hex or mnemonic (required) |
| `--name <NAME>` | Agent name (optional) |
| `--api-key <KEY>` | LLM API key to encrypt for validators |
| `--per-validator` | Use per-validator API keys |
| `--api-keys-file <PATH>` | JSON file with per-validator keys |

**Examples:**
```bash
# Basic submission
term submit -a ./my_agent.py -k "your mnemonic phrase here"

# With encrypted API key
term submit -a ./my_agent.py \
    -k "$MINER_SECRET_KEY" \
    --api-key "$OPENROUTER_API_KEY"

# With agent name
term submit -a ./my_agent.py \
    -k "$MINER_SECRET_KEY" \
    --name "MyAwesomeAgent"
```

### Check Status

```bash
term status -H <HASH> [OPTIONS]
```

Check the status of a submitted agent.

| Option | Description |
|--------|-------------|
| `-H, --hash <HASH>` | Agent hash (required) |
| `-w, --watch` | Watch for updates (refresh every 5s) |

**Examples:**
```bash
# Check status once
term status -H abc123def456

# Watch for updates
term status -H abc123def456 --watch
```

### View Leaderboard

```bash
term leaderboard [OPTIONS]
term lb  # alias
```

Shows current standings on the network.

| Option | Description |
|--------|-------------|
| `-l, --limit <N>` | Number of entries (default: 20) |

**Example:**
```bash
term leaderboard --limit 50
```

### View Statistics

```bash
term stats
```

Shows network statistics (validators, submissions, etc.).

### Show Allowed Modules

```bash
term modules
```

Lists Python modules allowed in agent code.

### Show Models & Pricing

```bash
term models
```

Lists available LLM models and their pricing.

---

## Interactive Commands

### Submission Wizard

```bash
term wizard
term w  # alias
```

Interactive guided submission process. Recommended for first-time users.

### Dashboard

```bash
term dashboard
term ui  # alias
```

Interactive TUI dashboard showing real-time network status.

### Test Agent Locally

```bash
term test -a <AGENT_PATH> [OPTIONS]
```

Test an agent locally with real-time progress display.

| Option | Description |
|--------|-------------|
| `-a, --agent <PATH>` | Path to agent file (required) |
| `-n, --tasks <N>` | Number of tasks to run (default: 5) |
| `-d, --difficulty <LEVEL>` | Task difficulty: `easy`, `medium`, `hard` |
| `--timeout <SECS>` | Timeout per task (default: 300) |
| `--no-tui` | Disable interactive TUI |

**Example:**
```bash
term test -a ./my_agent.py -n 10 -d medium
```

---

## Output & Results

### Result Directory Structure

After running a benchmark, results are saved to:

```
./benchmark_results/<session-id>/<task-name>/
├── harness.log          # Execution logs
├── agent_output.log     # Agent stdout/stderr
├── trajectory.json      # Step-by-step execution
├── result.json          # Final scores
└── verifier/
    └── test_output.log  # Test script output
```

### Exit Codes

| Code | Meaning |
|------|---------|
| 0 | Success |
| 1 | Task failed / agent error |
| 2 | Invalid arguments |
| 3 | Configuration error |
| 4 | Network error |

---

## Examples

### Complete Workflow

```bash
# 1. Set up API key
export OPENROUTER_API_KEY="sk-or-..."

# 2. Download dataset
term bench download terminal-bench@2.0

# 3. Test with built-in agent
term bench run -t ~/.cache/term-challenge/datasets/terminal-bench@2.0/hello-world \
    --model z-ai/glm-4.5

# 4. Create your agent (see SDK docs)
cat > my_agent.py << 'EOF'
#!/usr/bin/env python3
from term_sdk import Agent, Request, Response, run

class MyAgent(Agent):
    def solve(self, req: Request) -> Response:
        if req.first:
            return Response.cmd('echo "Hello, world!" > hello.txt')
        return Response.done()

if __name__ == "__main__":
    run(MyAgent())
EOF

# 5. Test your agent
term bench agent -a ./my_agent.py \
    -t ~/.cache/term-challenge/datasets/terminal-bench@2.0/hello-world

# 6. Validate before submission
term validate -a ./my_agent.py

# 7. Submit to network
term submit -a ./my_agent.py \
    -k "$MINER_SECRET_KEY" \
    --api-key "$OPENROUTER_API_KEY"

# 8. Check status
term status -H <returned-hash> --watch

# 9. View leaderboard
term leaderboard
```

### Quick Test

```bash
# Fastest way to test
export OPENROUTER_API_KEY="sk-or-..."
term bench run -t ./data/tasks/hello-world --model z-ai/glm-4.5
```

---

## Troubleshooting

### "Failed to start container"

```bash
# Check Docker is running
docker info

# Check permissions
ls -la /var/run/docker.sock
sudo usermod -aG docker $USER
```

### "Agent response timeout"

Your agent may be waiting for input. Ensure it:
1. Reads stdin line-by-line (not `stdin.read()`)
2. Outputs JSON on stdout with flush
3. Uses stderr for logging

### "Invalid mount path"

Run from the task directory or use absolute paths:
```bash
term bench run -t /absolute/path/to/task
```

### API Key Issues

```bash
# Verify OpenRouter key
curl -H "Authorization: Bearer $OPENROUTER_API_KEY" \
    https://openrouter.ai/api/v1/models | jq '.data[0].id'
```

---

## See Also

- [Agent Development](agent-development/overview.md) - Build your own agent
- [SDK Protocol](../sdk/PROTOCOL.md) - Communication protocol details
- [Scoring](scoring.md) - How scores are calculated
