//! Distributed Storage Manager for Term-Challenge
//!
//! Manages on-chain storage for:
//! - Agent submissions (permanent after consensus)
//! - Evaluation results (per validator)
//! - Execution logs (compressed, TTL-limited)
//! - Leaderboard (consensus-based)
//!
//! All data is replicated across validators with consensus validation.

use flate2::read::GzDecoder;
use flate2::write::GzEncoder;
use flate2::Compression;
use parking_lot::RwLock;
use platform_challenge_sdk::distributed_storage::{WriteRequest, WriteValidation};
use platform_challenge_sdk::{
    ChallengePartition, EntryType, StorageEntry, StorageSyncMessage, StoredAgent, StoredEvaluation,
    StoredLog, StoredSubmission, StoredTaskResult, MAX_ENTRY_SIZE, MAX_LOG_SIZE,
};
use platform_core::{ChallengeMessageType, ChallengeNetworkMessage, Hotkey, Keypair};
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use std::collections::HashMap;
use std::io::{Read, Write};
use std::sync::Arc;
use tracing::{debug, error, info, warn};

/// Challenge ID for term-bench
pub const TERM_BENCH_CHALLENGE_ID: &str = "term-bench";

/// Minimum stake to write to storage (100 TAO in RAO)
pub const MIN_WRITE_STAKE: u64 = 100_000_000_000;

/// Maximum consensus score deviation (10%)
pub const MAX_SCORE_DEVIATION: f64 = 0.10;

/// Minimum validators for consensus (2/3 + 1)
pub const MIN_CONSENSUS_VALIDATORS: usize = 2;

// ============================================================================
// DISTRIBUTED STORAGE MANAGER
// ============================================================================

/// Sled tree names
const TREE_PARTITION: &str = "partition";
const TREE_METADATA: &str = "metadata";
const KEY_PARTITION_STATE: &str = "partition_state";

/// Manages distributed storage for term-challenge
pub struct DistributedStore {
    /// Local partition (in-memory cache, backed by sled)
    partition: Arc<RwLock<ChallengePartition>>,
    /// Our validator keypair
    keypair: Arc<Keypair>,
    /// Our stake
    our_stake: Arc<RwLock<u64>>,
    /// Current block height
    current_block: Arc<RwLock<u64>>,
    /// Current epoch
    current_epoch: Arc<RwLock<u64>>,
    /// Total validators
    total_validators: Arc<RwLock<usize>>,
    /// Pending sync messages to broadcast
    pending_broadcasts: Arc<RwLock<Vec<ChallengeNetworkMessage>>>,
    /// Validator stakes (for consensus weighting)
    validator_stakes: Arc<RwLock<HashMap<String, u64>>>,
    /// Sled database for persistence (None = in-memory only)
    db: Option<sled::Db>,
}

impl DistributedStore {
    /// Create a new in-memory distributed store (no persistence)
    pub fn new(keypair: Arc<Keypair>, initial_stake: u64, block_height: u64) -> Self {
        Self {
            partition: Arc::new(RwLock::new(ChallengePartition::new(
                TERM_BENCH_CHALLENGE_ID.to_string(),
                block_height,
            ))),
            keypair,
            our_stake: Arc::new(RwLock::new(initial_stake)),
            current_block: Arc::new(RwLock::new(block_height)),
            current_epoch: Arc::new(RwLock::new(0)),
            total_validators: Arc::new(RwLock::new(1)),
            pending_broadcasts: Arc::new(RwLock::new(Vec::new())),
            validator_stakes: Arc::new(RwLock::new(HashMap::new())),
            db: None,
        }
    }

    /// Create a distributed store with sled persistence
    pub fn new_with_persistence(
        keypair: Arc<Keypair>,
        initial_stake: u64,
        block_height: u64,
        data_dir: std::path::PathBuf,
    ) -> Self {
        // Ensure directory exists
        if let Err(e) = std::fs::create_dir_all(&data_dir) {
            warn!("Failed to create data directory {:?}: {}", data_dir, e);
        }

        // Open sled database
        let db_path = data_dir.join("distributed_store.sled");
        let db = match sled::open(&db_path) {
            Ok(db) => {
                info!("Opened sled database at {:?}", db_path);
                Some(db)
            }
            Err(e) => {
                error!("Failed to open sled database: {}", e);
                None
            }
        };

        // Load existing partition from sled
        let partition = Self::load_partition_from_sled(db.as_ref(), block_height);
        let entry_count = partition.entries.len();

        if entry_count > 0 {
            info!(
                "Loaded {} entries from sled database at {:?}",
                entry_count, db_path
            );
        }

        Self {
            partition: Arc::new(RwLock::new(partition)),
            keypair,
            our_stake: Arc::new(RwLock::new(initial_stake)),
            current_block: Arc::new(RwLock::new(block_height)),
            current_epoch: Arc::new(RwLock::new(0)),
            total_validators: Arc::new(RwLock::new(1)),
            pending_broadcasts: Arc::new(RwLock::new(Vec::new())),
            validator_stakes: Arc::new(RwLock::new(HashMap::new())),
            db,
        }
    }

    /// Load partition from sled database
    fn load_partition_from_sled(db: Option<&sled::Db>, fallback_block: u64) -> ChallengePartition {
        let Some(db) = db else {
            return ChallengePartition::new(TERM_BENCH_CHALLENGE_ID.to_string(), fallback_block);
        };

        let tree = match db.open_tree(TREE_PARTITION) {
            Ok(t) => t,
            Err(e) => {
                warn!("Failed to open partition tree: {}", e);
                return ChallengePartition::new(
                    TERM_BENCH_CHALLENGE_ID.to_string(),
                    fallback_block,
                );
            }
        };

        // Load partition state (metadata like total_size, write_counts, etc.)
        let mut partition = match tree.get(KEY_PARTITION_STATE) {
            Ok(Some(bytes)) => match serde_json::from_slice::<ChallengePartition>(&bytes) {
                Ok(p) => p,
                Err(e) => {
                    warn!("Failed to deserialize partition state: {}", e);
                    ChallengePartition::new(TERM_BENCH_CHALLENGE_ID.to_string(), fallback_block)
                }
            },
            _ => ChallengePartition::new(TERM_BENCH_CHALLENGE_ID.to_string(), fallback_block),
        };

        // Load individual entries from sled (more efficient for large datasets)
        for item in tree.iter() {
            if let Ok((key, value)) = item {
                let key_str = String::from_utf8_lossy(&key);
                if key_str.starts_with("entry:") {
                    if let Ok(entry) = serde_json::from_slice::<StorageEntry>(&value) {
                        partition.entries.insert(entry.metadata.key.clone(), entry);
                    }
                }
            }
        }

        partition
    }

    /// Save partition to sled (called after writes)
    fn save_partition(&self) {
        let Some(db) = &self.db else {
            return; // No persistence configured
        };

        let tree = match db.open_tree(TREE_PARTITION) {
            Ok(t) => t,
            Err(e) => {
                warn!("Failed to open partition tree for save: {}", e);
                return;
            }
        };

        let partition = self.partition.read();

        // Save partition state (without entries - those are saved separately)
        let state_for_save = ChallengePartition {
            challenge_id: partition.challenge_id.clone(),
            entries: HashMap::new(), // Entries saved separately
            total_size: partition.total_size,
            write_counts: partition.write_counts.clone(),
            created_at_block: partition.created_at_block,
            last_modified_block: partition.last_modified_block,
        };

        if let Ok(bytes) = serde_json::to_vec(&state_for_save) {
            if let Err(e) = tree.insert(KEY_PARTITION_STATE, bytes) {
                warn!("Failed to save partition state: {}", e);
            }
        }

        // Save each entry separately for efficient incremental updates
        for (key, entry) in &partition.entries {
            let entry_key = format!("entry:{}", key);
            if let Ok(bytes) = serde_json::to_vec(entry) {
                if let Err(e) = tree.insert(entry_key.as_bytes(), bytes) {
                    warn!("Failed to save entry {}: {}", key, e);
                }
            }
        }

        // Flush to disk
        if let Err(e) = db.flush() {
            warn!("Failed to flush sled database: {}", e);
        }
    }

    /// Save single entry to sled (more efficient for single writes)
    fn save_entry(&self, entry: &StorageEntry) {
        let Some(db) = &self.db else {
            return;
        };

        let tree = match db.open_tree(TREE_PARTITION) {
            Ok(t) => t,
            Err(e) => {
                warn!("Failed to open partition tree: {}", e);
                return;
            }
        };

        let entry_key = format!("entry:{}", entry.metadata.key);
        if let Ok(bytes) = serde_json::to_vec(entry) {
            if let Err(e) = tree.insert(entry_key.as_bytes(), bytes) {
                warn!("Failed to save entry {}: {}", entry.metadata.key, e);
            }
        }

        // Update partition state
        let partition = self.partition.read();
        let state_for_save = ChallengePartition {
            challenge_id: partition.challenge_id.clone(),
            entries: HashMap::new(),
            total_size: partition.total_size,
            write_counts: partition.write_counts.clone(),
            created_at_block: partition.created_at_block,
            last_modified_block: partition.last_modified_block,
        };

        if let Ok(bytes) = serde_json::to_vec(&state_for_save) {
            let _ = tree.insert(KEY_PARTITION_STATE, bytes);
        }
    }

    /// Update current block
    pub fn set_block(&self, block: u64) {
        *self.current_block.write() = block;
    }

    /// Update current epoch
    pub fn set_epoch(&self, epoch: u64) {
        *self.current_epoch.write() = epoch;
    }

    /// Update our stake
    pub fn set_stake(&self, stake: u64) {
        *self.our_stake.write() = stake;
    }

    /// Update total validators
    pub fn set_total_validators(&self, count: usize) {
        *self.total_validators.write() = count;
    }

    /// Update validator stakes
    pub fn update_validator_stake(&self, hotkey: &str, stake: u64) {
        self.validator_stakes
            .write()
            .insert(hotkey.to_string(), stake);
    }

    /// Take pending broadcasts
    pub fn take_pending_broadcasts(&self) -> Vec<ChallengeNetworkMessage> {
        std::mem::take(&mut *self.pending_broadcasts.write())
    }

    // ========================================================================
    // SUBMISSION STORAGE
    // ========================================================================

    /// Store a new submission
    pub fn store_submission(&self, submission: StoredSubmission) -> Result<(), StoreError> {
        let key = format!("submission:{}", submission.submission_id);
        let value = serde_json::to_vec(&submission)
            .map_err(|e| StoreError::Serialization(e.to_string()))?;

        if value.len() > MAX_ENTRY_SIZE {
            return Err(StoreError::EntryTooLarge(value.len(), MAX_ENTRY_SIZE));
        }

        let block = *self.current_block.read();
        let epoch = *self.current_epoch.read();
        let stake = *self.our_stake.read();
        let validator = self.keypair.hotkey().to_hex();

        // Create and sign request
        let mut request = WriteRequest::new(
            TERM_BENCH_CHALLENGE_ID.to_string(),
            EntryType::Submission,
            key.clone(),
            value,
            validator.clone(),
            stake,
            block,
            epoch,
        );

        let sign_hash = request.compute_sign_hash();
        let signature = self.keypair.sign(&sign_hash).signature;
        request = request.sign(signature);

        // Validate and apply
        let validation = self
            .partition
            .read()
            .validate_write(&request, MIN_WRITE_STAKE);
        if !validation.is_accepted() {
            return Err(StoreError::ValidationFailed(format!("{:?}", validation)));
        }

        let entry = self.partition.write().apply_write(request);
        if let Some(entry) = entry {
            self.broadcast_write(&entry);
            self.save_entry(&entry);
            info!("Stored submission: {}", submission.submission_id);
        }

        Ok(())
    }

    /// Get submission by ID
    pub fn get_submission(&self, submission_id: &str) -> Option<StoredSubmission> {
        let key = format!("submission:{}", submission_id);
        self.partition
            .read()
            .get(&key)
            .and_then(|e| serde_json::from_slice(&e.value).ok())
    }

    /// Get all submissions for an epoch
    pub fn get_submissions_by_epoch(&self, epoch: u64) -> Vec<StoredSubmission> {
        self.partition
            .read()
            .get_by_type(EntryType::Submission)
            .iter()
            .filter_map(|e| {
                serde_json::from_slice::<StoredSubmission>(&e.value)
                    .ok()
                    .filter(|s| s.epoch == epoch)
            })
            .collect()
    }

    // ========================================================================
    // EVALUATION STORAGE
    // ========================================================================

    /// Store an evaluation result
    pub fn store_evaluation(&self, evaluation: StoredEvaluation) -> Result<(), StoreError> {
        // Key: evaluation:{agent_hash}:{validator}
        let key = format!(
            "evaluation:{}:{}",
            evaluation.agent_hash, evaluation.validator_hotkey
        );
        let value = serde_json::to_vec(&evaluation)
            .map_err(|e| StoreError::Serialization(e.to_string()))?;

        if value.len() > MAX_ENTRY_SIZE {
            return Err(StoreError::EntryTooLarge(value.len(), MAX_ENTRY_SIZE));
        }

        let block = *self.current_block.read();
        let epoch = *self.current_epoch.read();
        let stake = *self.our_stake.read();
        let validator = self.keypair.hotkey().to_hex();

        // Only our own validator can store our evaluations
        if evaluation.validator_hotkey != validator {
            return Err(StoreError::Unauthorized(
                "Cannot store evaluation for another validator".to_string(),
            ));
        }

        let mut request = WriteRequest::new(
            TERM_BENCH_CHALLENGE_ID.to_string(),
            EntryType::Evaluation,
            key.clone(),
            value,
            validator,
            stake,
            block,
            epoch,
        );

        let sign_hash = request.compute_sign_hash();
        let signature = self.keypair.sign(&sign_hash).signature;
        request = request.sign(signature);

        let validation = self
            .partition
            .read()
            .validate_write(&request, MIN_WRITE_STAKE);
        if !validation.is_accepted() {
            return Err(StoreError::ValidationFailed(format!("{:?}", validation)));
        }

        let entry = self.partition.write().apply_write(request);
        if let Some(entry) = entry {
            self.broadcast_write(&entry);
            self.save_entry(&entry);
            info!(
                "Stored evaluation for agent {} by {}",
                evaluation.agent_hash, evaluation.validator_hotkey
            );

            // Try to reach consensus
            self.try_finalize_agent(&evaluation.agent_hash);
        }

        Ok(())
    }

    /// Get evaluations for an agent
    pub fn get_evaluations(&self, agent_hash: &str) -> Vec<StoredEvaluation> {
        let prefix = format!("evaluation:{}:", agent_hash);
        self.partition
            .read()
            .entries
            .iter()
            .filter(|(k, _)| k.starts_with(&prefix))
            .filter_map(|(_, e)| serde_json::from_slice(&e.value).ok())
            .collect()
    }

    /// Get our evaluation for an agent
    pub fn get_our_evaluation(&self, agent_hash: &str) -> Option<StoredEvaluation> {
        let key = format!(
            "evaluation:{}:{}",
            agent_hash,
            self.keypair.hotkey().to_hex()
        );
        self.partition
            .read()
            .get(&key)
            .and_then(|e| serde_json::from_slice(&e.value).ok())
    }

    // ========================================================================
    // LOG STORAGE (Compressed)
    // ========================================================================

    /// Store execution log (compressed)
    pub fn store_log(
        &self,
        agent_hash: &str,
        task_id: Option<&str>,
        log_content: &str,
    ) -> Result<(), StoreError> {
        // Compress the log
        let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
        encoder
            .write_all(log_content.as_bytes())
            .map_err(|e| StoreError::Compression(e.to_string()))?;
        let compressed = encoder
            .finish()
            .map_err(|e| StoreError::Compression(e.to_string()))?;

        if compressed.len() > MAX_LOG_SIZE {
            return Err(StoreError::EntryTooLarge(compressed.len(), MAX_LOG_SIZE));
        }

        let validator = self.keypair.hotkey().to_hex();
        let block = *self.current_block.read();

        let stored_log = StoredLog {
            agent_hash: agent_hash.to_string(),
            validator_hotkey: validator.clone(),
            task_id: task_id.map(|s| s.to_string()),
            compressed_log: compressed.clone(),
            original_size: log_content.len(),
            block_height: block,
            timestamp: chrono::Utc::now().timestamp() as u64,
        };

        let key = format!(
            "log:{}:{}:{}",
            agent_hash,
            validator,
            task_id.unwrap_or("full")
        );
        let value = serde_json::to_vec(&stored_log)
            .map_err(|e| StoreError::Serialization(e.to_string()))?;

        let epoch = *self.current_epoch.read();
        let stake = *self.our_stake.read();

        let mut request = WriteRequest::new(
            TERM_BENCH_CHALLENGE_ID.to_string(),
            EntryType::Log,
            key,
            value,
            validator,
            stake,
            block,
            epoch,
        );

        let sign_hash = request.compute_sign_hash();
        let signature = self.keypair.sign(&sign_hash).signature;
        request = request.sign(signature);

        let validation = self
            .partition
            .read()
            .validate_write(&request, MIN_WRITE_STAKE);
        if !validation.is_accepted() {
            return Err(StoreError::ValidationFailed(format!("{:?}", validation)));
        }

        if let Some(entry) = self.partition.write().apply_write(request) {
            self.save_entry(&entry);
        }
        debug!(
            "Stored compressed log for agent {} ({} -> {} bytes)",
            agent_hash,
            log_content.len(),
            compressed.len()
        );

        Ok(())
    }

    /// Get log (decompressed)
    pub fn get_log(
        &self,
        agent_hash: &str,
        validator: &str,
        task_id: Option<&str>,
    ) -> Option<String> {
        let key = format!(
            "log:{}:{}:{}",
            agent_hash,
            validator,
            task_id.unwrap_or("full")
        );

        self.partition.read().get(&key).and_then(|e| {
            let stored: StoredLog = serde_json::from_slice(&e.value).ok()?;
            let mut decoder = GzDecoder::new(&stored.compressed_log[..]);
            let mut decompressed = String::new();
            decoder.read_to_string(&mut decompressed).ok()?;
            Some(decompressed)
        })
    }

    // ========================================================================
    // AGENT FINALIZATION (Consensus)
    // ========================================================================

    /// Try to finalize an agent with consensus
    fn try_finalize_agent(&self, agent_hash: &str) {
        let evaluations = self.get_evaluations(agent_hash);
        let total_validators = *self.total_validators.read();
        let min_required = (total_validators * 2) / 3 + 1;

        if evaluations.len() < MIN_CONSENSUS_VALIDATORS || evaluations.len() < min_required {
            debug!(
                "Not enough evaluations for consensus: {}/{}",
                evaluations.len(),
                min_required
            );
            return;
        }

        // Calculate consensus score
        let scores: Vec<f64> = evaluations.iter().map(|e| e.score).collect();
        let median = Self::median(&scores);

        // Check if scores are within tolerance
        let agreeing: Vec<&StoredEvaluation> = evaluations
            .iter()
            .filter(|e| (e.score - median).abs() <= MAX_SCORE_DEVIATION)
            .collect();

        if agreeing.len() < min_required {
            warn!(
                "Consensus not reached for agent {}: only {}/{} validators agree",
                agent_hash,
                agreeing.len(),
                min_required
            );
            return;
        }

        // Calculate stake-weighted average
        let consensus_score = self.stake_weighted_average(&agreeing);

        // Get submission to retrieve source code
        let source_code = self.find_submission_source(agent_hash);
        let miner_hotkey = self.find_miner_hotkey(agent_hash);

        let block = *self.current_block.read();
        let epoch = *self.current_epoch.read();

        let agent = StoredAgent {
            agent_hash: agent_hash.to_string(),
            miner_hotkey: miner_hotkey.unwrap_or_default(),
            source_code: source_code.unwrap_or_default(),
            consensus_score,
            evaluation_count: agreeing.len() as u32,
            evaluated_by: agreeing
                .iter()
                .map(|e| e.validator_hotkey.clone())
                .collect(),
            best_rank: None,
            first_epoch: evaluations.iter().map(|e| e.epoch).min().unwrap_or(epoch),
            last_epoch: epoch,
            created_at_block: evaluations
                .iter()
                .map(|e| e.evaluated_at_block)
                .min()
                .unwrap_or(block),
            updated_at_block: block,
        };

        // Store finalized agent
        if let Err(e) = self.store_finalized_agent(agent) {
            error!("Failed to store finalized agent: {}", e);
        } else {
            info!(
                "Agent {} finalized with consensus score {:.4} ({} validators)",
                agent_hash,
                consensus_score,
                agreeing.len()
            );
        }
    }

    /// Store finalized agent
    fn store_finalized_agent(&self, agent: StoredAgent) -> Result<(), StoreError> {
        let key = format!("agent:{}", agent.agent_hash);
        let value =
            serde_json::to_vec(&agent).map_err(|e| StoreError::Serialization(e.to_string()))?;

        let block = *self.current_block.read();
        let epoch = *self.current_epoch.read();
        let stake = *self.our_stake.read();
        let validator = self.keypair.hotkey().to_hex();

        let mut request = WriteRequest::new(
            TERM_BENCH_CHALLENGE_ID.to_string(),
            EntryType::Agent,
            key,
            value,
            validator,
            stake,
            block,
            epoch,
        );

        let sign_hash = request.compute_sign_hash();
        let signature = self.keypair.sign(&sign_hash).signature;
        request = request.sign(signature);

        let validation = self
            .partition
            .read()
            .validate_write(&request, MIN_WRITE_STAKE);
        if !validation.is_accepted() {
            return Err(StoreError::ValidationFailed(format!("{:?}", validation)));
        }

        let entry = self.partition.write().apply_write(request);
        if let Some(entry) = entry {
            self.broadcast_write(&entry);
            self.save_entry(&entry);
        }

        Ok(())
    }

    /// Get finalized agent
    pub fn get_agent(&self, agent_hash: &str) -> Option<StoredAgent> {
        let key = format!("agent:{}", agent_hash);
        self.partition
            .read()
            .get(&key)
            .and_then(|e| serde_json::from_slice(&e.value).ok())
    }

    /// Get all finalized agents
    pub fn get_all_agents(&self) -> Vec<StoredAgent> {
        self.partition
            .read()
            .get_by_type(EntryType::Agent)
            .iter()
            .filter_map(|e| serde_json::from_slice(&e.value).ok())
            .collect()
    }

    /// Get leaderboard (sorted by score)
    pub fn get_leaderboard(&self, limit: usize) -> Vec<StoredAgent> {
        let mut agents = self.get_all_agents();
        agents.sort_by(|a, b| b.consensus_score.partial_cmp(&a.consensus_score).unwrap());
        agents.truncate(limit);
        agents
    }

    // ========================================================================
    // P2P SYNC
    // ========================================================================

    /// Handle received storage message
    pub fn handle_storage_message(&self, msg: StorageSyncMessage) {
        match msg {
            StorageSyncMessage::WriteAnnounce {
                challenge_id,
                entry_key,
                entry_hash,
                entry_type,
                block_height,
                validator,
            } => {
                if challenge_id != TERM_BENCH_CHALLENGE_ID {
                    return;
                }

                // Check if we already have this entry
                if let Some(existing) = self.partition.read().get(&entry_key) {
                    if existing.metadata.value_hash == entry_hash {
                        return; // Already have it
                    }
                }

                // Request the entry
                let request = StorageSyncMessage::RequestEntry {
                    challenge_id,
                    entry_key,
                };
                self.queue_sync_message(request);
            }
            StorageSyncMessage::RequestEntry {
                challenge_id,
                entry_key,
            } => {
                if challenge_id != TERM_BENCH_CHALLENGE_ID {
                    return;
                }

                let entry = self.partition.read().get(&entry_key).cloned();
                let response = StorageSyncMessage::EntryResponse {
                    challenge_id,
                    entry,
                };
                self.queue_sync_message(response);
            }
            StorageSyncMessage::EntryResponse {
                challenge_id,
                entry,
            } => {
                if challenge_id != TERM_BENCH_CHALLENGE_ID {
                    return;
                }

                if let Some(entry) = entry {
                    self.apply_received_entry(entry);
                }
            }
            StorageSyncMessage::RequestPartitionHash { challenge_id } => {
                if challenge_id != TERM_BENCH_CHALLENGE_ID {
                    return;
                }

                let partition = self.partition.read();
                let response = StorageSyncMessage::PartitionHashResponse {
                    challenge_id,
                    entries_hash: self.compute_partition_hash(),
                    entry_count: partition.entries.len(),
                    total_size: partition.total_size,
                };
                self.queue_sync_message(response);
            }
            StorageSyncMessage::RequestFullSync {
                challenge_id,
                from_block,
            } => {
                if challenge_id != TERM_BENCH_CHALLENGE_ID {
                    return;
                }

                // Send entries in batches
                let entries: Vec<StorageEntry> = self
                    .partition
                    .read()
                    .entries
                    .values()
                    .filter(|e| e.metadata.created_at_block >= from_block)
                    .take(100) // Limit batch size
                    .cloned()
                    .collect();

                let has_more = self
                    .partition
                    .read()
                    .entries
                    .values()
                    .filter(|e| e.metadata.created_at_block >= from_block)
                    .count()
                    > 100;

                let next_key = if has_more {
                    entries.last().map(|e| e.metadata.key.clone())
                } else {
                    None
                };

                let response = StorageSyncMessage::FullSyncResponse {
                    challenge_id,
                    entries,
                    has_more,
                    next_key,
                };
                self.queue_sync_message(response);
            }
            StorageSyncMessage::FullSyncResponse {
                challenge_id,
                entries,
                has_more,
                next_key,
            } => {
                if challenge_id != TERM_BENCH_CHALLENGE_ID {
                    return;
                }

                for entry in entries {
                    self.apply_received_entry(entry);
                }

                if has_more {
                    // Request more
                    let from_block = next_key
                        .and_then(|k| {
                            self.partition
                                .read()
                                .get(&k)
                                .map(|e| e.metadata.created_at_block)
                        })
                        .unwrap_or(0);

                    let request = StorageSyncMessage::RequestFullSync {
                        challenge_id,
                        from_block,
                    };
                    self.queue_sync_message(request);
                }
            }
            _ => {}
        }
    }

    /// Apply a received entry (validate and store)
    fn apply_received_entry(&self, entry: StorageEntry) {
        // Verify integrity
        if !entry.verify_integrity() {
            warn!(
                "Received entry with invalid integrity: {}",
                entry.metadata.key
            );
            return;
        }

        // Check if we should accept it (conflict resolution: newer wins, or higher stake)
        if let Some(existing) = self.partition.read().get(&entry.metadata.key) {
            // If same version and hash, skip
            if existing.metadata.value_hash == entry.metadata.value_hash {
                return;
            }

            // Newer version wins
            if existing.metadata.version >= entry.metadata.version {
                return;
            }
        }

        // Store it
        let key = entry.metadata.key.clone();
        let entry_clone = entry.clone();
        {
            let mut partition = self.partition.write();
            partition.total_size += entry.metadata.size;
            if let Some(old) = partition.entries.get(&key) {
                partition.total_size -= old.metadata.size;
            }
            partition.entries.insert(key.clone(), entry);
            partition.last_modified_block = *self.current_block.read();
        }
        self.save_entry(&entry_clone);

        debug!("Applied received entry: {}", key);
    }

    /// Broadcast a write to other validators
    fn broadcast_write(&self, entry: &StorageEntry) {
        let announce = StorageSyncMessage::announce_write(entry, TERM_BENCH_CHALLENGE_ID);
        self.queue_sync_message(announce);
    }

    /// Queue a sync message for broadcast
    fn queue_sync_message(&self, msg: StorageSyncMessage) {
        let payload = serde_json::to_vec(&msg).unwrap_or_default();
        let network_msg = ChallengeNetworkMessage {
            challenge_id: TERM_BENCH_CHALLENGE_ID.to_string(),
            payload,
            message_type: match msg {
                StorageSyncMessage::WriteAnnounce { .. } => ChallengeMessageType::StorageWrite,
                StorageSyncMessage::RequestEntry { .. } => ChallengeMessageType::StorageRequest,
                StorageSyncMessage::EntryResponse { .. } => ChallengeMessageType::StorageResponse,
                _ => ChallengeMessageType::StorageSync,
            },
        };
        self.pending_broadcasts.write().push(network_msg);
    }

    // ========================================================================
    // HELPERS
    // ========================================================================

    fn median(values: &[f64]) -> f64 {
        if values.is_empty() {
            return 0.0;
        }
        let mut sorted = values.to_vec();
        sorted.sort_by(|a, b| a.partial_cmp(b).unwrap());
        sorted[sorted.len() / 2]
    }

    fn stake_weighted_average(&self, evaluations: &[&StoredEvaluation]) -> f64 {
        let stakes = self.validator_stakes.read();
        let mut total_stake = 0u64;
        let mut weighted_sum = 0.0;

        for eval in evaluations {
            let stake = stakes.get(&eval.validator_hotkey).copied().unwrap_or(1);
            weighted_sum += eval.score * (stake as f64);
            total_stake += stake;
        }

        if total_stake == 0 {
            evaluations.iter().map(|e| e.score).sum::<f64>() / evaluations.len() as f64
        } else {
            weighted_sum / (total_stake as f64)
        }
    }

    fn find_submission_source(&self, agent_hash: &str) -> Option<String> {
        // Search submissions for this agent hash
        self.partition
            .read()
            .get_by_type(EntryType::Submission)
            .iter()
            .filter_map(|e| serde_json::from_slice::<StoredSubmission>(&e.value).ok())
            .find(|s| s.agent_hash == agent_hash && s.revealed)
            .and_then(|s| s.source_code)
    }

    fn find_miner_hotkey(&self, agent_hash: &str) -> Option<String> {
        self.partition
            .read()
            .get_by_type(EntryType::Submission)
            .iter()
            .filter_map(|e| serde_json::from_slice::<StoredSubmission>(&e.value).ok())
            .find(|s| s.agent_hash == agent_hash)
            .map(|s| s.miner_hotkey)
    }

    fn compute_partition_hash(&self) -> [u8; 32] {
        let mut hasher = Sha256::new();
        let partition = self.partition.read();

        // Sort keys for deterministic hash
        let mut keys: Vec<&String> = partition.entries.keys().collect();
        keys.sort();

        for key in keys {
            if let Some(entry) = partition.entries.get(key) {
                hasher.update(key.as_bytes());
                hasher.update(entry.metadata.value_hash);
            }
        }

        hasher.finalize().into()
    }

    /// Cleanup expired entries
    pub fn cleanup(&self) -> usize {
        let block = *self.current_block.read();
        let removed = self.partition.write().cleanup_expired(block);
        if removed > 0 {
            self.save_partition();
        }
        removed
    }

    /// Get partition stats
    pub fn stats(&self) -> platform_challenge_sdk::PartitionStats {
        self.partition.read().stats()
    }
}

// ============================================================================
// ERRORS
// ============================================================================

#[derive(Debug, Clone)]
pub enum StoreError {
    Serialization(String),
    EntryTooLarge(usize, usize),
    ValidationFailed(String),
    Unauthorized(String),
    Compression(String),
    NotFound(String),
}

impl std::fmt::Display for StoreError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            StoreError::Serialization(e) => write!(f, "Serialization error: {}", e),
            StoreError::EntryTooLarge(size, max) => {
                write!(f, "Entry too large: {} bytes (max {})", size, max)
            }
            StoreError::ValidationFailed(e) => write!(f, "Validation failed: {}", e),
            StoreError::Unauthorized(e) => write!(f, "Unauthorized: {}", e),
            StoreError::Compression(e) => write!(f, "Compression error: {}", e),
            StoreError::NotFound(e) => write!(f, "Not found: {}", e),
        }
    }
}

impl std::error::Error for StoreError {}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_store() -> DistributedStore {
        let keypair = Arc::new(Keypair::generate());
        DistributedStore::new(keypair, 1_000_000_000_000, 0)
    }

    #[test]
    fn test_store_submission() {
        let store = create_test_store();

        let submission = StoredSubmission {
            submission_id: "sub1".to_string(),
            agent_hash: "agent1".to_string(),
            miner_hotkey: "miner1".to_string(),
            content_hash: [0u8; 32],
            encrypted_source: None,
            source_code: Some("print('hello')".to_string()),
            source_size: 14,
            epoch: 1,
            submitted_at_block: 100,
            submitted_at: 0,
            revealed: true,
            signature: vec![],
        };

        let result = store.store_submission(submission.clone());
        assert!(result.is_ok());

        let retrieved = store.get_submission("sub1");
        assert!(retrieved.is_some());
        assert_eq!(retrieved.unwrap().agent_hash, "agent1");
    }

    #[test]
    fn test_store_log_compression() {
        let store = create_test_store();

        let log_content = "a".repeat(10000); // 10KB of 'a's
        let result = store.store_log("agent1", Some("task1"), &log_content);
        assert!(result.is_ok());

        let retrieved = store.get_log("agent1", &store.keypair.hotkey().to_hex(), Some("task1"));
        assert!(retrieved.is_some());
        assert_eq!(retrieved.unwrap(), log_content);
    }

    #[test]
    fn test_consensus() {
        let store = create_test_store();
        store.set_total_validators(3);

        // Add 3 evaluations with similar scores
        for i in 0..3 {
            let eval = StoredEvaluation {
                agent_hash: "agent1".to_string(),
                validator_hotkey: format!("validator{}", i),
                epoch: 1,
                score: 0.85 + (i as f64) * 0.02, // 0.85, 0.87, 0.89
                total_tasks: 10,
                passed_tasks: 8,
                failed_tasks: 2,
                total_cost_usd: 0.1,
                task_results: vec![],
                evaluated_at_block: 100,
                evaluated_at: 0,
                results_hash: [0u8; 32],
                signature: vec![],
            };

            // Simulate receiving from network
            let key = format!("evaluation:{}:{}", eval.agent_hash, eval.validator_hotkey);
            let value = serde_json::to_vec(&eval).unwrap();
            let entry = StorageEntry::new(
                EntryType::Evaluation,
                key,
                value,
                eval.validator_hotkey.clone(),
                100,
                None,
            );
            store.apply_received_entry(entry);
        }

        // Trigger consensus check
        store.try_finalize_agent("agent1");

        // Should have finalized agent
        let agent = store.get_agent("agent1");
        assert!(agent.is_some());
        let agent = agent.unwrap();
        assert!(agent.consensus_score > 0.8);
        assert_eq!(agent.evaluation_count, 3);
    }
}
