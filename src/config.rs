//! Challenge Configuration
//!
//! Defines the configuration for the terminal benchmark challenge including:
//! - Module whitelist (Python modules allowed)
//! - Model whitelist (LLM models allowed)
//! - Pricing limits per task
//! - Execution constraints

use serde::{Deserialize, Serialize};
use std::collections::HashSet;

/// Complete challenge configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChallengeConfig {
    /// Python module whitelist
    pub module_whitelist: ModuleWhitelist,
    /// LLM model whitelist
    pub model_whitelist: ModelWhitelist,
    /// Pricing configuration
    pub pricing: PricingConfig,
    /// Execution configuration
    pub execution: ExecutionConfig,
    /// Evaluation configuration
    pub evaluation: EvaluationConfig,
    /// Minimum stake required for miners (in TAO)
    pub min_stake_tao: u64,
}

impl Default for ChallengeConfig {
    fn default() -> Self {
        Self {
            module_whitelist: ModuleWhitelist::default(),
            model_whitelist: ModelWhitelist::default(),
            pricing: PricingConfig::default(),
            execution: ExecutionConfig::default(),
            evaluation: EvaluationConfig::default(),
            min_stake_tao: 1000, // 1000 TAO minimum
        }
    }
}

/// Python module whitelist configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModuleWhitelist {
    /// Allowed standard library modules
    pub allowed_stdlib: HashSet<String>,
    /// Allowed third-party modules
    pub allowed_third_party: HashSet<String>,
    /// Explicitly forbidden modules (override allowed)
    pub forbidden: HashSet<String>,
    /// Allow all stdlib (except forbidden)
    pub allow_all_stdlib: bool,
}

impl Default for ModuleWhitelist {
    fn default() -> Self {
        let mut allowed_stdlib = HashSet::new();
        for m in &[
            "json",
            "re",
            "math",
            "random",
            "collections",
            "itertools",
            "functools",
            "operator",
            "string",
            "textwrap",
            "datetime",
            "time",
            "copy",
            "typing",
            "dataclasses",
            "enum",
            "abc",
            "contextlib",
            "hashlib",
            "base64",
            "uuid",
            "pathlib",
            "argparse",
            "logging",
            "io",
            "csv",
            "html",
            "xml",
        ] {
            allowed_stdlib.insert(m.to_string());
        }

        let mut allowed_third_party = HashSet::new();
        for m in &[
            "numpy",
            "pandas",
            "requests",
            "httpx",
            "aiohttp",
            "pydantic",
            "openai",
            "anthropic",
            "transformers",
            "torch",
            "tiktoken",
            "tenacity",
            "rich",
            "tqdm",
        ] {
            allowed_third_party.insert(m.to_string());
        }

        let mut forbidden = HashSet::new();
        for m in &["subprocess", "os", "sys", "socket", "ctypes", "pickle"] {
            forbidden.insert(m.to_string());
        }

        Self {
            allowed_stdlib,
            allowed_third_party,
            forbidden,
            allow_all_stdlib: false,
        }
    }
}

impl ModuleWhitelist {
    /// Check if a module is allowed
    pub fn is_allowed(&self, module: &str) -> bool {
        if self.forbidden.contains(module) {
            return false;
        }
        self.allowed_stdlib.contains(module) || self.allowed_third_party.contains(module)
    }
}

/// LLM Model whitelist configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelWhitelist {
    /// Allowed OpenAI models
    pub openai_models: HashSet<String>,
    /// Allowed Anthropic models
    pub anthropic_models: HashSet<String>,
    /// Allowed local/other models
    pub other_models: HashSet<String>,
    /// Maximum context length allowed
    pub max_context_length: usize,
    /// Allow any model (no restrictions)
    pub allow_any: bool,
}

impl Default for ModelWhitelist {
    fn default() -> Self {
        let mut openai_models = HashSet::new();
        for m in &[
            "gpt-4o",
            "gpt-4o-mini",
            "gpt-4-turbo",
            "gpt-4",
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-16k",
            "o1",
            "o1-mini",
            "o1-preview",
        ] {
            openai_models.insert(m.to_string());
        }

        let mut anthropic_models = HashSet::new();
        for m in &[
            "claude-3-5-sonnet-20241022",
            "claude-3-5-haiku-20241022",
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307",
        ] {
            anthropic_models.insert(m.to_string());
        }

        Self {
            openai_models,
            anthropic_models,
            other_models: HashSet::new(),
            max_context_length: 128_000,
            allow_any: false,
        }
    }
}

impl ModelWhitelist {
    /// Check if a model is allowed
    pub fn is_allowed(&self, model: &str) -> bool {
        if self.allow_any {
            return true;
        }
        self.openai_models.contains(model)
            || self.anthropic_models.contains(model)
            || self.other_models.contains(model)
    }
}

/// Pricing configuration per task
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PricingConfig {
    /// Maximum cost per task in USD
    pub max_cost_per_task_usd: f64,
    /// Maximum total cost per evaluation in USD
    pub max_total_cost_usd: f64,
    /// Cost tracking enabled
    pub track_costs: bool,
    /// Fail task if cost exceeded
    pub fail_on_cost_exceeded: bool,
    /// Price per 1K input tokens (by model)
    pub input_token_prices: std::collections::HashMap<String, f64>,
    /// Price per 1K output tokens (by model)
    pub output_token_prices: std::collections::HashMap<String, f64>,
}

impl Default for PricingConfig {
    fn default() -> Self {
        let mut input_prices = std::collections::HashMap::new();
        let mut output_prices = std::collections::HashMap::new();

        // OpenAI pricing (per 1K tokens)
        input_prices.insert("gpt-4o".to_string(), 0.0025);
        output_prices.insert("gpt-4o".to_string(), 0.01);
        input_prices.insert("gpt-4o-mini".to_string(), 0.00015);
        output_prices.insert("gpt-4o-mini".to_string(), 0.0006);
        input_prices.insert("gpt-4-turbo".to_string(), 0.01);
        output_prices.insert("gpt-4-turbo".to_string(), 0.03);
        input_prices.insert("o1".to_string(), 0.015);
        output_prices.insert("o1".to_string(), 0.06);

        // Anthropic pricing (per 1K tokens)
        input_prices.insert("claude-3-5-sonnet-20241022".to_string(), 0.003);
        output_prices.insert("claude-3-5-sonnet-20241022".to_string(), 0.015);
        input_prices.insert("claude-3-opus-20240229".to_string(), 0.015);
        output_prices.insert("claude-3-opus-20240229".to_string(), 0.075);

        Self {
            max_cost_per_task_usd: 0.50, // Max $0.50 per task
            max_total_cost_usd: 10.0,    // Max $10 total per evaluation
            track_costs: true,
            fail_on_cost_exceeded: true,
            input_token_prices: input_prices,
            output_token_prices: output_prices,
        }
    }
}

impl PricingConfig {
    /// Calculate cost for a model usage
    pub fn calculate_cost(&self, model: &str, input_tokens: usize, output_tokens: usize) -> f64 {
        let input_price = self.input_token_prices.get(model).copied().unwrap_or(0.01);
        let output_price = self.output_token_prices.get(model).copied().unwrap_or(0.03);

        let input_cost = (input_tokens as f64 / 1000.0) * input_price;
        let output_cost = (output_tokens as f64 / 1000.0) * output_price;

        input_cost + output_cost
    }
}

/// Execution configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionConfig {
    /// Maximum time per task in seconds
    pub max_task_timeout_secs: u64,
    /// Maximum total evaluation time in seconds
    pub max_total_timeout_secs: u64,
    /// Maximum memory per container in MB
    pub max_memory_mb: u64,
    /// Maximum CPU cores per container
    pub max_cpu_cores: f32,
    /// Network access allowed
    pub allow_network: bool,
    /// Maximum concurrent tasks
    pub max_concurrent_tasks: usize,
    /// Retry failed tasks
    pub retry_on_failure: bool,
    /// Maximum retries
    pub max_retries: u32,
}

impl Default for ExecutionConfig {
    fn default() -> Self {
        Self {
            max_task_timeout_secs: 300,   // 5 minutes per task
            max_total_timeout_secs: 3600, // 1 hour total
            max_memory_mb: 4096,          // 4GB
            max_cpu_cores: 2.0,
            allow_network: true, // Need network for LLM API calls
            max_concurrent_tasks: 4,
            retry_on_failure: true,
            max_retries: 2,
        }
    }
}

/// Evaluation configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvaluationConfig {
    /// Number of tasks per evaluation
    pub tasks_per_evaluation: usize,
    /// Randomize task order
    pub randomize_tasks: bool,
    /// Save intermediate results
    pub save_intermediate: bool,
    /// Real-time progress updates
    pub realtime_progress: bool,
    /// Progress update interval in seconds
    pub progress_interval_secs: u64,
}

impl Default for EvaluationConfig {
    fn default() -> Self {
        Self {
            tasks_per_evaluation: 10,
            randomize_tasks: true,
            save_intermediate: true,
            realtime_progress: true,
            progress_interval_secs: 5,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_module_whitelist() {
        let whitelist = ModuleWhitelist::default();

        assert!(whitelist.is_allowed("json"));
        assert!(whitelist.is_allowed("numpy"));
        assert!(!whitelist.is_allowed("subprocess"));
        assert!(!whitelist.is_allowed("os"));
    }

    #[test]
    fn test_model_whitelist() {
        let whitelist = ModelWhitelist::default();

        assert!(whitelist.is_allowed("gpt-4o"));
        assert!(whitelist.is_allowed("claude-3-5-sonnet-20241022"));
        assert!(!whitelist.is_allowed("unknown-model"));
    }

    #[test]
    fn test_pricing() {
        let pricing = PricingConfig::default();

        // 1000 input tokens + 500 output tokens with gpt-4o
        let cost = pricing.calculate_cost("gpt-4o", 1000, 500);
        assert!(cost > 0.0);
        assert!(cost < pricing.max_cost_per_task_usd);
    }
}
