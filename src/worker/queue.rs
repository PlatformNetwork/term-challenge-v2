//! Agent Evaluation Queue System — Stub
//!
//! DEPRECATED: Direct Docker evaluation has been removed.
//! Evaluation is now handled by SWE-Forge via Basilica.
//!
//! This module retains public types for backwards compatibility.

use anyhow::Result;
use indexmap::IndexMap;
use parking_lot::RwLock;
use serde::{Deserialize, Serialize};
use std::collections::{BinaryHeap, HashMap};
use std::sync::atomic::{AtomicBool, AtomicU32, AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, Mutex, Semaphore};
use tracing::{info, warn};
use uuid::Uuid;

/// Maximum concurrent tasks across all agents
const MAX_GLOBAL_CONCURRENT_TASKS: usize = 16;

/// Minimum concurrent tasks per agent
const MIN_TASKS_PER_AGENT: usize = 4;

/// Maximum concurrent tasks per agent
const MAX_TASKS_PER_AGENT: usize = 8;

/// Maximum queue size
const MAX_QUEUE_SIZE: usize = 100;

/// Agent information for queue
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueueAgentInfo {
    /// Agent hash (unique identifier)
    pub hash: String,
    /// Agent Docker image
    pub image: String,
    /// Agent API endpoint (if applicable)
    pub endpoint: Option<String>,
    /// Source code
    pub source_code: Option<String>,
}

/// Agent evaluation request
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvalRequest {
    pub id: String,
    pub agent: QueueAgentInfo,
    pub miner_hotkey: String,
    pub miner_uid: u16,
    pub miner_stake: u64,
    pub epoch: u64,
    pub submitted_at: u64,
    pub dataset: String,
    pub max_tasks: Option<usize>,
}

impl EvalRequest {
    pub fn new(
        agent: QueueAgentInfo,
        miner_hotkey: String,
        miner_uid: u16,
        miner_stake: u64,
        epoch: u64,
    ) -> Self {
        Self {
            id: Uuid::new_v4().to_string(),
            agent,
            miner_hotkey,
            miner_uid,
            miner_stake,
            epoch,
            submitted_at: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
            dataset: "terminal-bench@2.0".to_string(),
            max_tasks: None,
        }
    }
}

/// Priority wrapper for heap ordering (higher stake = higher priority)
#[derive(Debug)]
struct PriorityRequest {
    request: EvalRequest,
}

impl PartialEq for PriorityRequest {
    fn eq(&self, other: &Self) -> bool {
        self.request.miner_stake == other.request.miner_stake
    }
}

impl Eq for PriorityRequest {}

impl PartialOrd for PriorityRequest {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for PriorityRequest {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        self.request.miner_stake.cmp(&other.request.miner_stake)
    }
}

/// Evaluation result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvalResult {
    pub request_id: String,
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub miner_uid: u16,
    pub epoch: u64,
    pub score: f64,
    pub tasks_passed: u32,
    pub tasks_total: u32,
    pub task_results: Vec<TaskEvalResult>,
    pub execution_time_ms: u64,
    pub error: Option<String>,
}

/// Individual task result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskEvalResult {
    pub task_name: String,
    pub passed: bool,
    pub score: f64,
    pub duration_ms: u64,
    pub steps: u32,
    pub error: Option<String>,
}

/// Queue statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueueStats {
    pub queued: usize,
    pub running: usize,
    pub completed: usize,
    pub failed: usize,
    pub active_containers: usize,
    pub active_tasks: usize,
    pub max_concurrent_tasks: usize,
}

/// Running evaluation tracking
#[derive(Debug)]
#[allow(dead_code)]
struct RunningEval {
    request: EvalRequest,
    started_at: Instant,
    tasks_completed: AtomicU32,
    tasks_total: u32,
}

/// Internal stats
struct QueueStatsInner {
    completed: AtomicUsize,
    failed: AtomicUsize,
}

/// Agent Evaluation Queue (stub — Docker evaluation removed)
pub struct AgentQueue {
    pending: Mutex<BinaryHeap<PriorityRequest>>,
    running: RwLock<HashMap<String, RunningEval>>,
    results: RwLock<IndexMap<String, EvalResult>>,
    result_tx: mpsc::UnboundedSender<EvalResult>,
    stats: QueueStatsInner,
    shutdown: AtomicBool,
    #[allow(dead_code)]
    task_semaphore: Arc<Semaphore>,
}

impl AgentQueue {
    /// Create a new agent queue (stub — always returns error)
    pub async fn new() -> Result<(Self, mpsc::UnboundedReceiver<EvalResult>)> {
        warn!("Agent queue deprecated — evaluation handled by Basilica");
        let (result_tx, result_rx) = mpsc::unbounded_channel();

        let queue = Self {
            pending: Mutex::new(BinaryHeap::new()),
            running: RwLock::new(HashMap::new()),
            results: RwLock::new(IndexMap::new()),
            result_tx,
            stats: QueueStatsInner {
                completed: AtomicUsize::new(0),
                failed: AtomicUsize::new(0),
            },
            shutdown: AtomicBool::new(false),
            task_semaphore: Arc::new(Semaphore::new(MAX_GLOBAL_CONCURRENT_TASKS)),
        };

        Ok((queue, result_rx))
    }

    /// Submit an agent for evaluation
    pub async fn submit(&self, request: EvalRequest) -> Result<String> {
        if self.shutdown.load(Ordering::SeqCst) {
            anyhow::bail!("Queue is shutting down");
        }

        let mut pending = self.pending.lock().await;

        if pending.len() >= MAX_QUEUE_SIZE {
            anyhow::bail!("Queue is full ({} pending)", MAX_QUEUE_SIZE);
        }

        let request_id = request.id.clone();
        warn!(
            "Agent {} queued but Docker evaluation is deprecated — use Basilica",
            request.agent.hash,
        );

        pending.push(PriorityRequest { request });

        Ok(request_id)
    }

    /// Get queue statistics
    pub fn stats(&self) -> QueueStats {
        let pending = self.pending.try_lock().map(|p| p.len()).unwrap_or(0);
        let running = self.running.read().len();

        QueueStats {
            queued: pending,
            running,
            completed: self.stats.completed.load(Ordering::Relaxed),
            failed: self.stats.failed.load(Ordering::Relaxed),
            active_containers: 0,
            active_tasks: 0,
            max_concurrent_tasks: MAX_GLOBAL_CONCURRENT_TASKS,
        }
    }

    /// Get result for a request
    pub fn get_result(&self, request_id: &str) -> Option<EvalResult> {
        self.results.read().get(request_id).cloned()
    }

    /// Start the queue processor (stub — logs deprecation and sleeps)
    pub async fn run(self: Arc<Self>) {
        warn!("Agent queue deprecated — evaluation handled by Basilica");

        loop {
            if self.shutdown.load(Ordering::SeqCst) {
                info!("Queue processor shutting down");
                break;
            }

            // Drain any pending requests with error
            {
                let mut pending = self.pending.lock().await;
                while let Some(priority_req) = pending.pop() {
                    let request = priority_req.request;
                    let result = EvalResult {
                        request_id: request.id.clone(),
                        agent_hash: request.agent.hash.clone(),
                        miner_hotkey: request.miner_hotkey.clone(),
                        miner_uid: request.miner_uid,
                        epoch: request.epoch,
                        score: 0.0,
                        tasks_passed: 0,
                        tasks_total: 0,
                        task_results: vec![],
                        execution_time_ms: 0,
                        error: Some(
                            "Docker evaluation removed — use SWE-Forge via Basilica".to_string(),
                        ),
                    };

                    self.results
                        .write()
                        .insert(request.id.clone(), result.clone());
                    self.stats.failed.fetch_add(1, Ordering::Relaxed);
                    let _ = self.result_tx.send(result);
                }
            }

            tokio::time::sleep(Duration::from_secs(10)).await;
        }
    }

    /// Graceful shutdown
    pub async fn shutdown(&self) {
        info!("Initiating queue shutdown...");
        self.shutdown.store(true, Ordering::SeqCst);
        info!("Queue shutdown complete");
    }
}

/// Queue configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueueConfig {
    pub max_global_concurrent: usize,
    pub min_per_agent: usize,
    pub max_per_agent: usize,
    pub max_queue_size: usize,
    pub default_dataset: String,
}

impl Default for QueueConfig {
    fn default() -> Self {
        Self {
            max_global_concurrent: MAX_GLOBAL_CONCURRENT_TASKS,
            min_per_agent: MIN_TASKS_PER_AGENT,
            max_per_agent: MAX_TASKS_PER_AGENT,
            max_queue_size: MAX_QUEUE_SIZE,
            default_dataset: "terminal-bench@2.0".to_string(),
        }
    }
}

#[cfg(test)]
#[allow(clippy::assertions_on_constants)]
mod tests {
    use super::*;

    fn create_test_eval_request(id: &str, stake: u64) -> EvalRequest {
        EvalRequest {
            id: id.to_string(),
            agent: QueueAgentInfo {
                hash: format!("hash_{}", id),
                image: "test-image:latest".to_string(),
                endpoint: None,
                source_code: Some("print('test')".to_string()),
            },
            miner_hotkey: format!("miner_{}", id),
            miner_uid: 1,
            miner_stake: stake,
            epoch: 10,
            submitted_at: 12345,
            dataset: "terminal-bench@2.0".to_string(),
            max_tasks: None,
        }
    }

    #[test]
    fn test_eval_request_new() {
        let agent = QueueAgentInfo {
            hash: "test_hash".to_string(),
            image: "test:latest".to_string(),
            endpoint: None,
            source_code: None,
        };

        let request = EvalRequest::new(agent, "miner1".to_string(), 1, 1000, 5);

        assert_eq!(request.miner_hotkey, "miner1");
        assert_eq!(request.miner_uid, 1);
        assert_eq!(request.miner_stake, 1000);
        assert_eq!(request.epoch, 5);
        assert!(!request.id.is_empty());
    }

    #[test]
    fn test_queue_config_default() {
        let config = QueueConfig::default();
        assert_eq!(config.max_global_concurrent, 16);
        assert_eq!(config.min_per_agent, 4);
        assert_eq!(config.max_per_agent, 8);
        assert_eq!(config.max_queue_size, 100);
        assert_eq!(config.default_dataset, "terminal-bench@2.0");
    }

    #[test]
    fn test_priority_ordering() {
        let low = PriorityRequest {
            request: create_test_eval_request("low", 100),
        };
        let high = PriorityRequest {
            request: create_test_eval_request("high", 1000),
        };

        assert!(high > low);
    }

    #[test]
    fn test_eval_result_serialization() {
        let result = EvalResult {
            request_id: "req1".to_string(),
            agent_hash: "hash1".to_string(),
            miner_hotkey: "miner1".to_string(),
            miner_uid: 1,
            epoch: 10,
            score: 0.75,
            tasks_passed: 3,
            tasks_total: 4,
            task_results: vec![],
            execution_time_ms: 5000,
            error: None,
        };

        let json = serde_json::to_string(&result).unwrap();
        let deserialized: EvalResult = serde_json::from_str(&json).unwrap();
        assert_eq!(deserialized.score, 0.75);
        assert_eq!(deserialized.tasks_passed, 3);
    }

    #[test]
    fn test_task_eval_result_serialization() {
        let result = TaskEvalResult {
            task_name: "test_task".to_string(),
            passed: true,
            score: 1.0,
            duration_ms: 1000,
            steps: 5,
            error: None,
        };

        let json = serde_json::to_string(&result).unwrap();
        let deserialized: TaskEvalResult = serde_json::from_str(&json).unwrap();
        assert!(deserialized.passed);
        assert_eq!(deserialized.task_name, "test_task");
    }

    #[test]
    fn test_queue_stats_serialization() {
        let stats = QueueStats {
            queued: 5,
            running: 2,
            completed: 10,
            failed: 1,
            active_containers: 3,
            active_tasks: 4,
            max_concurrent_tasks: 16,
        };

        let json = serde_json::to_string(&stats).unwrap();
        let deserialized: QueueStats = serde_json::from_str(&json).unwrap();
        assert_eq!(deserialized.queued, 5);
        assert_eq!(deserialized.max_concurrent_tasks, 16);
    }

    #[tokio::test]
    async fn test_queue_creation() {
        let (queue, _rx) = AgentQueue::new().await.unwrap();
        let stats = queue.stats();
        assert_eq!(stats.queued, 0);
        assert_eq!(stats.running, 0);
    }

    #[tokio::test]
    async fn test_queue_submit() {
        let (queue, _rx) = AgentQueue::new().await.unwrap();
        let request = create_test_eval_request("test1", 500);
        let id = queue.submit(request).await.unwrap();
        assert_eq!(id, "test1");
        assert_eq!(queue.stats().queued, 1);
    }
}
