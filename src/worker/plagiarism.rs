//! AST-based Plagiarism Detection Worker
//!
//! Detects code plagiarism by parsing Python source into ASTs, normalizing
//! (stripping names/comments, keeping structure), hashing subtrees, and
//! comparing against an index of existing agents.
//!
//! Pipeline: submit -> plagiarism_check -> llm_review -> compilation
//!
//! Verdicts:
//! - cleared: < flag_threshold (auto-proceeds to LLM review)
//! - flagged: >= flag_threshold, < reject_threshold (LLM review with plagiarism context)
//! - rejected: >= reject_threshold (auto-rejected, skips LLM review)

use crate::storage::pg::PgStorage;
use crate::validation::package::PackageValidator;
use anyhow::{Context, Result};
use md5::{Digest, Md5};
use rustpython_parser::ast::Ranged;
use rustpython_parser::{ast, Parse};
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use std::time::Duration;
use tokio::time::interval;
use tracing::{debug, error, info, warn};

const POLL_INTERVAL_SECS: u64 = 10;
const BATCH_SIZE: i64 = 5;

// ============================================================================
// Data Structures
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IndexEntry {
    pub agent_hash: String,
    pub file_path: String,
    pub node_type: String,
    pub line_start: u32,
    pub line_end: u32,
    pub subtree_size: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlagiarismMatch {
    pub pending_file: String,
    pub pending_lines: (u32, u32),
    pub matched_agent_hash: String,
    pub matched_file: String,
    pub matched_lines: (u32, u32),
    pub node_type: String,
    pub subtree_size: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlagiarismReport {
    pub total_nodes: u32,
    pub matched_nodes: u32,
    pub match_percent: f64,
    pub matches: Vec<PlagiarismMatch>,
    pub verdict: String,
}

#[derive(Debug, Clone)]
pub struct PlagiarismConfig {
    pub flag_threshold: f64,
    pub reject_threshold: f64,
    pub min_subtree_size: u32,
    pub index_top_n: i64,
    pub prompt_template: String,
}

impl Default for PlagiarismConfig {
    fn default() -> Self {
        Self {
            flag_threshold: 70.0,
            reject_threshold: 95.0,
            min_subtree_size: 10,
            index_top_n: 20,
            prompt_template: String::new(),
        }
    }
}

// ============================================================================
// AST Normalization
// ============================================================================

#[derive(Debug, Clone)]
struct NormalizedNode {
    node_type: String,
    structure_hash: String,
    size: u32,
    line_start: u32,
    line_end: u32,
    children: Vec<NormalizedNode>,
}

/// Converts byte offset to line number (1-based) in source code
fn offset_to_line(source: &str, offset: u32) -> u32 {
    let offset = offset as usize;
    if offset >= source.len() {
        return source.lines().count() as u32;
    }
    source[..offset].matches('\n').count() as u32 + 1
}

struct AstNormalizer<'a> {
    source: &'a str,
}

impl<'a> AstNormalizer<'a> {
    fn new(source: &'a str) -> Self {
        Self { source }
    }

    fn normalize_module(&self, stmts: &[ast::Stmt]) -> Vec<NormalizedNode> {
        stmts.iter().map(|s| self.normalize_stmt(s)).collect()
    }

    fn normalize_stmt(&self, stmt: &ast::Stmt) -> NormalizedNode {
        use ast::Stmt::*;
        match stmt {
            FunctionDef(f) => {
                let mut children: Vec<NormalizedNode> =
                    f.body.iter().map(|s| self.normalize_stmt(s)).collect();
                for d in &f.decorator_list {
                    children.push(self.normalize_expr(d));
                }
                if let Some(ref ret) = f.returns {
                    children.push(self.normalize_expr(ret));
                }
                self.make_node(
                    "FunctionDef",
                    &format!(
                        "args:{}|decorators:{}",
                        f.args.args.len(),
                        f.decorator_list.len()
                    ),
                    children,
                    f.range,
                )
            }
            AsyncFunctionDef(f) => {
                let mut children: Vec<NormalizedNode> =
                    f.body.iter().map(|s| self.normalize_stmt(s)).collect();
                for d in &f.decorator_list {
                    children.push(self.normalize_expr(d));
                }
                if let Some(ref ret) = f.returns {
                    children.push(self.normalize_expr(ret));
                }
                self.make_node(
                    "AsyncFunctionDef",
                    &format!(
                        "args:{}|decorators:{}",
                        f.args.args.len(),
                        f.decorator_list.len()
                    ),
                    children,
                    f.range,
                )
            }
            ClassDef(c) => {
                let mut children: Vec<NormalizedNode> =
                    c.body.iter().map(|s| self.normalize_stmt(s)).collect();
                for b in &c.bases {
                    children.push(self.normalize_expr(b));
                }
                for d in &c.decorator_list {
                    children.push(self.normalize_expr(d));
                }
                self.make_node(
                    "ClassDef",
                    &format!(
                        "bases:{}|decorators:{}",
                        c.bases.len(),
                        c.decorator_list.len()
                    ),
                    children,
                    c.range,
                )
            }
            Return(r) => {
                let children = r
                    .value
                    .as_ref()
                    .map(|v| vec![self.normalize_expr(v)])
                    .unwrap_or_default();
                self.make_node("Return", "", children, r.range)
            }
            Delete(d) => {
                let children = d.targets.iter().map(|e| self.normalize_expr(e)).collect();
                self.make_node("Delete", "", children, d.range)
            }
            Assign(a) => {
                let mut children: Vec<NormalizedNode> =
                    a.targets.iter().map(|e| self.normalize_expr(e)).collect();
                children.push(self.normalize_expr(&a.value));
                self.make_node("Assign", "", children, a.range)
            }
            AugAssign(a) => {
                let children = vec![
                    self.normalize_expr(&a.target),
                    self.normalize_expr(&a.value),
                ];
                self.make_node("AugAssign", &format!("op:{:?}", a.op), children, a.range)
            }
            AnnAssign(a) => {
                let mut children = vec![
                    self.normalize_expr(&a.target),
                    self.normalize_expr(&a.annotation),
                ];
                if let Some(ref v) = a.value {
                    children.push(self.normalize_expr(v));
                }
                self.make_node("AnnAssign", "", children, a.range)
            }
            For(f) => {
                let mut children =
                    vec![self.normalize_expr(&f.target), self.normalize_expr(&f.iter)];
                children.extend(f.body.iter().map(|s| self.normalize_stmt(s)));
                children.extend(f.orelse.iter().map(|s| self.normalize_stmt(s)));
                self.make_node(
                    "For",
                    &format!("has_else:{}", !f.orelse.is_empty()),
                    children,
                    f.range,
                )
            }
            AsyncFor(f) => {
                let mut children =
                    vec![self.normalize_expr(&f.target), self.normalize_expr(&f.iter)];
                children.extend(f.body.iter().map(|s| self.normalize_stmt(s)));
                children.extend(f.orelse.iter().map(|s| self.normalize_stmt(s)));
                self.make_node(
                    "AsyncFor",
                    &format!("has_else:{}", !f.orelse.is_empty()),
                    children,
                    f.range,
                )
            }
            While(w) => {
                let mut children = vec![self.normalize_expr(&w.test)];
                children.extend(w.body.iter().map(|s| self.normalize_stmt(s)));
                children.extend(w.orelse.iter().map(|s| self.normalize_stmt(s)));
                self.make_node(
                    "While",
                    &format!("has_else:{}", !w.orelse.is_empty()),
                    children,
                    w.range,
                )
            }
            If(i) => {
                let mut children = vec![self.normalize_expr(&i.test)];
                children.extend(i.body.iter().map(|s| self.normalize_stmt(s)));
                children.extend(i.orelse.iter().map(|s| self.normalize_stmt(s)));
                self.make_node(
                    "If",
                    &format!("has_else:{}", !i.orelse.is_empty()),
                    children,
                    i.range,
                )
            }
            With(w) => {
                let mut children: Vec<NormalizedNode> = Vec::new();
                for item in &w.items {
                    children.push(self.normalize_expr(&item.context_expr));
                    if let Some(ref v) = item.optional_vars {
                        children.push(self.normalize_expr(v));
                    }
                }
                children.extend(w.body.iter().map(|s| self.normalize_stmt(s)));
                self.make_node(
                    "With",
                    &format!("items:{}", w.items.len()),
                    children,
                    w.range,
                )
            }
            AsyncWith(w) => {
                let mut children: Vec<NormalizedNode> = Vec::new();
                for item in &w.items {
                    children.push(self.normalize_expr(&item.context_expr));
                    if let Some(ref v) = item.optional_vars {
                        children.push(self.normalize_expr(v));
                    }
                }
                children.extend(w.body.iter().map(|s| self.normalize_stmt(s)));
                self.make_node(
                    "AsyncWith",
                    &format!("items:{}", w.items.len()),
                    children,
                    w.range,
                )
            }
            Match(m) => {
                let mut children = vec![self.normalize_expr(&m.subject)];
                for case in &m.cases {
                    children.extend(case.body.iter().map(|s| self.normalize_stmt(s)));
                }
                self.make_node(
                    "Match",
                    &format!("cases:{}", m.cases.len()),
                    children,
                    m.range,
                )
            }
            Raise(r) => {
                let mut children = Vec::new();
                if let Some(ref exc) = r.exc {
                    children.push(self.normalize_expr(exc));
                }
                if let Some(ref cause) = r.cause {
                    children.push(self.normalize_expr(cause));
                }
                self.make_node("Raise", "", children, r.range)
            }
            Try(t) => {
                let mut children: Vec<NormalizedNode> =
                    t.body.iter().map(|s| self.normalize_stmt(s)).collect();
                for handler in &t.handlers {
                    let ast::ExceptHandler::ExceptHandler(h) = handler;
                    children.extend(h.body.iter().map(|s| self.normalize_stmt(s)));
                }
                children.extend(t.orelse.iter().map(|s| self.normalize_stmt(s)));
                children.extend(t.finalbody.iter().map(|s| self.normalize_stmt(s)));
                self.make_node(
                    "Try",
                    &format!(
                        "handlers:{}|has_else:{}|has_finally:{}",
                        t.handlers.len(),
                        !t.orelse.is_empty(),
                        !t.finalbody.is_empty()
                    ),
                    children,
                    t.range,
                )
            }
            TryStar(t) => {
                let mut children: Vec<NormalizedNode> =
                    t.body.iter().map(|s| self.normalize_stmt(s)).collect();
                for handler in &t.handlers {
                    let ast::ExceptHandler::ExceptHandler(h) = handler;
                    children.extend(h.body.iter().map(|s| self.normalize_stmt(s)));
                }
                children.extend(t.orelse.iter().map(|s| self.normalize_stmt(s)));
                children.extend(t.finalbody.iter().map(|s| self.normalize_stmt(s)));
                self.make_node("TryStar", "", children, t.range)
            }
            Assert(a) => {
                let mut children = vec![self.normalize_expr(&a.test)];
                if let Some(ref msg) = a.msg {
                    children.push(self.normalize_expr(msg));
                }
                self.make_node("Assert", "", children, a.range)
            }
            Import(i) => self.make_node(
                "Import",
                &format!("names:{}", i.names.len()),
                vec![],
                i.range,
            ),
            ImportFrom(i) => {
                let module_sig = i.module.as_ref().map(|m| m.as_str()).unwrap_or("");
                self.make_node(
                    "ImportFrom",
                    &format!("module:{}|names:{}", module_sig, i.names.len()),
                    vec![],
                    i.range,
                )
            }
            Global(g) => self.make_node(
                "Global",
                &format!("names:{}", g.names.len()),
                vec![],
                g.range,
            ),
            Nonlocal(n) => self.make_node(
                "Nonlocal",
                &format!("names:{}", n.names.len()),
                vec![],
                n.range,
            ),
            Expr(e) => {
                let children = vec![self.normalize_expr(&e.value)];
                self.make_node("ExprStmt", "", children, e.range)
            }
            Pass(p) => self.make_node("Pass", "", vec![], p.range),
            Break(b) => self.make_node("Break", "", vec![], b.range),
            Continue(c) => self.make_node("Continue", "", vec![], c.range),
            TypeAlias(t) => {
                let children = vec![self.normalize_expr(&t.name), self.normalize_expr(&t.value)];
                self.make_node("TypeAlias", "", children, t.range)
            }
        }
    }

    fn normalize_expr(&self, expr: &ast::Expr) -> NormalizedNode {
        use ast::Expr::*;
        match expr {
            BoolOp(b) => {
                let children = b.values.iter().map(|e| self.normalize_expr(e)).collect();
                self.make_node("BoolOp", &format!("{:?}", b.op), children, b.range)
            }
            NamedExpr(n) => {
                let children = vec![
                    self.normalize_expr(&n.target),
                    self.normalize_expr(&n.value),
                ];
                self.make_node("NamedExpr", "", children, n.range)
            }
            BinOp(b) => {
                let children = vec![self.normalize_expr(&b.left), self.normalize_expr(&b.right)];
                self.make_node("BinOp", &format!("{:?}", b.op), children, b.range)
            }
            UnaryOp(u) => {
                let children = vec![self.normalize_expr(&u.operand)];
                self.make_node("UnaryOp", &format!("{:?}", u.op), children, u.range)
            }
            Lambda(l) => {
                let children = vec![self.normalize_expr(&l.body)];
                self.make_node(
                    "Lambda",
                    &format!("args:{}", l.args.args.len()),
                    children,
                    l.range,
                )
            }
            IfExp(i) => {
                let children = vec![
                    self.normalize_expr(&i.test),
                    self.normalize_expr(&i.body),
                    self.normalize_expr(&i.orelse),
                ];
                self.make_node("IfExp", "", children, i.range)
            }
            Dict(d) => {
                let mut children: Vec<NormalizedNode> = Vec::new();
                for k in &d.keys {
                    if let Some(k) = k {
                        children.push(self.normalize_expr(k));
                    }
                }
                for v in &d.values {
                    children.push(self.normalize_expr(v));
                }
                self.make_node(
                    "Dict",
                    &format!("len:{}", d.values.len()),
                    children,
                    d.range,
                )
            }
            Set(s) => {
                let children = s.elts.iter().map(|e| self.normalize_expr(e)).collect();
                self.make_node("Set", &format!("len:{}", s.elts.len()), children, s.range)
            }
            ListComp(l) => {
                let mut children = vec![self.normalize_expr(&l.elt)];
                for gen in &l.generators {
                    children.push(self.normalize_expr(&gen.target));
                    children.push(self.normalize_expr(&gen.iter));
                    for cond in &gen.ifs {
                        children.push(self.normalize_expr(cond));
                    }
                }
                self.make_node(
                    "ListComp",
                    &format!("gens:{}", l.generators.len()),
                    children,
                    l.range,
                )
            }
            SetComp(s) => {
                let mut children = vec![self.normalize_expr(&s.elt)];
                for gen in &s.generators {
                    children.push(self.normalize_expr(&gen.target));
                    children.push(self.normalize_expr(&gen.iter));
                }
                self.make_node(
                    "SetComp",
                    &format!("gens:{}", s.generators.len()),
                    children,
                    s.range,
                )
            }
            DictComp(d) => {
                let mut children = vec![self.normalize_expr(&d.key), self.normalize_expr(&d.value)];
                for gen in &d.generators {
                    children.push(self.normalize_expr(&gen.target));
                    children.push(self.normalize_expr(&gen.iter));
                }
                self.make_node(
                    "DictComp",
                    &format!("gens:{}", d.generators.len()),
                    children,
                    d.range,
                )
            }
            GeneratorExp(g) => {
                let mut children = vec![self.normalize_expr(&g.elt)];
                for gen in &g.generators {
                    children.push(self.normalize_expr(&gen.target));
                    children.push(self.normalize_expr(&gen.iter));
                }
                self.make_node(
                    "GeneratorExp",
                    &format!("gens:{}", g.generators.len()),
                    children,
                    g.range,
                )
            }
            Await(a) => {
                let children = vec![self.normalize_expr(&a.value)];
                self.make_node("Await", "", children, a.range)
            }
            Yield(y) => {
                let children = y
                    .value
                    .as_ref()
                    .map(|v| vec![self.normalize_expr(v)])
                    .unwrap_or_default();
                self.make_node("Yield", "", children, y.range)
            }
            YieldFrom(y) => {
                let children = vec![self.normalize_expr(&y.value)];
                self.make_node("YieldFrom", "", children, y.range)
            }
            Compare(c) => {
                let mut children = vec![self.normalize_expr(&c.left)];
                children.extend(c.comparators.iter().map(|e| self.normalize_expr(e)));
                let ops: String = c
                    .ops
                    .iter()
                    .map(|o| format!("{:?}", o))
                    .collect::<Vec<_>>()
                    .join(",");
                self.make_node("Compare", &ops, children, c.range)
            }
            Call(c) => {
                let mut children = vec![self.normalize_expr(&c.func)];
                children.extend(c.args.iter().map(|e| self.normalize_expr(e)));
                for kw in &c.keywords {
                    children.push(self.normalize_expr(&kw.value));
                }
                self.make_node(
                    "Call",
                    &format!("args:{}|kwargs:{}", c.args.len(), c.keywords.len()),
                    children,
                    c.range,
                )
            }
            FormattedValue(f) => {
                let children = vec![self.normalize_expr(&f.value)];
                self.make_node("FormattedValue", "", children, f.range)
            }
            JoinedStr(j) => {
                let children = j.values.iter().map(|e| self.normalize_expr(e)).collect();
                self.make_node(
                    "JoinedStr",
                    &format!("len:{}", j.values.len()),
                    children,
                    j.range,
                )
            }
            Constant(c) => {
                // Normalize constant type but not value
                let kind = match &c.value {
                    ast::Constant::Int(_) => "int",
                    ast::Constant::Float(_) => "float",
                    ast::Constant::Complex { .. } => "complex",
                    ast::Constant::Str(_) => "str",
                    ast::Constant::Bytes(_) => "bytes",
                    ast::Constant::Bool(_) => "bool",
                    ast::Constant::None => "None",
                    ast::Constant::Ellipsis => "Ellipsis",
                    _ => "other",
                };
                self.make_node("Constant", kind, vec![], c.range)
            }
            Attribute(a) => {
                let children = vec![self.normalize_expr(&a.value)];
                // Keep attribute name as it's structural (e.g., self.solve)
                self.make_node("Attribute", &format!("attr:{}", a.attr), children, a.range)
            }
            Subscript(s) => {
                let children = vec![self.normalize_expr(&s.value), self.normalize_expr(&s.slice)];
                self.make_node("Subscript", "", children, s.range)
            }
            Starred(s) => {
                let children = vec![self.normalize_expr(&s.value)];
                self.make_node("Starred", "", children, s.range)
            }
            Name(_) => {
                // Strip variable name - just mark as "Name"
                self.make_node("Name", "", vec![], expr.range())
            }
            List(l) => {
                let children = l.elts.iter().map(|e| self.normalize_expr(e)).collect();
                self.make_node("List", &format!("len:{}", l.elts.len()), children, l.range)
            }
            Tuple(t) => {
                let children = t.elts.iter().map(|e| self.normalize_expr(e)).collect();
                self.make_node("Tuple", &format!("len:{}", t.elts.len()), children, t.range)
            }
            Slice(s) => {
                let mut children = Vec::new();
                if let Some(ref lower) = s.lower {
                    children.push(self.normalize_expr(lower));
                }
                if let Some(ref upper) = s.upper {
                    children.push(self.normalize_expr(upper));
                }
                if let Some(ref step) = s.step {
                    children.push(self.normalize_expr(step));
                }
                self.make_node("Slice", "", children, s.range)
            }
        }
    }

    fn make_node(
        &self,
        node_type: &str,
        extra: &str,
        children: Vec<NormalizedNode>,
        range: rustpython_parser::text_size::TextRange,
    ) -> NormalizedNode {
        let size = 1 + children.iter().map(|c| c.size).sum::<u32>();

        // Build structure signature: type|extra|child_hashes
        let mut sig = format!("{}|{}", node_type, extra);
        for child in &children {
            sig.push('|');
            sig.push_str(&child.structure_hash);
        }

        let mut hasher = Md5::new();
        hasher.update(sig.as_bytes());
        let hash = format!("{:x}", hasher.finalize());

        let start = u32::from(range.start());
        let end = u32::from(range.end());

        NormalizedNode {
            node_type: node_type.to_string(),
            structure_hash: hash,
            size,
            line_start: offset_to_line(self.source, start),
            line_end: offset_to_line(self.source, end),
            children,
        }
    }
}

// ============================================================================
// Plagiarism Index
// ============================================================================

pub struct PlagiarismIndex {
    /// hash -> list of entries from indexed agents
    index: HashMap<String, Vec<IndexEntry>>,
    min_subtree_size: u32,
}

impl PlagiarismIndex {
    pub fn new(min_subtree_size: u32) -> Self {
        Self {
            index: HashMap::new(),
            min_subtree_size,
        }
    }

    pub fn len(&self) -> usize {
        self.index.len()
    }

    /// Load index from precomputed AST hashes (from DB)
    pub fn load_from_stored(&mut self, agent_hash: &str, ast_hashes: &serde_json::Value) {
        if let Some(map) = ast_hashes.as_object() {
            for (hash, entries) in map {
                if let Some(arr) = entries.as_array() {
                    for entry_val in arr {
                        let entry = IndexEntry {
                            agent_hash: agent_hash.to_string(),
                            file_path: entry_val["file"].as_str().unwrap_or("").to_string(),
                            node_type: entry_val["node_type"].as_str().unwrap_or("").to_string(),
                            line_start: entry_val["line_start"].as_u64().unwrap_or(0) as u32,
                            line_end: entry_val["line_end"].as_u64().unwrap_or(0) as u32,
                            subtree_size: entry_val["size"].as_u64().unwrap_or(0) as u32,
                        };
                        self.index.entry(hash.clone()).or_default().push(entry);
                    }
                }
            }
        }
    }

    /// Index an agent's files and return the hash map for DB storage
    pub fn index_agent(
        &mut self,
        agent_hash: &str,
        files: &HashMap<String, String>,
    ) -> (serde_json::Value, u32) {
        let mut ast_hashes: HashMap<String, Vec<serde_json::Value>> = HashMap::new();
        let mut total_nodes: u32 = 0;

        for (file_path, code) in files {
            let parsed = match ast::Suite::parse(code, file_path) {
                Ok(suite) => suite,
                Err(e) => {
                    debug!("Failed to parse {}: {}", file_path, e);
                    continue;
                }
            };

            let normalizer = AstNormalizer::new(code);
            let nodes = normalizer.normalize_module(&parsed);

            for node in &nodes {
                total_nodes += node.size;
                self.index_subtrees(node, agent_hash, file_path, &mut ast_hashes);
            }
        }

        let json_map: serde_json::Map<String, serde_json::Value> = ast_hashes
            .into_iter()
            .map(|(k, v)| (k, serde_json::Value::Array(v)))
            .collect();

        (serde_json::Value::Object(json_map), total_nodes)
    }

    fn index_subtrees(
        &mut self,
        node: &NormalizedNode,
        agent_hash: &str,
        file_path: &str,
        ast_hashes: &mut HashMap<String, Vec<serde_json::Value>>,
    ) {
        if node.size >= self.min_subtree_size {
            let entry = IndexEntry {
                agent_hash: agent_hash.to_string(),
                file_path: file_path.to_string(),
                node_type: node.node_type.clone(),
                line_start: node.line_start,
                line_end: node.line_end,
                subtree_size: node.size,
            };

            let json_entry = serde_json::json!({
                "file": file_path,
                "node_type": node.node_type,
                "line_start": node.line_start,
                "line_end": node.line_end,
                "size": node.size,
            });

            self.index
                .entry(node.structure_hash.clone())
                .or_default()
                .push(entry);
            ast_hashes
                .entry(node.structure_hash.clone())
                .or_default()
                .push(json_entry);
        }

        for child in &node.children {
            self.index_subtrees(child, agent_hash, file_path, ast_hashes);
        }
    }
}

// ============================================================================
// Plagiarism Detector
// ============================================================================

pub struct PlagiarismDetector<'a> {
    index: &'a PlagiarismIndex,
}

impl<'a> PlagiarismDetector<'a> {
    pub fn new(index: &'a PlagiarismIndex) -> Self {
        Self { index }
    }

    /// Check an agent against the index.
    /// Computes similarity **per reference agent** and takes the highest score.
    /// This way, reusing small snippets from many agents won't inflate the score --
    /// only copying a single specific agent triggers flag/reject.
    pub fn check_agent(
        &self,
        agent_hash: &str,
        files: &HashMap<String, String>,
        config: &PlagiarismConfig,
    ) -> PlagiarismReport {
        // Step 1: parse all files once
        let mut all_nodes: Vec<(String, Vec<NormalizedNode>)> = Vec::new();
        for (file_path, code) in files {
            let parsed = match ast::Suite::parse(code, file_path) {
                Ok(suite) => suite,
                Err(_) => continue,
            };
            let normalizer = AstNormalizer::new(code);
            let nodes = normalizer.normalize_module(&parsed);
            if !nodes.is_empty() {
                all_nodes.push((file_path.clone(), nodes));
            }
        }

        // Step 2: collect all distinct reference agent hashes in the index
        let mut ref_agents: HashSet<String> = HashSet::new();
        for entries in self.index.index.values() {
            for entry in entries {
                if entry.agent_hash != agent_hash {
                    ref_agents.insert(entry.agent_hash.clone());
                }
            }
        }

        if ref_agents.is_empty() || all_nodes.is_empty() {
            return PlagiarismReport {
                total_nodes: 0,
                matched_nodes: 0,
                match_percent: 0.0,
                matches: Vec::new(),
                verdict: "cleared".to_string(),
            };
        }

        // Step 3: for each reference agent, compute similarity independently
        let mut best_report: Option<PlagiarismReport> = None;

        for ref_hash in &ref_agents {
            let mut matches: Vec<PlagiarismMatch> = Vec::new();
            let mut total_nodes: u32 = 0;
            let mut matched_nodes: u32 = 0;
            let mut matched_hashes: HashSet<String> = HashSet::new();

            for (file_path, nodes) in &all_nodes {
                for node in nodes {
                    let (node_matches, node_total, node_matched) = self.check_subtrees_single(
                        node,
                        file_path,
                        agent_hash,
                        ref_hash,
                        &mut matched_hashes,
                    );
                    matches.extend(node_matches);
                    total_nodes += node_total;
                    matched_nodes += node_matched;
                }
            }

            let match_percent = if total_nodes > 0 {
                (matched_nodes as f64 / total_nodes as f64) * 100.0
            } else {
                0.0
            };

            if best_report
                .as_ref()
                .map_or(true, |r| match_percent > r.match_percent)
            {
                matches.sort_by(|a, b| b.subtree_size.cmp(&a.subtree_size));
                matches.truncate(50);
                best_report = Some(PlagiarismReport {
                    total_nodes,
                    matched_nodes,
                    match_percent,
                    matches,
                    verdict: String::new(), // set below
                });
            }
        }

        let mut report = best_report.unwrap_or(PlagiarismReport {
            total_nodes: 0,
            matched_nodes: 0,
            match_percent: 0.0,
            matches: Vec::new(),
            verdict: "cleared".to_string(),
        });

        report.verdict = if report.match_percent >= config.reject_threshold {
            "rejected".to_string()
        } else if report.match_percent >= config.flag_threshold {
            "flagged".to_string()
        } else {
            "cleared".to_string()
        };

        report
    }

    /// Greedy top-down matching against a **single** reference agent.
    fn check_subtrees_single(
        &self,
        node: &NormalizedNode,
        file_path: &str,
        self_agent_hash: &str,
        ref_agent_hash: &str,
        matched_hashes: &mut HashSet<String>,
    ) -> (Vec<PlagiarismMatch>, u32, u32) {
        if node.size < self.index.min_subtree_size {
            return (Vec::new(), 0, 0);
        }

        // Look up in index, only match against the specific reference agent
        if let Some(entries) = self.index.index.get(&node.structure_hash) {
            let ref_entries: Vec<&IndexEntry> = entries
                .iter()
                .filter(|e| e.agent_hash == ref_agent_hash)
                .collect();

            if !ref_entries.is_empty() && !matched_hashes.contains(&node.structure_hash) {
                matched_hashes.insert(node.structure_hash.clone());

                let best = ref_entries.iter().max_by_key(|e| e.subtree_size).unwrap();

                let m = PlagiarismMatch {
                    pending_file: file_path.to_string(),
                    pending_lines: (node.line_start, node.line_end),
                    matched_agent_hash: best.agent_hash.clone(),
                    matched_file: best.file_path.clone(),
                    matched_lines: (best.line_start, best.line_end),
                    node_type: node.node_type.clone(),
                    subtree_size: node.size,
                };

                return (vec![m], node.size, node.size);
            }
        }

        // Node didn't match this reference agent -> recurse
        let mut matches = Vec::new();
        let mut children_total: u32 = 0;
        let mut matched: u32 = 0;

        for child in &node.children {
            let (child_matches, child_total, child_matched) = self.check_subtrees_single(
                child,
                file_path,
                self_agent_hash,
                ref_agent_hash,
                matched_hashes,
            );
            matches.extend(child_matches);
            children_total += child_total;
            matched += child_matched;
        }

        let total = if children_total > 0 {
            children_total
        } else {
            node.size
        };

        (matches, total, matched)
    }
}

// ============================================================================
// Plagiarism Worker
// ============================================================================

pub struct PlagiarismWorker {
    storage: Arc<PgStorage>,
    index: tokio::sync::RwLock<PlagiarismIndex>,
}

impl PlagiarismWorker {
    pub fn new(storage: Arc<PgStorage>) -> Self {
        Self {
            storage,
            index: tokio::sync::RwLock::new(PlagiarismIndex::new(10)),
        }
    }

    pub async fn run(&self) {
        info!(
            "Plagiarism detection worker started (poll={}s, batch={})",
            POLL_INTERVAL_SECS, BATCH_SIZE
        );

        // Load config and build initial index
        if let Err(e) = self.rebuild_index().await {
            error!("Failed to build initial plagiarism index: {}", e);
        }

        let mut ticker = interval(Duration::from_secs(POLL_INTERVAL_SECS));

        loop {
            ticker.tick().await;

            if let Err(e) = self.process_pending().await {
                error!("Error processing pending plagiarism checks: {}", e);
            }
        }
    }

    async fn rebuild_index(&self) -> Result<()> {
        let config = self.storage.get_plagiarism_config().await?;
        let mut index = PlagiarismIndex::new(config.min_subtree_size);

        // Load existing AST index entries from DB
        let stored = self.storage.load_ast_index().await?;
        for (agent_hash, ast_hashes, _total_nodes) in &stored {
            index.load_from_stored(agent_hash, ast_hashes);
        }

        if stored.is_empty() {
            // Build from top agents
            let top_agents = self
                .storage
                .get_top_agents_for_index(config.index_top_n)
                .await?;

            info!(
                "Building plagiarism index from {} top agents",
                top_agents.len()
            );

            for agent in &top_agents {
                let files = match Self::extract_python_files(agent) {
                    Ok(f) => f,
                    Err(e) => {
                        debug!(
                            "Failed to extract files for {}: {}",
                            &agent.agent_hash[..16.min(agent.agent_hash.len())],
                            e
                        );
                        continue;
                    }
                };

                let (ast_hashes, total_nodes) = index.index_agent(&agent.agent_hash, &files);

                // Save to DB for persistence
                if let Err(e) = self
                    .storage
                    .save_ast_index(&agent.agent_hash, &ast_hashes, total_nodes as i32)
                    .await
                {
                    warn!(
                        "Failed to save AST index for {}: {}",
                        &agent.agent_hash[..16.min(agent.agent_hash.len())],
                        e
                    );
                }
            }
        }

        info!("Plagiarism index loaded: {} unique hashes", index.len());

        let mut guard = self.index.write().await;
        *guard = index;

        Ok(())
    }

    fn extract_python_files(
        submission: &crate::storage::pg::PendingLlmReview,
    ) -> Result<HashMap<String, String>> {
        let mut files = HashMap::new();

        if submission.is_package {
            let pkg_data = submission
                .package_data
                .as_deref()
                .context("Package data missing")?;
            let format = submission.package_format.as_deref().unwrap_or("zip");
            let entry = submission.entry_point.as_deref().unwrap_or("agent.py");

            let validator = PackageValidator::new();
            let (_validation, extracted) = validator
                .validate_and_extract(pkg_data, format, entry)
                .context("Failed to extract package")?;

            for f in extracted {
                if f.is_python {
                    files.insert(f.path, String::from_utf8_lossy(&f.content).to_string());
                }
            }
        } else if !submission.source_code.is_empty() {
            files.insert("agent.py".to_string(), submission.source_code.clone());
        }

        if files.is_empty() {
            anyhow::bail!("No Python files found");
        }

        Ok(files)
    }

    async fn process_pending(&self) -> Result<()> {
        let config = self.storage.get_plagiarism_config().await?;

        let pending = self
            .storage
            .claim_pending_plagiarism_checks(BATCH_SIZE as i32)
            .await?;

        if pending.is_empty() {
            return Ok(());
        }

        info!("Claimed {} agents for plagiarism check", pending.len());

        for submission in pending {
            let short_hash = &submission.agent_hash[..16.min(submission.agent_hash.len())];

            let files = match Self::extract_python_files(&submission) {
                Ok(f) => f,
                Err(e) => {
                    error!("Failed to extract files for {}: {}", short_hash, e);
                    // Reset for retry
                    let _ = self
                        .storage
                        .reset_plagiarism_for_retry(&submission.agent_hash)
                        .await;
                    continue;
                }
            };

            // Run detection
            let report = {
                let index = self.index.read().await;
                let detector = PlagiarismDetector::new(&index);
                detector.check_agent(&submission.agent_hash, &files, &config)
            };

            info!(
                "Plagiarism check for {}: {:.1}% match ({}/{} nodes) -> {}",
                short_hash,
                report.match_percent,
                report.matched_nodes,
                report.total_nodes,
                report.verdict
            );

            let matches_json = serde_json::to_value(&report.matches).unwrap_or_default();

            // Update DB
            if report.verdict == "rejected" {
                // Build detailed rejection message
                let matched_agents: Vec<String> = report
                    .matches
                    .iter()
                    .map(|m| m.matched_agent_hash[..16.min(m.matched_agent_hash.len())].to_string())
                    .collect::<HashSet<_>>()
                    .into_iter()
                    .collect();

                let reason = format!(
                    "Plagiarism detected: {:.1}% structural similarity with agents [{}]. \
                     Your code structure matches existing submissions. Please submit original work.",
                    report.match_percent,
                    matched_agents.join(", ")
                );

                self.storage
                    .update_plagiarism_result(
                        &submission.agent_hash,
                        "rejected",
                        report.match_percent as f32,
                        &matches_json,
                        Some(&reason),
                    )
                    .await?;
            } else {
                self.storage
                    .update_plagiarism_result(
                        &submission.agent_hash,
                        &report.verdict,
                        report.match_percent as f32,
                        &matches_json,
                        None,
                    )
                    .await?;
            }

            // Index this agent for future comparisons (even if flagged)
            if report.verdict != "rejected" {
                let (ast_hashes, total_nodes) = {
                    let mut index = self.index.write().await;
                    index.index_agent(&submission.agent_hash, &files)
                };
                let _ = self
                    .storage
                    .save_ast_index(&submission.agent_hash, &ast_hashes, total_nodes as i32)
                    .await;
            }
        }

        Ok(())
    }
}

// ============================================================================
// Tests
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_offset_to_line() {
        let source = "line1\nline2\nline3\n";
        assert_eq!(offset_to_line(source, 0), 1);
        assert_eq!(offset_to_line(source, 5), 1); // '\n'
        assert_eq!(offset_to_line(source, 6), 2); // 'l' of line2
        assert_eq!(offset_to_line(source, 12), 3);
    }

    #[test]
    fn test_normalize_simple_function() {
        let code = r#"
def hello():
    x = 1
    return x
"#;
        let suite = ast::Suite::parse(code, "<test>").unwrap();
        let normalizer = AstNormalizer::new(code);
        let nodes = normalizer.normalize_module(&suite);

        assert_eq!(nodes.len(), 1);
        assert_eq!(nodes[0].node_type, "FunctionDef");
        assert!(nodes[0].size > 1);
    }

    #[test]
    fn test_normalize_strips_names() {
        // Two functions with identical structure but different names
        let code1 = "def foo():\n    x = 1\n    return x\n";
        let code2 = "def bar():\n    y = 1\n    return y\n";

        let suite1 = ast::Suite::parse(code1, "<test>").unwrap();
        let suite2 = ast::Suite::parse(code2, "<test>").unwrap();

        let n1 = AstNormalizer::new(code1).normalize_module(&suite1);
        let n2 = AstNormalizer::new(code2).normalize_module(&suite2);

        // Structure hashes should be identical since we strip names
        assert_eq!(n1[0].structure_hash, n2[0].structure_hash);
    }

    #[test]
    fn test_normalize_different_structure() {
        let code1 = "def foo():\n    return 1\n";
        let code2 = "def foo():\n    x = 1\n    return x\n";

        let suite1 = ast::Suite::parse(code1, "<test>").unwrap();
        let suite2 = ast::Suite::parse(code2, "<test>").unwrap();

        let n1 = AstNormalizer::new(code1).normalize_module(&suite1);
        let n2 = AstNormalizer::new(code2).normalize_module(&suite2);

        // Different structure -> different hashes
        assert_ne!(n1[0].structure_hash, n2[0].structure_hash);
    }

    #[test]
    fn test_index_and_detect() {
        let mut index = PlagiarismIndex::new(3); // Low threshold for testing

        let agent1_code = r#"
class Agent:
    def solve(self, req):
        result = self.compute(req.data)
        return Response.cmd(result)

    def compute(self, data):
        x = data.split()
        y = len(x)
        return str(y)
"#;

        let mut files1 = HashMap::new();
        files1.insert("agent.py".to_string(), agent1_code.to_string());
        let (_hashes, _total) = index.index_agent("agent1hash", &files1);

        // Same code, different agent
        let agent2_code = r#"
class MyBot:
    def solve(self, req):
        result = self.compute(req.data)
        return Response.cmd(result)

    def compute(self, data):
        x = data.split()
        y = len(x)
        return str(y)
"#;

        let mut files2 = HashMap::new();
        files2.insert("agent.py".to_string(), agent2_code.to_string());

        let config = PlagiarismConfig {
            flag_threshold: 50.0,
            reject_threshold: 90.0,
            min_subtree_size: 3,
            ..Default::default()
        };

        let detector = PlagiarismDetector::new(&index);
        let report = detector.check_agent("agent2hash", &files2, &config);

        // Should detect high similarity
        assert!(
            report.match_percent > 50.0,
            "Expected >50% match, got {:.1}%",
            report.match_percent
        );
        assert!(!report.matches.is_empty());
    }

    #[test]
    fn test_index_excludes_self() {
        let mut index = PlagiarismIndex::new(3);

        let code = "def solve(self, req):\n    x = 1\n    y = 2\n    return x + y\n";
        let mut files = HashMap::new();
        files.insert("agent.py".to_string(), code.to_string());

        let (_hashes, _total) = index.index_agent("agent1", &files);

        let config = PlagiarismConfig {
            flag_threshold: 50.0,
            reject_threshold: 90.0,
            min_subtree_size: 3,
            ..Default::default()
        };

        // Check same agent against itself -> should find 0 matches (self excluded)
        let detector = PlagiarismDetector::new(&index);
        let report = detector.check_agent("agent1", &files, &config);
        assert_eq!(report.matched_nodes, 0);
    }

    #[test]
    fn test_parse_error_handled() {
        let code = "def invalid(:\n    pass\n";
        let result = ast::Suite::parse(code, "<test>");
        assert!(result.is_err());
    }

    #[test]
    fn test_empty_files() {
        let index = PlagiarismIndex::new(10);
        let config = PlagiarismConfig::default();
        let detector = PlagiarismDetector::new(&index);
        let files = HashMap::new();
        let report = detector.check_agent("empty", &files, &config);
        assert_eq!(report.match_percent, 0.0);
        assert_eq!(report.verdict, "cleared");
    }

    fn load_python_files(dir: &str) -> HashMap<String, String> {
        let mut files = HashMap::new();
        let path = std::path::Path::new(dir);
        if !path.exists() {
            return files;
        }
        fn walk(
            base: &std::path::Path,
            current: &std::path::Path,
            files: &mut HashMap<String, String>,
        ) {
            if let Ok(entries) = std::fs::read_dir(current) {
                for entry in entries.flatten() {
                    let p = entry.path();
                    if p.is_dir() {
                        walk(base, &p, files);
                    } else if p.extension().map_or(false, |e| e == "py") {
                        if let Ok(content) = std::fs::read_to_string(&p) {
                            let rel = p.strip_prefix(base).unwrap_or(&p);
                            files.insert(rel.to_string_lossy().to_string(), content);
                        }
                    }
                }
            }
        }
        walk(path, path, &mut files);
        files
    }

    #[test]
    fn test_baseagent_vs_b2_real_files() {
        let original_dir = "/mnt/c/Users/mathi/baseagent-fresh";
        let modified_dir = "/mnt/c/Users/mathi/b2";

        let original_files = load_python_files(original_dir);
        let modified_files = load_python_files(modified_dir);

        if original_files.is_empty() || modified_files.is_empty() {
            eprintln!("Skipping test: directories not found");
            return;
        }

        eprintln!("Original: {} Python files", original_files.len());
        eprintln!("Modified: {} Python files", modified_files.len());

        let config = PlagiarismConfig {
            flag_threshold: 70.0,
            reject_threshold: 95.0,
            min_subtree_size: 10,
            ..Default::default()
        };

        // Index the original agent
        let mut index = PlagiarismIndex::new(config.min_subtree_size);
        let (hashes_count, total_nodes) = index.index_agent("original_baseagent", &original_files);
        eprintln!(
            "Indexed original: {} hashes, {} total nodes",
            hashes_count, total_nodes
        );

        // Check modified agent against original
        let detector = PlagiarismDetector::new(&index);
        let report = detector.check_agent("modified_b2", &modified_files, &config);

        eprintln!("========================================");
        eprintln!("RESULT: b2 vs baseagent-fresh");
        eprintln!("========================================");
        eprintln!("Similarity: {:.1}%", report.match_percent);
        eprintln!("Verdict: {}", report.verdict);
        eprintln!("Matched nodes: {}", report.matched_nodes);
        eprintln!("Total nodes: {}", report.total_nodes);
        eprintln!("Matches: {}", report.matches.len());

        for (i, m) in report.matches.iter().take(10).enumerate() {
            eprintln!(
                "  Match {}: {} ({}:{}-{}) -> {} ({}:{}-{}) [{} nodes]",
                i + 1,
                m.pending_file,
                m.pending_lines.0,
                m.pending_lines.1,
                m.pending_lines.0,
                m.matched_file,
                m.matched_lines.0,
                m.matched_lines.1,
                m.matched_lines.0,
                m.subtree_size
            );
        }

        // Modified agent should NOT be 100% similar (we added new code)
        assert!(
            report.match_percent < 100.0,
            "Modified agent should not be 100% similar, got {:.1}%",
            report.match_percent
        );
        // But should still have significant overlap (core code is the same)
        assert!(
            report.match_percent > 50.0,
            "Modified agent should have >50% overlap, got {:.1}%",
            report.match_percent
        );

        eprintln!("========================================");
        eprintln!(
            "TEST PASSED: {:.1}% similarity (not 100%)",
            report.match_percent
        );
        eprintln!("========================================");

        // Now check original vs modified (reverse direction)
        let mut index2 = PlagiarismIndex::new(config.min_subtree_size);
        index2.index_agent("modified_b2", &modified_files);
        let detector2 = PlagiarismDetector::new(&index2);
        let report2 = detector2.check_agent("original_baseagent", &original_files, &config);

        eprintln!("========================================");
        eprintln!("REVERSE: baseagent-fresh vs b2");
        eprintln!("========================================");
        eprintln!("Similarity: {:.1}%", report2.match_percent);
        eprintln!("Verdict: {}", report2.verdict);
        eprintln!("Matched nodes: {}", report2.matched_nodes);
        eprintln!("Total nodes: {}", report2.total_nodes);
    }
}
