//! LLM Review Worker
//!
//! Background service that reviews pending agent submissions using a conversational
//! LLM agent that can explore the code via function calls before submitting a verdict.
//!
//! Flow:
//! 1. Polls DB for agents with llm_review_status='pending'
//! 2. Loads validation rules from the validation_rules table
//! 3. Creates a temporary workspace with the agent code
//! 4. Runs a conversation loop where the LLM can:
//!    - read_file(path) - Read a file from the workspace
//!    - list_files(path) - List files in a directory
//!    - grep(pattern, path) - Search for a pattern in files
//!    - submit_verdict(approved, reason, violations) - Submit final verdict
//! 5. Updates DB based on the verdict

use crate::storage::pg::PgStorage;
use crate::validation::package::PackageValidator;
use anyhow::{Context, Result};
use reqwest::Client;
use serde_json::json;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::Duration;
use tokio::time::interval;
use tracing::{debug, error, info, warn};

const REVIEW_TIMEOUT_SECS: u64 = 180;
const POLL_INTERVAL_SECS: u64 = 10;
const BATCH_SIZE: i64 = 5;
const LLM_MODEL: &str = "moonshotai/Kimi-K2.5-TEE";
const CHUTES_API_URL: &str = "https://llm.chutes.ai/v1/chat/completions";
const MAX_CONVERSATION_TURNS: u32 = 20;
const MAX_LLM_REVIEW_RETRIES: i32 = 3;

const SYSTEM_PROMPT: &str = r#"You are a strict security code reviewer for a terminal-based AI agent challenge.

Your task is to analyze Python agent code and determine if it complies with ALL of the validation rules.

VALIDATION RULES:
{rules}

You have access to a workspace containing the agent's source code. Use the provided tools to explore and analyze the code:

- list_files(path): List files in a directory (use "." for root)
- read_file(path): Read the contents of a file
- grep(pattern, path): Search for a regex pattern in files (path can be "." for all files)
- submit_verdict(approved, reason, violations): Submit your final verdict

WORKFLOW:
1. First, list the files to understand the project structure
2. Read the main entry point and any imported modules
3. Search for potentially dangerous patterns (subprocess, os.system, socket, requests, etc.)
4. Once you have analyzed all relevant code, submit your verdict

IMPORTANT:
- You MUST call submit_verdict when you have finished your analysis
- If ANY rule is violated, set approved=false
- Be thorough - check all Python files in the project
- The violations array should list specific rule violations found"#;

/// Tool definitions for the LLM
fn get_tools() -> serde_json::Value {
    json!([
        {
            "type": "function",
            "function": {
                "name": "list_files",
                "description": "List files and directories in the specified path",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "path": {
                            "type": "string",
                            "description": "Path relative to workspace root (use '.' for root)"
                        }
                    },
                    "required": ["path"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "read_file",
                "description": "Read the contents of a file",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "path": {
                            "type": "string",
                            "description": "Path to the file relative to workspace root"
                        }
                    },
                    "required": ["path"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "grep",
                "description": "Search for a pattern in files using regex",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "pattern": {
                            "type": "string",
                            "description": "Regex pattern to search for"
                        },
                        "path": {
                            "type": "string",
                            "description": "Path to search in (use '.' for all files)"
                        }
                    },
                    "required": ["pattern"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "submit_verdict",
                "description": "Submit your final code review verdict. Call this when you have finished analyzing the code.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "approved": {
                            "type": "boolean",
                            "description": "true if the code passes ALL rules, false if ANY rule is violated"
                        },
                        "reason": {
                            "type": "string",
                            "description": "Brief explanation of the review decision"
                        },
                        "violations": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "List of specific rule violations found (empty array if approved)"
                        }
                    },
                    "required": ["approved", "reason", "violations"]
                }
            }
        }
    ])
}

/// Workspace for exploring agent code
struct ReviewWorkspace {
    root: PathBuf,
}

impl ReviewWorkspace {
    #[allow(deprecated)]
    fn new(source_code: &str, is_package: bool) -> Result<Self> {
        let tmp_dir = tempfile::tempdir().context("Failed to create temp dir")?;
        let root = tmp_dir.into_path(); // Take ownership of path, dir won't be auto-deleted

        if is_package {
            // Source code is already formatted as "### FILE: path ###\ncontent"
            for section in source_code.split("### FILE: ") {
                if section.trim().is_empty() {
                    continue;
                }
                if let Some(header_end) = section.find(" ###\n") {
                    let path = section[..header_end].trim();
                    let content = &section[header_end + 5..];
                    
                    let file_path = root.join(path);
                    if let Some(parent) = file_path.parent() {
                        std::fs::create_dir_all(parent).ok();
                    }
                    std::fs::write(&file_path, content).ok();
                }
            }
        } else {
            // Single file submission
            let file_path = root.join("agent.py");
            std::fs::write(&file_path, source_code).ok();
        }

        Ok(Self { root })
    }

    fn list_files(&self, path: &str) -> String {
        let target = if path == "." || path.is_empty() {
            self.root.clone()
        } else {
            self.root.join(path)
        };

        if !target.exists() {
            return format!("Error: Path '{}' not found", path);
        }

        let mut entries = Vec::new();
        if let Ok(read_dir) = std::fs::read_dir(&target) {
            for entry in read_dir.flatten() {
                let name = entry.file_name().to_string_lossy().to_string();
                let is_dir = entry.file_type().map(|t| t.is_dir()).unwrap_or(false);
                if is_dir {
                    entries.push(format!("{}/", name));
                } else {
                    entries.push(name);
                }
            }
        }

        if entries.is_empty() {
            "Directory is empty".to_string()
        } else {
            entries.sort();
            entries.join("\n")
        }
    }

    fn read_file(&self, path: &str) -> String {
        let file_path = self.root.join(path);
        
        // Security: prevent path traversal
        if !file_path.starts_with(&self.root) {
            return "Error: Access denied - path traversal detected".to_string();
        }

        match std::fs::read_to_string(&file_path) {
            Ok(content) => {
                if content.len() > 50000 {
                    format!("{}...\n\n[Truncated - file too large ({} bytes)]", &content[..50000], content.len())
                } else {
                    content
                }
            }
            Err(e) => format!("Error reading file '{}': {}", path, e),
        }
    }

    fn grep(&self, pattern: &str, path: &str) -> String {
        let regex = match regex::Regex::new(pattern) {
            Ok(r) => r,
            Err(e) => return format!("Error: Invalid regex pattern: {}", e),
        };

        let mut results = Vec::new();
        let search_path = if path == "." || path.is_empty() {
            self.root.clone()
        } else {
            self.root.join(path)
        };

        self.grep_recursive(&search_path, &regex, &mut results);

        if results.is_empty() {
            format!("No matches found for pattern '{}'", pattern)
        } else {
            results.join("\n")
        }
    }

    fn grep_recursive(&self, path: &Path, regex: &regex::Regex, results: &mut Vec<String>) {
        if path.is_file() {
            if let Ok(content) = std::fs::read_to_string(path) {
                let rel_path = path.strip_prefix(&self.root).unwrap_or(path);
                for (line_num, line) in content.lines().enumerate() {
                    if regex.is_match(line) {
                        results.push(format!(
                            "{}:{}: {}",
                            rel_path.display(),
                            line_num + 1,
                            line.trim()
                        ));
                    }
                }
            }
        } else if path.is_dir() {
            if let Ok(entries) = std::fs::read_dir(path) {
                for entry in entries.flatten() {
                    self.grep_recursive(&entry.path(), regex, results);
                }
            }
        }
    }

    fn cleanup(self) {
        let _ = std::fs::remove_dir_all(&self.root);
    }
}

pub struct LlmReviewWorkerConfig {
    pub poll_interval_secs: u64,
    pub batch_size: i64,
    pub chutes_api_token: String,
}

impl Default for LlmReviewWorkerConfig {
    fn default() -> Self {
        Self {
            poll_interval_secs: POLL_INTERVAL_SECS,
            batch_size: BATCH_SIZE,
            chutes_api_token: String::new(),
        }
    }
}

pub struct LlmReviewWorker {
    storage: Arc<PgStorage>,
    config: LlmReviewWorkerConfig,
    http_client: Client,
}

impl LlmReviewWorker {
    pub fn new(storage: Arc<PgStorage>, config: LlmReviewWorkerConfig) -> Self {
        let http_client = Client::builder()
            .timeout(Duration::from_secs(REVIEW_TIMEOUT_SECS))
            .build()
            .expect("Failed to create HTTP client");

        Self {
            storage,
            config,
            http_client,
        }
    }

    pub fn from_env(storage: Arc<PgStorage>) -> Option<Self> {
        let token = std::env::var("EXTRA_CHUTES_API_TOKEN")
            .or_else(|_| std::env::var("CHUTES_API_KEY"))
            .ok()?;

        if token.is_empty() {
            return None;
        }

        Some(Self::new(
            storage,
            LlmReviewWorkerConfig {
                chutes_api_token: token,
                ..Default::default()
            },
        ))
    }

    pub async fn run(&self) {
        info!(
            "LLM Review worker started (poll={}s, batch={}, model={}, max_turns={})",
            self.config.poll_interval_secs, self.config.batch_size, LLM_MODEL, MAX_CONVERSATION_TURNS
        );

        let mut ticker = interval(Duration::from_secs(self.config.poll_interval_secs));

        loop {
            ticker.tick().await;

            if let Err(e) = self.process_pending().await {
                error!("Error processing pending LLM reviews: {}", e);
            }
        }
    }

    async fn process_pending(&self) -> Result<()> {
        let rules = self.storage.get_active_validation_rules().await?;
        if rules.is_empty() {
            debug!("No active validation rules found - skipping LLM review cycle");
            return Ok(());
        }

        let pending = self
            .storage
            .claim_pending_llm_reviews(self.config.batch_size, MAX_LLM_REVIEW_RETRIES)
            .await?;

        if pending.is_empty() {
            debug!("No pending LLM reviews");
            return Ok(());
        }

        info!("Claimed {} agents for LLM review", pending.len());

        let formatted_rules = rules
            .iter()
            .enumerate()
            .map(|(i, r)| format!("{}. {}", i + 1, r))
            .collect::<Vec<_>>()
            .join("\n");

        for submission in pending {
            let agent_hash = &submission.agent_hash;
            let short_hash = &agent_hash[..16.min(agent_hash.len())];

            let review_code = if submission.is_package {
                match Self::extract_package_code(&submission) {
                    Ok(code) => code,
                    Err(e) => {
                        error!("Failed to extract package for {}: {}", short_hash, e);
                        if let Err(e2) = self.storage.reset_llm_review_for_retry(agent_hash).await {
                            error!("Failed to reset review status for {}: {}", short_hash, e2);
                        }
                        continue;
                    }
                }
            } else {
                submission.source_code.clone()
            };

            if review_code.trim().is_empty() {
                warn!("Empty review code for agent {}, skipping", short_hash);
                if let Err(e) = self.storage.reset_llm_review_for_retry(agent_hash).await {
                    error!("Failed to reset review status for {}: {}", short_hash, e);
                }
                continue;
            }

            info!(
                "Reviewing agent {} with {} ({} bytes of code)",
                short_hash,
                LLM_MODEL,
                review_code.len()
            );

            match self
                .review_code(&review_code, submission.is_package, &formatted_rules)
                .await
            {
                Ok(result) => {
                    let approved = result["approved"].as_bool().unwrap_or(false);
                    let reason = result["reason"]
                        .as_str()
                        .unwrap_or("No reason provided")
                        .to_string();
                    let violations: Vec<String> = result["violations"]
                        .as_array()
                        .map(|arr| {
                            arr.iter()
                                .filter_map(|v| v.as_str().map(String::from))
                                .collect()
                        })
                        .unwrap_or_default();

                    if approved {
                        info!("Agent {} APPROVED by LLM review", short_hash);
                        if let Err(e) = self
                            .storage
                            .update_llm_review_result(agent_hash, "approved", LLM_MODEL, &result)
                            .await
                        {
                            error!("Failed to update approved status for {}: {}", short_hash, e);
                        }
                    } else {
                        warn!(
                            "Agent {} REJECTED by LLM review: {} (violations: {:?})",
                            short_hash, reason, violations
                        );
                        if let Err(e) = self
                            .storage
                            .update_llm_review_rejected(agent_hash, LLM_MODEL, &result, &reason)
                            .await
                        {
                            error!("Failed to update rejected status for {}: {}", short_hash, e);
                        }
                    }
                }
                Err(e) => {
                    error!("LLM review failed for agent {}: {}", short_hash, e);
                    if let Err(e2) = self.storage.reset_llm_review_for_retry(agent_hash).await {
                        error!("Failed to reset review status for {}: {}", short_hash, e2);
                    }
                }
            }
        }

        Ok(())
    }

    fn extract_package_code(submission: &crate::storage::pg::PendingLlmReview) -> Result<String> {
        let pkg_data = submission
            .package_data
            .as_deref()
            .context("Package data is missing for package submission")?;
        let format = submission.package_format.as_deref().unwrap_or("zip");
        let entry = submission.entry_point.as_deref().unwrap_or("agent.py");

        let validator = PackageValidator::new();
        let (_validation, files) = validator
            .validate_and_extract(pkg_data, format, entry)
            .context("Failed to validate and extract package")?;

        let code = files
            .iter()
            .filter(|f| f.is_python)
            .map(|f| {
                format!(
                    "### FILE: {} ###\n{}",
                    f.path,
                    String::from_utf8_lossy(&f.content)
                )
            })
            .collect::<Vec<_>>()
            .join("\n\n");

        if code.is_empty() {
            anyhow::bail!("No Python files found in package");
        }

        Ok(code)
    }

    async fn review_code(
        &self,
        source_code: &str,
        is_package: bool,
        rules: &str,
    ) -> Result<serde_json::Value> {
        let workspace = ReviewWorkspace::new(source_code, is_package)
            .context("Failed to create review workspace")?;

        let system_prompt = SYSTEM_PROMPT.replace("{rules}", rules);
        let tools = get_tools();

        let mut messages = vec![
            json!({"role": "system", "content": system_prompt}),
            json!({
                "role": "user",
                "content": "Please review the agent code in the workspace. Start by listing the files, then read and analyze them to check for rule violations. When done, call submit_verdict with your decision."
            }),
        ];

        let mut verdict: Option<serde_json::Value> = None;

        for turn in 0..MAX_CONVERSATION_TURNS {
            debug!("LLM review turn {}/{}", turn + 1, MAX_CONVERSATION_TURNS);

            let payload = json!({
                "model": LLM_MODEL,
                "messages": messages,
                "tools": tools,
                "max_tokens": 4096,
                "temperature": 0.1
            });

            let response = self
                .http_client
                .post(CHUTES_API_URL)
                .bearer_auth(&self.config.chutes_api_token)
                .json(&payload)
                .send()
                .await
                .context("Failed to send request to Chutes API")?;

            let status = response.status();
            if !status.is_success() {
                let error_body = response
                    .text()
                    .await
                    .unwrap_or_else(|_| "Unknown error".to_string());
                anyhow::bail!(
                    "Chutes API error HTTP {}: {}",
                    status,
                    &error_body[..500.min(error_body.len())]
                );
            }

            let response_json: serde_json::Value = response
                .json()
                .await
                .context("Failed to parse Chutes API response")?;

            let message = &response_json["choices"][0]["message"];
            let tool_calls = message["tool_calls"].as_array();

            // Add assistant message to history
            messages.push(message.clone());

            if let Some(calls) = tool_calls {
                if calls.is_empty() {
                    // No tool calls - prompt the LLM to continue
                    debug!("No tool calls in response, prompting for verdict");
                    messages.push(json!({
                        "role": "user",
                        "content": "Please continue your analysis or call submit_verdict if you have finished reviewing the code."
                    }));
                    continue;
                }

                // Process each tool call
                for call in calls {
                    let tool_id = call["id"].as_str().unwrap_or("");
                    let func_name = call["function"]["name"].as_str().unwrap_or("");
                    let args_str = call["function"]["arguments"].as_str().unwrap_or("{}");
                    
                    let args: serde_json::Value = serde_json::from_str(args_str).unwrap_or(json!({}));

                    debug!("Tool call: {}({})", func_name, args_str);

                    let result = match func_name {
                        "list_files" => {
                            let path = args["path"].as_str().unwrap_or(".");
                            workspace.list_files(path)
                        }
                        "read_file" => {
                            let path = args["path"].as_str().unwrap_or("");
                            workspace.read_file(path)
                        }
                        "grep" => {
                            let pattern = args["pattern"].as_str().unwrap_or("");
                            let path = args["path"].as_str().unwrap_or(".");
                            workspace.grep(pattern, path)
                        }
                        "submit_verdict" => {
                            info!("LLM submitted verdict: approved={}", args["approved"]);
                            verdict = Some(args.clone());
                            "Verdict received.".to_string()
                        }
                        _ => format!("Unknown function: {}", func_name),
                    };

                    // Add tool response to messages
                    messages.push(json!({
                        "role": "tool",
                        "tool_call_id": tool_id,
                        "content": result
                    }));

                    if verdict.is_some() {
                        break;
                    }
                }

                if verdict.is_some() {
                    break;
                }
            } else {
                // No tool_calls field at all - prompt for verdict
                debug!("No tool_calls in response, prompting for verdict");
                messages.push(json!({
                    "role": "user",
                    "content": "You must use the available tools to analyze the code. Please call list_files to see the project structure, or if you have finished your analysis, call submit_verdict with your decision."
                }));
            }
        }

        workspace.cleanup();

        match verdict {
            Some(v) => Ok(v),
            None => anyhow::bail!(
                "LLM did not submit verdict after {} turns",
                MAX_CONVERSATION_TURNS
            ),
        }
    }
}
