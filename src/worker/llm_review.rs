//! LLM Review Worker
//!
//! Background service that reviews pending agent submissions using a conversational
//! LLM agent that can explore the code via function calls before submitting a verdict.
//!
//! Flow:
//! 1. Polls DB for agents with llm_review_status='pending'
//! 2. Loads validation rules from the validation_rules table
//! 3. Creates a temporary workspace with the agent code
//! 4. Runs a conversation loop where the LLM can:
//!    - read_file(path) - Read a file from the workspace
//!    - list_files(path) - List files in a directory
//!    - grep(pattern, path) - Search for a pattern in files
//!    - submit_verdict(approved, reason, violations) - Submit final verdict
//! 5. Updates DB based on the verdict

use crate::storage::pg::PgStorage;
use crate::validation::package::PackageValidator;
use anyhow::{Context, Result};
use chrono::Utc;
use reqwest::Client;
use serde_json::json;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::time::interval;
use tracing::{debug, error, info, warn};

const REVIEW_TIMEOUT_SECS: u64 = 180;
const POLL_INTERVAL_SECS: u64 = 10;
const BATCH_SIZE: i64 = 5;
const LLM_MODEL: &str = "moonshotai/Kimi-K2.5-TEE";
const CHUTES_API_URL: &str = "https://llm.chutes.ai/v1/chat/completions";
const MAX_CONVERSATION_TURNS: u32 = 50;
const MAX_LLM_REVIEW_RETRIES: i32 = 3;

/// Default system prompt (used if database has no custom prompt)
const DEFAULT_SYSTEM_PROMPT: &str = r#"You are a strict security code reviewer for a terminal-based AI agent challenge.

Your task is to analyze Python agent code and determine if it complies with ALL of the validation rules.

VALIDATION RULES:
{rules}

You have access to a workspace containing the agent's source code. Use the provided tools to explore and analyze the code:

- list_files(path): List files in a directory (use "." for root)
- read_file(path): Read the contents of a file
- grep(pattern, path): Search for a regex pattern in files (path can be "." for all files)
- submit_verdict(approved, reason, violations): Submit your final verdict

WORKFLOW:
1. First, list the files to understand the project structure
2. Read the main entry point and any imported modules
3. Search for potentially dangerous patterns (subprocess, os.system, socket, requests, etc.)
4. Once you have analyzed all relevant code, submit your verdict

IMPORTANT:
- You MUST call submit_verdict when you have finished your analysis
- If ANY rule is violated, set approved=false
- Be thorough - check all Python files in the project
- The violations array should list specific rule violations found"#;

/// Redact API keys and secrets from code before LLM review
/// This prevents the LLM from seeing actual API keys in agent code
fn redact_api_keys(code: &str) -> String {
    use regex::Regex;

    let patterns = [
        // Any variable containing API_KEY, SECRET, TOKEN, PASSWORD with assignment
        (
            r#"(?i)([A-Z_]*(?:API_KEY|SECRET|TOKEN|PASSWORD|CREDENTIAL|AUTH)[A-Z_]*)\s*[=:]\s*['"](.[^'"]{8,}?)['"]"#,
            "$1=\"[REDACTED]\"",
        ),
        // Any variable containing api_key, secret, token (lowercase)
        (
            r#"(?i)([a-z_]*(?:api_key|secret|token|password|credential|auth)[a-z_]*)\s*[=:]\s*['"](.[^'"]{8,}?)['"]"#,
            "$1=\"[REDACTED]\"",
        ),
        // Chutes API tokens (cpk_ prefix with any chars)
        (r#"cpk_[a-zA-Z0-9._\-]{10,}"#, "[REDACTED_CHUTES_KEY]"),
        // sk- prefix (OpenAI, etc) - extended pattern
        (r#"sk-[a-zA-Z0-9\-_]{20,}"#, "[REDACTED_SK_KEY]"),
        // sk-proj- prefix (OpenAI project keys)
        (r#"sk-proj-[a-zA-Z0-9\-_]{20,}"#, "[REDACTED_SK_PROJ_KEY]"),
        // Bearer tokens
        (
            r#"Bearer\s+[a-zA-Z0-9\-_.]{20,}"#,
            "Bearer [REDACTED_TOKEN]",
        ),
        // AWS keys
        (r#"AKIA[0-9A-Z]{16}"#, "[REDACTED_AWS_KEY]"),
        // AWS secret keys (40 char base64)
        (
            r#"(?i)(aws_secret_access_key|aws_secret)\s*[=:]\s*['"](.[^'"]{30,}?)['"]"#,
            "$1=\"[REDACTED_AWS_SECRET]\"",
        ),
        // Generic long hex strings (64 chars - likely hashes/keys)
        (r#"['"]([a-fA-F0-9]{64})['"]"#, "\"[REDACTED_HASH]\""),
        // Generic long alphanumeric in quotes (32+ chars, likely API keys)
        (r#"['"]([a-zA-Z0-9\-_]{32,})['"]"#, "\"[REDACTED_KEY]\""),
        // Anthropic keys
        (r#"sk-ant-[a-zA-Z0-9\-_]{20,}"#, "[REDACTED_ANTHROPIC_KEY]"),
        // Google API keys
        (r#"AIza[a-zA-Z0-9\-_]{35}"#, "[REDACTED_GOOGLE_KEY]"),
        // GitHub tokens
        (r#"ghp_[a-zA-Z0-9]{36}"#, "[REDACTED_GITHUB_TOKEN]"),
        (r#"gho_[a-zA-Z0-9]{36}"#, "[REDACTED_GITHUB_TOKEN]"),
        (r#"ghu_[a-zA-Z0-9]{36}"#, "[REDACTED_GITHUB_TOKEN]"),
        // Hugging Face tokens
        (r#"hf_[a-zA-Z0-9]{34}"#, "[REDACTED_HF_TOKEN]"),
        // OpenRouter keys
        (r#"sk-or-[a-zA-Z0-9\-_]{20,}"#, "[REDACTED_OPENROUTER_KEY]"),
        // Groq keys
        (r#"gsk_[a-zA-Z0-9]{20,}"#, "[REDACTED_GROQ_KEY]"),
    ];

    let mut result = code.to_string();
    for (pattern, replacement) in patterns {
        if let Ok(re) = Regex::new(pattern) {
            result = re.replace_all(&result, replacement).to_string();
        }
    }
    result
}

/// Tool definitions for the LLM
fn get_tools() -> serde_json::Value {
    json!([
        {
            "type": "function",
            "function": {
                "name": "list_files",
                "description": "List files and directories in the specified path",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "path": {
                            "type": "string",
                            "description": "Path relative to workspace root (use '.' for root)"
                        }
                    },
                    "required": ["path"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "read_file",
                "description": "Read the contents of a file",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "path": {
                            "type": "string",
                            "description": "Path to the file relative to workspace root"
                        }
                    },
                    "required": ["path"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "grep",
                "description": "Search for a pattern in files using regex",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "pattern": {
                            "type": "string",
                            "description": "Regex pattern to search for"
                        },
                        "path": {
                            "type": "string",
                            "description": "Path to search in (use '.' for all files)"
                        }
                    },
                    "required": ["pattern"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "submit_verdict",
                "description": "Submit your final code review verdict. Call this when you have finished analyzing the code.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "approved": {
                            "type": "boolean",
                            "description": "true if the code passes ALL rules, false if ANY rule is violated"
                        },
                        "reason": {
                            "type": "string",
                            "description": "Brief explanation of the review decision"
                        },
                        "violations": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "List of specific rule violations found (empty array if approved)"
                        }
                    },
                    "required": ["approved", "reason", "violations"]
                }
            }
        }
    ])
}

/// Workspace for exploring agent code
struct ReviewWorkspace {
    root: PathBuf,
}

impl ReviewWorkspace {
    #[allow(deprecated)]
    fn new(source_code: &str, is_package: bool) -> Result<Self> {
        let tmp_dir = tempfile::tempdir().context("Failed to create temp dir")?;
        let root = tmp_dir.into_path(); // Take ownership of path, dir won't be auto-deleted

        if is_package {
            // Source code is already formatted as "### FILE: path ###\ncontent"
            for section in source_code.split("### FILE: ") {
                if section.trim().is_empty() {
                    continue;
                }
                if let Some(header_end) = section.find(" ###\n") {
                    let path = section[..header_end].trim();
                    let content = &section[header_end + 5..];

                    let file_path = root.join(path);
                    if let Some(parent) = file_path.parent() {
                        std::fs::create_dir_all(parent).ok();
                    }
                    std::fs::write(&file_path, content).ok();
                }
            }
        } else {
            // Single file submission
            let file_path = root.join("agent.py");
            std::fs::write(&file_path, source_code).ok();
        }

        Ok(Self { root })
    }

    fn list_files(&self, path: &str) -> String {
        let target = if path == "." || path.is_empty() {
            self.root.clone()
        } else {
            self.root.join(path)
        };

        if !target.exists() {
            return format!("Error: Path '{}' not found", path);
        }

        let mut entries = Vec::new();
        if let Ok(read_dir) = std::fs::read_dir(&target) {
            for entry in read_dir.flatten() {
                let name = entry.file_name().to_string_lossy().to_string();
                let is_dir = entry.file_type().map(|t| t.is_dir()).unwrap_or(false);
                if is_dir {
                    entries.push(format!("{}/", name));
                } else {
                    entries.push(name);
                }
            }
        }

        if entries.is_empty() {
            "Directory is empty".to_string()
        } else {
            entries.sort();
            entries.join("\n")
        }
    }

    fn read_file(&self, path: &str) -> String {
        let file_path = self.root.join(path);

        // Security: prevent path traversal
        if !file_path.starts_with(&self.root) {
            return "Error: Access denied - path traversal detected".to_string();
        }

        match std::fs::read_to_string(&file_path) {
            Ok(content) => {
                if content.len() > 50000 {
                    format!(
                        "{}...\n\n[Truncated - file too large ({} bytes)]",
                        &content[..50000],
                        content.len()
                    )
                } else {
                    content
                }
            }
            Err(e) => format!("Error reading file '{}': {}", path, e),
        }
    }

    fn grep(&self, pattern: &str, path: &str) -> String {
        let regex = match regex::Regex::new(pattern) {
            Ok(r) => r,
            Err(e) => return format!("Error: Invalid regex pattern: {}", e),
        };

        let mut results = Vec::new();
        let search_path = if path == "." || path.is_empty() {
            self.root.clone()
        } else {
            self.root.join(path)
        };

        self.grep_recursive(&search_path, &regex, &mut results);

        if results.is_empty() {
            format!("No matches found for pattern '{}'", pattern)
        } else {
            results.join("\n")
        }
    }

    fn grep_recursive(&self, path: &Path, regex: &regex::Regex, results: &mut Vec<String>) {
        if path.is_file() {
            if let Ok(content) = std::fs::read_to_string(path) {
                let rel_path = path.strip_prefix(&self.root).unwrap_or(path);
                for (line_num, line) in content.lines().enumerate() {
                    if regex.is_match(line) {
                        results.push(format!(
                            "{}:{}: {}",
                            rel_path.display(),
                            line_num + 1,
                            line.trim()
                        ));
                    }
                }
            }
        } else if path.is_dir() {
            if let Ok(entries) = std::fs::read_dir(path) {
                for entry in entries.flatten() {
                    self.grep_recursive(&entry.path(), regex, results);
                }
            }
        }
    }

    /// Add a reference agent's code into a `reference/<label>/` subfolder.
    /// Used for plagiarism comparison -- the LLM can read both the pending
    /// agent (at the workspace root) and each reference agent.
    #[allow(deprecated)]
    fn add_reference_agent(&self, label: &str, source_code: &str, is_package: bool) -> Result<()> {
        let ref_dir = self.root.join("reference").join(label);
        std::fs::create_dir_all(&ref_dir).context("Failed to create reference dir")?;

        if is_package {
            for section in source_code.split("### FILE: ") {
                if section.trim().is_empty() {
                    continue;
                }
                if let Some(header_end) = section.find(" ###\n") {
                    let path = section[..header_end].trim();
                    let content = &section[header_end + 5..];
                    let file_path = ref_dir.join(path);
                    if let Some(parent) = file_path.parent() {
                        std::fs::create_dir_all(parent).ok();
                    }
                    std::fs::write(&file_path, content).ok();
                }
            }
        } else {
            std::fs::write(ref_dir.join("agent.py"), source_code).ok();
        }

        Ok(())
    }

    fn cleanup(self) {
        let _ = std::fs::remove_dir_all(&self.root);
    }
}

pub struct LlmReviewWorkerConfig {
    pub poll_interval_secs: u64,
    pub batch_size: i64,
    pub chutes_api_token: String,
}

impl Default for LlmReviewWorkerConfig {
    fn default() -> Self {
        Self {
            poll_interval_secs: POLL_INTERVAL_SECS,
            batch_size: BATCH_SIZE,
            chutes_api_token: String::new(),
        }
    }
}

pub struct LlmReviewWorker {
    storage: Arc<PgStorage>,
    config: LlmReviewWorkerConfig,
    http_client: Client,
}

impl LlmReviewWorker {
    pub fn new(storage: Arc<PgStorage>, config: LlmReviewWorkerConfig) -> Self {
        let http_client = Client::builder()
            .timeout(Duration::from_secs(REVIEW_TIMEOUT_SECS))
            .build()
            .expect("Failed to create HTTP client");

        Self {
            storage,
            config,
            http_client,
        }
    }

    pub fn from_env(storage: Arc<PgStorage>) -> Option<Self> {
        let token = std::env::var("EXTRA_CHUTES_API_TOKEN")
            .or_else(|_| std::env::var("CHUTES_API_KEY"))
            .ok()?;

        if token.is_empty() {
            return None;
        }

        Some(Self::new(
            storage,
            LlmReviewWorkerConfig {
                chutes_api_token: token,
                ..Default::default()
            },
        ))
    }

    pub async fn run(&self) {
        info!(
            "LLM Review worker started (poll={}s, batch={}, model={}, max_turns={})",
            self.config.poll_interval_secs,
            self.config.batch_size,
            LLM_MODEL,
            MAX_CONVERSATION_TURNS
        );

        let mut ticker = interval(Duration::from_secs(self.config.poll_interval_secs));

        loop {
            ticker.tick().await;

            if let Err(e) = self.process_pending().await {
                error!("Error processing pending LLM reviews: {}", e);
            }
        }
    }

    async fn process_pending(&self) -> Result<()> {
        let rules = self.storage.get_active_validation_rules().await?;
        if rules.is_empty() {
            debug!("No active validation rules found - skipping LLM review cycle");
            return Ok(());
        }

        let pending = self
            .storage
            .claim_pending_llm_reviews(self.config.batch_size, MAX_LLM_REVIEW_RETRIES)
            .await?;

        if pending.is_empty() {
            debug!("No pending LLM reviews");
            return Ok(());
        }

        info!("Claimed {} agents for LLM review", pending.len());

        // Load system prompt from database (or use default)
        let system_prompt_template = self
            .storage
            .get_llm_review_system_prompt()
            .await
            .ok()
            .flatten()
            .unwrap_or_else(|| DEFAULT_SYSTEM_PROMPT.to_string());

        let formatted_rules = rules
            .iter()
            .enumerate()
            .map(|(i, r)| format!("{}. {}", i + 1, r))
            .collect::<Vec<_>>()
            .join("\n");

        for submission in pending {
            let agent_hash = &submission.agent_hash;
            let short_hash = &agent_hash[..16.min(agent_hash.len())];

            let review_code = if submission.is_package {
                match Self::extract_package_code(&submission) {
                    Ok(code) => code,
                    Err(e) => {
                        error!("Failed to extract package for {}: {}", short_hash, e);
                        if let Err(e2) = self.storage.reset_llm_review_for_retry(agent_hash).await {
                            error!("Failed to reset review status for {}: {}", short_hash, e2);
                        }
                        continue;
                    }
                }
            } else {
                submission.source_code.clone()
            };

            if review_code.trim().is_empty() {
                warn!("Empty review code for agent {}, skipping", short_hash);
                if let Err(e) = self.storage.reset_llm_review_for_retry(agent_hash).await {
                    error!("Failed to reset review status for {}: {}", short_hash, e);
                }
                continue;
            }

            // Redact API keys before passing to LLM reviewer
            let redacted_code = redact_api_keys(&review_code);

            // Check if this agent was flagged by plagiarism detection
            // If flagged, load reference agents' code for side-by-side comparison
            let mut effective_system_prompt = system_prompt_template.clone();
            let mut reference_agents: Vec<(String, String, bool)> = Vec::new();

            if let Ok(Some(report)) = self.storage.get_plagiarism_report(agent_hash).await {
                if report["status"].as_str() == Some("flagged") {
                    let score = report["score"].as_f64().unwrap_or(0.0);
                    info!(
                        "Agent {} flagged for plagiarism ({:.1}%), loading reference agents for comparison",
                        short_hash, score
                    );

                    // Collect unique matched agent hashes (up to 3)
                    let matched_hashes: Vec<String> = report["matches"]
                        .as_array()
                        .map(|arr| {
                            let mut seen = std::collections::HashSet::new();
                            arr.iter()
                                .filter_map(|m| m["matched_agent_hash"].as_str().map(String::from))
                                .filter(|h| seen.insert(h.clone()))
                                .take(3)
                                .collect()
                        })
                        .unwrap_or_default();

                    // Load reference agents' code from DB
                    if let Ok(refs) = self
                        .storage
                        .get_reference_agents_by_hashes(&matched_hashes, 3)
                        .await
                    {
                        for ref_submission in refs {
                            let ref_hash = &ref_submission.agent_hash;
                            let label = ref_hash[..16.min(ref_hash.len())].to_string();

                            let ref_code = if ref_submission.is_package {
                                match Self::extract_package_code(&ref_submission) {
                                    Ok(code) => redact_api_keys(&code),
                                    Err(e) => {
                                        warn!("Failed to extract reference agent {}: {}", label, e);
                                        continue;
                                    }
                                }
                            } else {
                                redact_api_keys(&ref_submission.source_code)
                            };

                            reference_agents.push((label, ref_code, ref_submission.is_package));
                        }
                    }

                    // Build plagiarism context for system prompt
                    if let Ok(config) = self.storage.get_plagiarism_config().await {
                        if !config.prompt_template.is_empty() {
                            let ref_labels: Vec<String> =
                                reference_agents.iter().map(|(l, _, _)| l.clone()).collect();

                            let matches_summary = report["matches"]
                                .as_array()
                                .map(|arr| {
                                    arr.iter()
                                        .take(10)
                                        .map(|m| {
                                            format!(
                                                "- {} in {}:{}-{} matches {}:{}-{} ({} nodes)",
                                                m["node_type"].as_str().unwrap_or("?"),
                                                m["pending_file"].as_str().unwrap_or("?"),
                                                m["pending_lines"]
                                                    .as_array()
                                                    .and_then(|a| a.first())
                                                    .and_then(|v| v.as_u64())
                                                    .unwrap_or(0),
                                                m["pending_lines"]
                                                    .as_array()
                                                    .and_then(|a| a.get(1))
                                                    .and_then(|v| v.as_u64())
                                                    .unwrap_or(0),
                                                m["matched_file"].as_str().unwrap_or("?"),
                                                m["matched_lines"]
                                                    .as_array()
                                                    .and_then(|a| a.first())
                                                    .and_then(|v| v.as_u64())
                                                    .unwrap_or(0),
                                                m["matched_lines"]
                                                    .as_array()
                                                    .and_then(|a| a.get(1))
                                                    .and_then(|v| v.as_u64())
                                                    .unwrap_or(0),
                                                m["subtree_size"].as_u64().unwrap_or(0),
                                            )
                                        })
                                        .collect::<Vec<_>>()
                                        .join("\n")
                                })
                                .unwrap_or_default();

                            let plagiarism_context = config
                                .prompt_template
                                .replace("{match_percent}", &format!("{:.1}", score))
                                .replace("{matches_summary}", &matches_summary)
                                .replace("{reference_labels}", &ref_labels.join(", "));

                            effective_system_prompt = format!(
                                "{}\n\n⚠️ PLAGIARISM WARNING:\n{}",
                                effective_system_prompt, plagiarism_context
                            );
                        }
                    }
                }
            }

            info!(
                "Reviewing agent {} with {} ({} bytes of code, redacted{})",
                short_hash,
                LLM_MODEL,
                redacted_code.len(),
                if reference_agents.is_empty() {
                    "".to_string()
                } else {
                    format!(", {} reference agents", reference_agents.len())
                }
            );

            match self
                .review_code(
                    agent_hash,
                    &redacted_code,
                    submission.is_package,
                    &formatted_rules,
                    &effective_system_prompt,
                    &reference_agents,
                )
                .await
            {
                Ok(result) => {
                    let verdict = &result.verdict;
                    let approved = verdict["approved"].as_bool().unwrap_or(false);
                    let reason = verdict["reason"]
                        .as_str()
                        .unwrap_or("No reason provided")
                        .to_string();
                    let violations: Vec<String> = verdict["violations"]
                        .as_array()
                        .map(|arr| {
                            arr.iter()
                                .filter_map(|v| v.as_str().map(String::from))
                                .collect()
                        })
                        .unwrap_or_default();

                    if approved {
                        info!(
                            "Agent {} APPROVED by LLM review ({} turns, {} tool calls)",
                            short_hash, result.turns_count, result.tool_calls_count
                        );
                        if let Err(e) = self
                            .storage
                            .update_llm_review_result(agent_hash, "approved", LLM_MODEL, verdict)
                            .await
                        {
                            error!("Failed to update approved status for {}: {}", short_hash, e);
                        }
                    } else {
                        warn!(
                            "Agent {} REJECTED by LLM review: {} (violations: {:?}, {} turns, {} tool calls)",
                            short_hash, reason, violations, result.turns_count, result.tool_calls_count
                        );
                        if let Err(e) = self
                            .storage
                            .update_llm_review_rejected(agent_hash, LLM_MODEL, verdict, &reason)
                            .await
                        {
                            error!("Failed to update rejected status for {}: {}", short_hash, e);
                        }
                    }
                }
                Err(e) => {
                    error!("LLM review failed for agent {}: {}", short_hash, e);
                    if let Err(e2) = self.storage.reset_llm_review_for_retry(agent_hash).await {
                        error!("Failed to reset review status for {}: {}", short_hash, e2);
                    }
                }
            }
        }

        Ok(())
    }

    fn extract_package_code(submission: &crate::storage::pg::PendingLlmReview) -> Result<String> {
        let pkg_data = submission
            .package_data
            .as_deref()
            .context("Package data is missing for package submission")?;
        let format = submission.package_format.as_deref().unwrap_or("zip");
        let entry = submission.entry_point.as_deref().unwrap_or("agent.py");

        let validator = PackageValidator::new();
        let (_validation, files) = validator
            .validate_and_extract(pkg_data, format, entry)
            .context("Failed to validate and extract package")?;

        let code = files
            .iter()
            .filter(|f| f.is_python)
            .map(|f| {
                format!(
                    "### FILE: {} ###\n{}",
                    f.path,
                    String::from_utf8_lossy(&f.content)
                )
            })
            .collect::<Vec<_>>()
            .join("\n\n");

        if code.is_empty() {
            anyhow::bail!("No Python files found in package");
        }

        Ok(code)
    }

    async fn review_code(
        &self,
        agent_hash: &str,
        source_code: &str,
        is_package: bool,
        rules: &str,
        system_prompt_template: &str,
        reference_agents: &[(String, String, bool)], // (label, code, is_package)
    ) -> Result<ReviewResult> {
        let workspace = ReviewWorkspace::new(source_code, is_package)
            .context("Failed to create review workspace")?;

        // Add reference agents to workspace for plagiarism comparison
        for (label, ref_code, ref_is_package) in reference_agents {
            if let Err(e) = workspace.add_reference_agent(label, ref_code, *ref_is_package) {
                warn!("Failed to add reference agent {}: {}", label, e);
            }
        }

        let system_prompt = system_prompt_template.replace("{rules}", rules);
        let tools = get_tools();

        let user_message = if reference_agents.is_empty() {
            "Please review the agent code in the workspace. Start by listing the files, then read and analyze them to check for rule violations. When done, call submit_verdict with your decision.".to_string()
        } else {
            let ref_labels: Vec<&str> = reference_agents
                .iter()
                .map(|(l, _, _)| l.as_str())
                .collect();
            format!(
                "Please review the agent code in the workspace. The agent's code is at the root. \
                 Reference agents for plagiarism comparison are in reference/ subdirectories: [{}]. \
                 First list the files, read the agent code AND the reference code, compare them, \
                 and check for rule violations. When done, call submit_verdict with your decision.",
                ref_labels.join(", ")
            )
        };

        let mut messages = vec![
            json!({"role": "system", "content": system_prompt}),
            json!({"role": "user", "content": user_message}),
        ];

        let mut verdict: Option<serde_json::Value> = None;
        let mut tool_calls_count: i32 = 0;
        let mut turns_count: i32 = 0;
        let started_at = Utc::now();
        let start_time = Instant::now();

        for turn in 0..MAX_CONVERSATION_TURNS {
            turns_count = turn as i32 + 1;
            debug!("LLM review turn {}/{}", turn + 1, MAX_CONVERSATION_TURNS);

            let payload = json!({
                "model": LLM_MODEL,
                "messages": messages,
                "tools": tools,
                "max_tokens": 4096,
                "temperature": 0.1
            });

            let response = self
                .http_client
                .post(CHUTES_API_URL)
                .bearer_auth(&self.config.chutes_api_token)
                .json(&payload)
                .send()
                .await
                .context("Failed to send request to Chutes API")?;

            let status = response.status();
            if !status.is_success() {
                let error_body = response
                    .text()
                    .await
                    .unwrap_or_else(|_| "Unknown error".to_string());
                let error_msg = format!(
                    "Chutes API error HTTP {}: {}",
                    status,
                    &error_body[..500.min(error_body.len())]
                );

                // Save error log
                let duration_ms = start_time.elapsed().as_millis() as i32;
                let _ = self
                    .storage
                    .save_llm_review_log(
                        agent_hash,
                        None,
                        &json!(messages),
                        tool_calls_count,
                        turns_count,
                        None,
                        LLM_MODEL,
                        started_at,
                        Some(duration_ms),
                        Some(&error_msg),
                    )
                    .await;

                anyhow::bail!("{}", error_msg);
            }

            let response_json: serde_json::Value = response
                .json()
                .await
                .context("Failed to parse Chutes API response")?;

            let message = &response_json["choices"][0]["message"];
            let tool_calls = message["tool_calls"].as_array();

            // Add assistant message to history
            messages.push(message.clone());

            if let Some(calls) = tool_calls {
                if calls.is_empty() {
                    // No tool calls - prompt the LLM to continue
                    debug!("No tool calls in response, prompting for verdict");
                    messages.push(json!({
                        "role": "user",
                        "content": "Please continue your analysis or call submit_verdict if you have finished reviewing the code."
                    }));
                    continue;
                }

                // Process each tool call
                for call in calls {
                    tool_calls_count += 1;
                    let tool_id = call["id"].as_str().unwrap_or("");
                    let func_name = call["function"]["name"].as_str().unwrap_or("");
                    let args_str = call["function"]["arguments"].as_str().unwrap_or("{}");

                    let args: serde_json::Value =
                        serde_json::from_str(args_str).unwrap_or(json!({}));

                    debug!("Tool call: {}({})", func_name, args_str);

                    let result = match func_name {
                        "list_files" => {
                            let path = args["path"].as_str().unwrap_or(".");
                            workspace.list_files(path)
                        }
                        "read_file" => {
                            let path = args["path"].as_str().unwrap_or("");
                            workspace.read_file(path)
                        }
                        "grep" => {
                            let pattern = args["pattern"].as_str().unwrap_or("");
                            let path = args["path"].as_str().unwrap_or(".");
                            workspace.grep(pattern, path)
                        }
                        "submit_verdict" => {
                            info!("LLM submitted verdict: approved={}", args["approved"]);
                            verdict = Some(args.clone());
                            "Verdict received.".to_string()
                        }
                        _ => format!("Unknown function: {}", func_name),
                    };

                    // Add tool response to messages
                    messages.push(json!({
                        "role": "tool",
                        "tool_call_id": tool_id,
                        "content": result
                    }));

                    if verdict.is_some() {
                        break;
                    }
                }

                if verdict.is_some() {
                    break;
                }
            } else {
                // No tool_calls field at all - prompt for verdict
                debug!("No tool_calls in response, prompting for verdict");
                messages.push(json!({
                    "role": "user",
                    "content": "You must use the available tools to analyze the code. Please call list_files to see the project structure, or if you have finished your analysis, call submit_verdict with your decision."
                }));
            }
        }

        workspace.cleanup();
        let duration_ms = start_time.elapsed().as_millis() as i32;

        // Save conversation log to database
        let error_msg = if verdict.is_none() {
            Some(format!(
                "LLM did not submit verdict after {} turns",
                MAX_CONVERSATION_TURNS
            ))
        } else {
            None
        };

        if let Err(e) = self
            .storage
            .save_llm_review_log(
                agent_hash,
                None,
                &json!(messages),
                tool_calls_count,
                turns_count,
                verdict.as_ref(),
                LLM_MODEL,
                started_at,
                Some(duration_ms),
                error_msg.as_deref(),
            )
            .await
        {
            warn!("Failed to save LLM review log: {}", e);
        }

        match verdict {
            Some(v) => Ok(ReviewResult {
                verdict: v,
                conversation: json!(messages),
                tool_calls_count,
                turns_count,
                duration_ms,
            }),
            None => anyhow::bail!(
                "LLM did not submit verdict after {} turns",
                MAX_CONVERSATION_TURNS
            ),
        }
    }
}

/// Result of an LLM review including conversation log
struct ReviewResult {
    verdict: serde_json::Value,
    #[allow(dead_code)]
    conversation: serde_json::Value,
    #[allow(dead_code)]
    tool_calls_count: i32,
    #[allow(dead_code)]
    turns_count: i32,
    #[allow(dead_code)]
    duration_ms: i32,
}
