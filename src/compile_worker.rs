//! Agent Compilation Worker
//!
//! Background service that compiles pending agents using PyInstaller.
//! Runs only on term-server (not validators).
//!
//! Flow:
//! 1. Polls DB for agents with compile_status='pending'
//! 2. Compiles each with PyInstaller in isolated Docker container
//! 3. Stores binary in DB
//! 4. Marks as 'success' or 'failed'
//! 5. Clears and reassigns validators from platform-server
//! 6. Assigns real evaluation tasks from terminal-bench@2.0 registry
//! 7. Notifies assigned validators via WebSocket that binary is ready

use crate::bench::registry::RegistryClient;
use crate::compiler;
use crate::container_backend::create_backend;
use crate::pg_storage::{PgStorage, TaskAssignment};
use crate::platform_ws_client::PlatformWsClient;
use serde::Deserialize;
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::RwLock;
use tokio::time::interval;
use tracing::{debug, error, info, warn};

/// Number of tasks to assign per agent (first N from terminal-bench@2.0)
const TASKS_PER_AGENT: usize = 30;

/// Number of validators to assign per agent
const VALIDATORS_PER_AGENT: usize = 2;

/// Dataset to load tasks from
const TASK_DATASET_NAME: &str = "terminal-bench";
const TASK_DATASET_VERSION: &str = "2.0";

/// Validator info from platform-server
#[derive(Debug, Deserialize)]
struct ValidatorInfo {
    hotkey: String,
    is_active: bool,
}

/// Configuration for the compile worker
pub struct CompileWorkerConfig {
    /// How often to poll for pending compilations
    pub poll_interval_secs: u64,
    /// Max agents to compile per poll
    pub batch_size: i32,
    /// Max concurrent compilations
    pub max_concurrent: usize,
}

impl Default for CompileWorkerConfig {
    fn default() -> Self {
        Self {
            poll_interval_secs: 10,
            batch_size: 5,
            max_concurrent: 2,
        }
    }
}

/// Background worker that compiles pending agents
pub struct CompileWorker {
    storage: Arc<PgStorage>,
    ws_client: Option<Arc<PlatformWsClient>>,
    config: CompileWorkerConfig,
    /// Platform server URL for fetching validators
    platform_url: String,
    /// Cached task list from terminal-bench@2.0 registry (first 30 tasks)
    task_list: Arc<RwLock<Vec<TaskAssignment>>>,
}

impl CompileWorker {
    pub fn new(
        storage: Arc<PgStorage>,
        ws_client: Option<Arc<PlatformWsClient>>,
        config: CompileWorkerConfig,
        platform_url: String,
    ) -> Self {
        Self {
            storage,
            ws_client,
            config,
            platform_url,
            task_list: Arc::new(RwLock::new(Vec::new())),
        }
    }

    /// Start the worker (runs forever)
    pub async fn run(&self) {
        info!(
            "Compile worker started (poll={}s, batch={}, concurrent={})",
            self.config.poll_interval_secs, self.config.batch_size, self.config.max_concurrent
        );

        // Load evaluation tasks from registry at startup
        if let Err(e) = self.load_evaluation_tasks().await {
            error!("Failed to load evaluation tasks: {}", e);
            error!("Compile worker will not be able to assign tasks to agents!");
        }

        // Cleanup orphan compiler containers from previous runs
        if let Err(e) = self.cleanup_orphan_compilers().await {
            warn!("Failed to cleanup orphan compiler containers: {}", e);
        }

        let mut ticker = interval(Duration::from_secs(self.config.poll_interval_secs));

        loop {
            ticker.tick().await;

            if let Err(e) = self.process_pending().await {
                error!("Error processing pending compilations: {}", e);
            }
        }
    }

    /// Load evaluation tasks from terminal-bench@2.0 registry
    async fn load_evaluation_tasks(&self) -> anyhow::Result<()> {
        info!(
            "Loading evaluation tasks from {}@{}...",
            TASK_DATASET_NAME, TASK_DATASET_VERSION
        );

        let mut registry_client = RegistryClient::new();
        let dataset = registry_client
            .get_dataset(TASK_DATASET_NAME, TASK_DATASET_VERSION)
            .await?;

        // Get first N tasks, sorted by name for determinism
        let mut task_sources = dataset.tasks.clone();
        task_sources.sort_by(|a, b| a.name.cmp(&b.name));

        let tasks: Vec<TaskAssignment> = task_sources
            .into_iter()
            .take(TASKS_PER_AGENT)
            .map(|source| TaskAssignment {
                task_id: source.name.clone(),
                task_name: source.name,
            })
            .collect();

        info!(
            "Loaded {} evaluation tasks: {:?}",
            tasks.len(),
            tasks.iter().map(|t| &t.task_id).collect::<Vec<_>>()
        );

        let mut guard = self.task_list.write().await;
        *guard = tasks;

        Ok(())
    }

    /// Cleanup orphan compiler containers from previous runs
    async fn cleanup_orphan_compilers(&self) -> anyhow::Result<()> {
        info!("Cleaning up orphan compiler containers...");
        let backend = create_backend().await?;
        // Use same challenge_id as the main challenge (from env var)
        let challenge_id =
            std::env::var("CHALLENGE_ID").unwrap_or_else(|_| "term-challenge".to_string());
        let removed = backend.cleanup(&challenge_id).await?;
        if removed > 0 {
            info!("Cleaned up {} orphan compiler containers", removed);
        } else {
            debug!("No orphan compiler containers found");
        }
        Ok(())
    }

    /// Process pending compilations
    async fn process_pending(&self) -> anyhow::Result<()> {
        // Get pending agents
        let pending = self
            .storage
            .get_pending_compilations(self.config.batch_size)
            .await?;

        if pending.is_empty() {
            debug!("No pending compilations");
            return Ok(());
        }

        info!("Found {} agents pending compilation", pending.len());

        // Process each agent (could be parallelized with semaphore)
        for (agent_hash, source_code) in pending {
            self.compile_agent(&agent_hash, &source_code).await;
        }

        Ok(())
    }

    /// Compile a single agent
    async fn compile_agent(&self, agent_hash: &str, source_code: &str) {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];
        info!("Compiling agent {}...", short_hash);
        info!(
            "Source code preview: {}...",
            &source_code[..200.min(source_code.len())].replace('\n', " ")
        );

        // Mark as compiling
        if let Err(e) = self.storage.set_compiling(agent_hash).await {
            error!("Failed to mark agent {} as compiling: {}", short_hash, e);
            return;
        }

        // Log container backend being used
        info!("Starting compilation with container backend...");
        info!(
            "  CONTAINER_BROKER_WS_URL: {:?}",
            std::env::var("CONTAINER_BROKER_WS_URL").ok()
        );
        info!(
            "  CONTAINER_BROKER_JWT: {:?}",
            std::env::var("CONTAINER_BROKER_JWT")
                .ok()
                .map(|s| format!("{}...", &s[..20.min(s.len())]))
        );

        // Compile
        match compiler::compile_agent(source_code, agent_hash).await {
            Ok(result) => {
                info!(
                    "Agent {} compiled successfully: {} bytes in {}ms",
                    short_hash, result.size, result.compile_time_ms
                );

                // Log warnings
                for warning in &result.warnings {
                    warn!("Compile warning for {}: {}", short_hash, warning);
                }

                // Store binary
                if let Err(e) = self
                    .storage
                    .store_binary(agent_hash, &result.binary, result.compile_time_ms as i32)
                    .await
                {
                    error!("Failed to store binary for {}: {}", short_hash, e);
                    let _ = self
                        .storage
                        .set_compile_failed(agent_hash, &format!("Failed to store: {}", e))
                        .await;
                    return;
                }

                // Clear and reassign validators from platform-server
                self.assign_validators(agent_hash).await;

                // Assign real evaluation tasks to this agent
                self.assign_evaluation_tasks(agent_hash).await;

                // Notify assigned validators that binary is ready
                self.notify_validators_binary_ready(agent_hash).await;
            }
            Err(e) => {
                error!("Compilation failed for {}: {}", short_hash, e);
                let _ = self
                    .storage
                    .set_compile_failed(agent_hash, &e.to_string())
                    .await;
            }
        }
    }

    /// Assign evaluation tasks from terminal-bench@2.0 to the compiled agent
    /// Clears any existing task assignments first
    async fn assign_evaluation_tasks(&self, agent_hash: &str) {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        // Clear existing task assignments
        if let Err(e) = self.storage.clear_evaluation_tasks(agent_hash).await {
            warn!(
                "Failed to clear existing task assignments for {}: {}",
                short_hash, e
            );
        }

        let tasks = self.task_list.read().await;
        if tasks.is_empty() {
            error!(
                "No evaluation tasks loaded! Cannot assign tasks to agent {}",
                short_hash
            );
            return;
        }

        match self.storage.assign_tasks_to_agent(agent_hash, &tasks).await {
            Ok(_) => {
                info!(
                    "Assigned {} evaluation tasks to agent {}",
                    tasks.len(),
                    short_hash
                );
            }
            Err(e) => {
                error!(
                    "Failed to assign evaluation tasks to agent {}: {}",
                    short_hash, e
                );
            }
        }
    }

    /// Fetch active validators from platform-server
    async fn fetch_validators(&self) -> Vec<String> {
        let client = reqwest::Client::builder()
            .timeout(Duration::from_secs(10))
            .build()
            .unwrap_or_default();

        let url = format!("{}/api/v1/validators", self.platform_url);

        match client.get(&url).send().await {
            Ok(resp) if resp.status().is_success() => match resp.json::<Vec<ValidatorInfo>>().await
            {
                Ok(validators) => {
                    let active: Vec<String> = validators
                        .into_iter()
                        .filter(|v| v.is_active)
                        .map(|v| v.hotkey)
                        .collect();
                    debug!(
                        "Fetched {} active validators from platform-server",
                        active.len()
                    );
                    active
                }
                Err(e) => {
                    warn!("Failed to parse validators response: {}", e);
                    vec![]
                }
            },
            Ok(resp) => {
                warn!("Failed to fetch validators: HTTP {}", resp.status());
                vec![]
            }
            Err(e) => {
                warn!("Failed to connect to platform-server: {}", e);
                vec![]
            }
        }
    }

    /// Select validators for an agent using deterministic hash-based selection
    fn select_validators(&self, agent_hash: &str, validators: &[String]) -> Vec<String> {
        if validators.is_empty() {
            return vec![];
        }

        let count = VALIDATORS_PER_AGENT.min(validators.len());

        // Sort validators for deterministic ordering
        let mut sorted_validators: Vec<&String> = validators.iter().collect();
        sorted_validators.sort();

        // Use agent_hash to deterministically select starting index
        let hash_bytes = hex::decode(agent_hash).unwrap_or_default();
        let start_idx = if hash_bytes.is_empty() {
            0
        } else {
            let mut idx_bytes = [0u8; 8];
            for (i, b) in hash_bytes.iter().take(8).enumerate() {
                idx_bytes[i] = *b;
            }
            u64::from_le_bytes(idx_bytes) as usize % sorted_validators.len()
        };

        // Select validators starting from start_idx (wrapping around)
        let mut selected = Vec::with_capacity(count);
        for i in 0..count {
            let idx = (start_idx + i) % sorted_validators.len();
            selected.push(sorted_validators[idx].clone());
        }

        selected
    }

    /// Assign validators to an agent after successful compilation
    /// Clears any existing validator assignments first
    async fn assign_validators(&self, agent_hash: &str) {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        // Clear existing validator assignments
        if let Err(e) = self.storage.clear_validator_assignments(agent_hash).await {
            warn!(
                "Failed to clear existing validator assignments for {}: {}",
                short_hash, e
            );
        }

        // Fetch active validators from platform-server
        let all_validators = self.fetch_validators().await;
        if all_validators.is_empty() {
            warn!("No active validators available for agent {}", short_hash);
            return;
        }

        // Select validators deterministically
        let selected = self.select_validators(agent_hash, &all_validators);
        if selected.is_empty() {
            warn!("No validators selected for agent {}", short_hash);
            return;
        }

        // Assign selected validators
        match self
            .storage
            .assign_validators_to_agent(agent_hash, &selected)
            .await
        {
            Ok(count) => {
                info!(
                    "Assigned {} validators to agent {}: {:?}",
                    count,
                    short_hash,
                    selected
                        .iter()
                        .map(|s| &s[..16.min(s.len())])
                        .collect::<Vec<_>>()
                );
            }
            Err(e) => {
                error!("Failed to assign validators to agent {}: {}", short_hash, e);
            }
        }
    }

    /// Notify assigned validators that binary compilation is complete
    async fn notify_validators_binary_ready(&self, agent_hash: &str) {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        // Get assigned validators for this agent
        let validators = match self.storage.get_assigned_validators(agent_hash).await {
            Ok(v) => v,
            Err(e) => {
                warn!(
                    "Failed to get assigned validators for {}: {}",
                    short_hash, e
                );
                return;
            }
        };

        if validators.is_empty() {
            warn!("No validators assigned to agent {}", short_hash);
            return;
        }

        // Send WebSocket notification
        if let Some(ws) = &self.ws_client {
            match ws.notify_binary_ready(&validators, agent_hash).await {
                Ok(_) => {
                    info!(
                        "Notified {} validators that binary is ready for {}",
                        validators.len(),
                        short_hash
                    );
                }
                Err(e) => {
                    warn!("Failed to notify validators for {}: {}", short_hash, e);
                }
            }
        } else {
            debug!(
                "No WebSocket client configured, skipping validator notification for {}",
                short_hash
            );
        }
    }
}

/// Start the compile worker in background
pub fn spawn_compile_worker(
    storage: Arc<PgStorage>,
    ws_client: Option<Arc<PlatformWsClient>>,
    config: CompileWorkerConfig,
    platform_url: String,
) {
    tokio::spawn(async move {
        let worker = CompileWorker::new(storage, ws_client, config, platform_url);
        worker.run().await;
    });
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_config_defaults() {
        let config = CompileWorkerConfig::default();
        assert_eq!(config.poll_interval_secs, 10);
        assert_eq!(config.batch_size, 5);
        assert_eq!(config.max_concurrent, 2);
    }
}
