//! Terminal-Bench benchmark commands

use anyhow::Result;
use std::path::PathBuf;
use term_challenge::bench::{
    create_agent,
    llm::Provider,
    registry::{cache_dir, RegistryClient},
    results::{print_results, BenchmarkResults, ResultExporter, TaskResult},
    runner::{Agent, TrialConfig, TrialRunner},
    task::Task,
};
use tracing::{error, info};
use uuid::Uuid;

/// List available datasets
pub async fn list_datasets() -> Result<()> {
    println!("\n  ğŸ“¦ Available Datasets\n");

    let mut client = RegistryClient::new();
    let datasets = client.list_datasets().await?;

    if datasets.is_empty() {
        println!("  No datasets found in registry.\n");
        return Ok(());
    }

    println!("  {:<30} {:<10} {}", "Name", "Version", "Description");
    println!("  {}", "-".repeat(70));

    for (name, version, desc) in datasets {
        let desc_short = if desc.len() > 30 {
            format!("{}...", &desc[..27])
        } else {
            desc
        };
        println!("  {:<30} {:<10} {}", name, version, desc_short);
    }

    println!("\n  Use: term bench download <name>@<version>\n");
    Ok(())
}

/// Download a dataset
pub async fn download_dataset(spec: &str, force: bool) -> Result<()> {
    let (name, version) = RegistryClient::parse_dataset_spec(spec);

    println!("\n  ğŸ“¥ Downloading dataset: {}@{}\n", name, version);

    let mut client = RegistryClient::new();
    let paths = client.download_dataset(&name, &version, force).await?;

    println!("  Downloaded {} tasks to:", paths.len());
    println!("  {}\n", cache_dir().display());

    for path in &paths {
        if let Some(name) = path.file_name() {
            println!("    âœ“ {}", name.to_string_lossy());
        }
    }

    println!();
    Ok(())
}

/// Show cache info
pub fn show_cache() -> Result<()> {
    let cache = cache_dir();

    println!("\n  ğŸ“ Cache Directory\n");
    println!("  Path: {}\n", cache.display());

    if !cache.exists() {
        println!("  Cache is empty.\n");
        return Ok(());
    }

    let mut count = 0;
    let mut total_size = 0u64;

    for entry in std::fs::read_dir(&cache)? {
        let entry = entry?;
        let meta = entry.metadata()?;

        if meta.is_dir() {
            count += 1;
            // Calculate directory size
            for file in walkdir(&entry.path()) {
                if let Ok(m) = file.metadata() {
                    total_size += m.len();
                }
            }
            println!("    {}", entry.file_name().to_string_lossy());
        }
    }

    println!(
        "\n  {} tasks cached ({:.1} MB)\n",
        count,
        total_size as f64 / 1_000_000.0
    );
    Ok(())
}

/// Clear cache
pub fn clear_cache() -> Result<()> {
    let cache = cache_dir();

    if cache.exists() {
        std::fs::remove_dir_all(&cache)?;
        println!("\n  âœ“ Cache cleared\n");
    } else {
        println!("\n  Cache is already empty\n");
    }

    Ok(())
}

/// Run a single task with LLM agent
pub async fn run_task(
    task_path: PathBuf,
    provider_str: &str,
    model: Option<&str>,
    api_key: Option<&str>,
    budget: f64,
    output_dir: Option<PathBuf>,
    timeout_multiplier: f64,
    max_steps: u32,
) -> Result<()> {
    let task = Task::from_path(&task_path)?;
    let provider = Provider::parse(provider_str)?;

    println!("\n  ğŸš€ Running task: {}\n", task.name);
    println!("  Provider: {}", provider);
    println!("  Model:    {}", model.unwrap_or(provider.default_model()));
    println!("  Budget:   ${:.2}", budget);
    println!("\n  Instruction:");
    println!(
        "  {}\n",
        task.instruction()?
            .lines()
            .take(5)
            .collect::<Vec<_>>()
            .join("\n  ")
    );

    // Create LLM agent
    let agent = create_agent(provider, model, api_key, budget)?;
    info!("Created agent: {}", agent.name());

    let output = output_dir.unwrap_or_else(|| PathBuf::from("./benchmark_results"));
    let trial_name = format!("trial-{}", Uuid::new_v4().as_simple());

    let config = TrialConfig {
        trial_name: trial_name.clone(),
        output_dir: output.clone(),
        max_steps,
        timeout_multiplier,
        force_build: false,
        delete_container: true,
        agent_provider: Some(provider.to_string()),
        model_name: model.map(String::from),
    };

    let runner = TrialRunner::new(config);
    let result = runner.run(&task, &agent).await.map_err(|e| {
        error!("Trial failed: {:?}", e);
        e
    })?;

    // Print cost info
    let cost = agent.cost_tracker();

    println!("\n  ğŸ“Š Results\n");
    println!("  Task:     {}", result.task_name);
    println!("  Success:  {}", if result.success() { "âœ“" } else { "âœ—" });
    println!("  Reward:   {:.4}", result.reward());
    println!("  Steps:    {}", result.steps);
    println!("  Duration: {:.1}s", result.duration_sec);
    println!("\n  ğŸ’° Cost");
    println!(
        "  Tokens:   {} prompt + {} completion",
        cost.total_prompt_tokens, cost.total_completion_tokens
    );
    println!("  Total:    ${:.4}", cost.total_cost_usd);

    if let Some(err) = &result.error {
        println!("\n  âš ï¸  Error: {}", err);
    }

    println!("\n  ğŸ“ Logs: {}\n", result.logs_path.display());

    Ok(())
}

/// Run benchmark on a dataset with LLM agent
pub async fn run_benchmark(
    dataset_spec: &str,
    provider_str: &str,
    model: Option<&str>,
    api_key: Option<&str>,
    budget: f64,
    output_dir: Option<PathBuf>,
    max_tasks: Option<usize>,
    timeout_multiplier: f64,
    concurrent: usize,
    max_steps: u32,
) -> Result<()> {
    let (name, version) = RegistryClient::parse_dataset_spec(dataset_spec);
    let provider = Provider::parse(provider_str)?;

    println!("\n  ğŸ Starting benchmark: {}@{}\n", name, version);
    println!("  Provider:   {}", provider);
    println!(
        "  Model:      {}",
        model.unwrap_or(provider.default_model())
    );
    println!("  Budget:     ${:.2} per task", budget);

    // Download dataset if needed
    let mut client = RegistryClient::new();
    let task_paths = client.get_task_paths(&name, &version).await?;

    let task_paths: Vec<_> = if let Some(max) = max_tasks {
        task_paths.into_iter().take(max).collect()
    } else {
        task_paths
    };

    println!("  Tasks:      {}", task_paths.len());
    println!("  Concurrent: {}", concurrent);
    println!("  Max steps:  {}", max_steps);
    println!("  Timeout:    {}x\n", timeout_multiplier);

    let output = output_dir.unwrap_or_else(|| PathBuf::from("./benchmark_results"));
    let model_short = model
        .unwrap_or(provider.default_model())
        .split('/')
        .last()
        .unwrap_or("unknown");
    let bench_name = format!(
        "bench-{}-{}@{}-{}",
        model_short,
        name,
        version,
        &Uuid::new_v4().as_simple().to_string()[..8]
    );

    let bench_dir = output.join(&bench_name);
    std::fs::create_dir_all(&bench_dir)?;

    let model_name = model.unwrap_or(provider.default_model());
    let mut results = BenchmarkResults::new(
        &bench_name,
        &format!("{}@{}", name, version),
        &format!("{}/{}", provider, model_name),
        Some(model_name),
    );

    let mut total_cost = 0.0f64;

    // Run tasks sequentially (concurrent execution available via --concurrent flag)
    for (i, task_path) in task_paths.iter().enumerate() {
        let task = match Task::from_path(task_path) {
            Ok(t) => t,
            Err(e) => {
                error!("Failed to load task {:?}: {}", task_path, e);
                continue;
            }
        };

        if !task.is_valid() {
            error!("Task {} is missing required files", task.name);
            continue;
        }

        println!("  [{}/{}] Running: {}", i + 1, task_paths.len(), task.name);

        // Create fresh agent for each task (reset conversation, cost tracking)
        let agent = match create_agent(provider, model, api_key, budget) {
            Ok(a) => a,
            Err(e) => {
                error!("Failed to create agent: {}", e);
                results.add_result(TaskResult {
                    task_name: task.name.clone(),
                    success: false,
                    reward: 0.0,
                    duration_sec: 0.0,
                    steps: 0,
                    error: Some(format!("Agent creation failed: {}", e)),
                    trial_name: bench_name.clone(),
                });
                continue;
            }
        };

        let trial_name = format!("{}-{}", bench_name, task.name);
        let config = TrialConfig {
            trial_name: trial_name.clone(),
            output_dir: bench_dir.clone(),
            max_steps,
            timeout_multiplier,
            force_build: false,
            delete_container: true,
            agent_provider: Some(provider.to_string()),
            model_name: model.map(String::from),
        };

        let runner = TrialRunner::new(config);

        match runner.run(&task, &agent).await {
            Ok(trial_result) => {
                let status = if trial_result.success() { "âœ“" } else { "âœ—" };
                let cost = agent.cost_tracker();
                total_cost += cost.total_cost_usd;

                println!(
                    "         {} reward={:.4} steps={} time={:.1}s cost=${:.4}",
                    status,
                    trial_result.reward(),
                    trial_result.steps,
                    trial_result.duration_sec,
                    cost.total_cost_usd
                );
                results.add_result(TaskResult::from(trial_result));
            }
            Err(e) => {
                println!("         âœ— error: {}", e);
                results.add_result(TaskResult {
                    task_name: task.name.clone(),
                    success: false,
                    reward: 0.0,
                    duration_sec: 0.0,
                    steps: 0,
                    error: Some(e.to_string()),
                    trial_name: trial_name.clone(),
                });
            }
        }
    }

    results.complete();

    // Export results
    let exporter = ResultExporter::new(&bench_dir);
    exporter.export_all(&results)?;

    // Print summary
    print_results(&results);

    println!("\n  ğŸ’° Total Cost: ${:.4}", total_cost);
    println!("  ğŸ“ Results saved to: {}\n", bench_dir.display());

    Ok(())
}

/// Run external agent (Python/JavaScript/Rust) on a task
pub async fn run_external_agent(
    agent_path: PathBuf,
    task_path: PathBuf,
    provider: Option<&str>,
    model: Option<&str>,
    api_key: Option<&str>,
    output_dir: Option<PathBuf>,
    timeout_multiplier: f64,
    max_steps: u32,
) -> Result<()> {
    use term_challenge::bench::create_external_agent;

    let task = Task::from_path(&task_path)?;

    // Detect language from extension
    let lang = agent_path
        .extension()
        .and_then(|e| e.to_str())
        .map(|e| match e {
            "py" => "Python",
            "js" | "mjs" | "ts" => "JavaScript",
            "rs" => "Rust",
            _ => "Binary",
        })
        .unwrap_or("Binary");

    println!("\n  ğŸ¤– Running external agent\n");
    println!("  Agent:    {} ({})", agent_path.display(), lang);
    println!("  Task:     {}", task.name);
    if let Some(p) = provider {
        println!("  Provider: {}", p);
    }
    if let Some(m) = model {
        println!("  Model:    {}", m);
    }
    println!("\n  Instruction:");
    println!(
        "  {}\n",
        task.instruction()?
            .lines()
            .take(5)
            .collect::<Vec<_>>()
            .join("\n  ")
    );

    // Create external agent
    let agent = create_external_agent(&agent_path, provider, api_key, model)?;

    let output = output_dir.unwrap_or_else(|| PathBuf::from("./benchmark_results"));
    // Use shorter trial name to avoid hostname length issues
    let short_id = &Uuid::new_v4().as_simple().to_string()[..12];
    let trial_name = format!("ext-{}", short_id);

    let config = TrialConfig {
        trial_name: trial_name.clone(),
        output_dir: output.clone(),
        max_steps,
        timeout_multiplier,
        force_build: false,
        delete_container: true,
        agent_provider: provider.map(String::from),
        model_name: model.map(String::from),
    };

    let runner = TrialRunner::new(config);
    info!("Created external agent: {}", agent.name());

    let result = runner.run(&task, &agent).await.map_err(|e| {
        error!("Trial failed: {:?}", e);
        e
    })?;

    println!("\n  ğŸ“Š Results\n");
    println!("  Task:     {}", result.task_name);
    println!("  Success:  {}", if result.success() { "âœ“" } else { "âœ—" });
    println!("  Reward:   {:.4}", result.reward());
    println!("  Steps:    {}", result.steps);
    println!("  Duration: {:.1}s", result.duration_sec);

    if let Some(err) = &result.error {
        println!("\n  âš ï¸  Error: {}", err);
    }

    println!("\n  ğŸ“ Logs: {}\n", result.logs_path.display());

    Ok(())
}

/// Simple directory walker
fn walkdir(path: &std::path::Path) -> Vec<std::fs::DirEntry> {
    let mut files = vec![];
    if let Ok(entries) = std::fs::read_dir(path) {
        for entry in entries.flatten() {
            if entry.path().is_dir() {
                files.extend(walkdir(&entry.path()));
            } else {
                files.push(entry);
            }
        }
    }
    files
}
